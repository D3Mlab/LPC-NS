{"time_milp": 0.15304994583129883, "time_greedy": 0.8265018463134766, "time_refit_milp_assignment": 0.6093089580535889, "mse_refit_ground_truth_assignment": 0.18782509805919062, "r2_refit_ground_truth_assignment": 0.996707768029141, "weight_mismatch_refit_ground_truth_assignment": 0.20728834892198392, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.23976044533166724, "r2_milp": 0.9957974359570436, "weight_mismatch_milp": 0.27464388820261154, "refit-weight_mismatch_milp": 0.1068882197979834, "rand_score_milp": 0.8734463276836159, "label_mismatch_milp": 0.06666666666666667, "mse_refit_milp_assignment": 0.23973413522491116, "r2_refit_milp_assignment": 0.9957978971253088, "weight_mismatch_refit_milp_assignment": 0.2716888503284701, "refit-weight_mismatch_refit_milp_assignment": 0.0996128847902532, "rand_score_refit_milp_assignment": 0.8734463276836159, "label_mismatch_refit_milp_assignment": 0.06666666666666667, "mse_greedy": 5.2207717283794075, "r2_greedy": 0.9084893777544527, "weight_mismatch_greedy": 4.539489915284593, "refit-weight_mismatch_greedy": 4.383898052604348, "rand_score_greedy": 0.850225988700565, "label_mismatch_greedy": 0.13333333333333336, "mse_greedy_sem": 1.8012214512694547, "r2_greedy_sem": 0.031572132317468915, "weight_mismatch_greedy_sem": 1.5684684089114724, "refit-weight_mismatch_greedy_sem": 1.585682930421992, "rand_score_greedy_sem": 0.05250371708782266, "label_mismatch_greedy_sem": 0.046969568348848946, "mse_ground_truth": 0.206826573467185, "r2_ground_truth": 0.996708717198468, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 54.87454507145427, "r2_baseline_sklearn": 0.03814914227462696, "mse_milp_val": 13.20347670358571, "r2_milp_val": 0.7957606193045368, "label_mismatch_milp_val": 0.15, "mse_refit_milp_assignment_val": 13.212955680481125, "r2_refit_milp_assignment_val": 0.7956139927444111, "label_mismatch_refit_milp_assignment_val": 0.15, "mse_greedy_val": 26.547318069370835, "label_mismatch_greedy_val": 0.205, "mse_greedy_val_sem": 4.5429074537238545, "label_mismatch_greedy_val_sem": 0.023198230422530983, "r2_greedy_val": 0.5893499929347163, "r2_greedy_val_sem": 0.07027244609394334, "mse_refit_ground_truth_assignment_val": 13.672762491979125, "r2_refit_ground_truth_assignment_val": 0.7885014222807238, "label_mismatch_refit_ground_truth_assignment_val": 0.15, "mse_ground_truth_val": 13.790145935894651, "r2_ground_truth_val": 0.7866856640204243, "label_mismatch_ground_truth_val": 0.15, "mse_baseline_sklearn_val": 76.11416047678843, "r2_baseline_sklearn_val": -0.17737996945248713, "random_state": 42}