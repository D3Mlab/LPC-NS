{"time_milp": 6.06780219078064, "time_greedy": 0.8677179098129273, "time_refit_milp_assignment": 6.498121023178101, "mse_refit_ground_truth_assignment": 0.09336682139276496, "r2_refit_ground_truth_assignment": 0.9996550036607468, "weight_mismatch_refit_ground_truth_assignment": 1.2152959987649419, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.20885224405988295, "r2_milp": 0.9992282776839712, "weight_mismatch_milp": 2.4440079648660347, "refit-weight_mismatch_milp": 1.2919652028678648, "rand_score_milp": 0.9666666666666667, "label_mismatch_milp": 0.016666666666666666, "mse_refit_milp_assignment": 0.20870852585344407, "r2_refit_milp_assignment": 0.9992288087318784, "weight_mismatch_refit_milp_assignment": 2.404642742100583, "refit-weight_mismatch_refit_milp_assignment": 1.2631819352759295, "rand_score_refit_milp_assignment": 0.9666666666666667, "label_mismatch_refit_milp_assignment": 0.016666666666666666, "mse_greedy": 28.333547930773392, "r2_greedy": 0.895305739572607, "weight_mismatch_greedy": 35.12072697079786, "refit-weight_mismatch_greedy": 34.68601881703109, "rand_score_greedy": 0.5362146892655367, "label_mismatch_greedy": 0.40166666666666667, "mse_greedy_sem": 2.414344755446934, "r2_greedy_sem": 0.008921157322261687, "weight_mismatch_greedy_sem": 3.147604485534386, "refit-weight_mismatch_greedy_sem": 3.113628339375512, "rand_score_greedy_sem": 0.024172358683268808, "label_mismatch_greedy_sem": 0.02544630857085249, "mse_ground_truth": 0.2859709755546288, "r2_ground_truth": 0.9990189208687302, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 211.80921282804871, "r2_baseline_sklearn": 0.21735149643380647, "mse_milp_val": 23.32358545369222, "r2_milp_val": 0.9236430468909294, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 23.345404150412357, "r2_refit_milp_assignment_val": 0.9235716166553994, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 817.9818662539468, "label_mismatch_greedy_val": 0.36374999999999996, "mse_greedy_val_sem": 82.35687168807321, "label_mismatch_greedy_val_sem": 0.019989717751621047, "r2_greedy_val": -1.6779160146552516, "r2_greedy_val_sem": 0.26962062939171516, "mse_refit_ground_truth_assignment_val": 25.556785346674893, "r2_refit_ground_truth_assignment_val": 0.9163319780224564, "label_mismatch_refit_ground_truth_assignment_val": 0.175, "mse_ground_truth_val": 24.768773001425153, "r2_ground_truth_val": 0.9189117795634788, "label_mismatch_ground_truth_val": 0.175, "mse_baseline_sklearn_val": 334.4456146975752, "r2_baseline_sklearn_val": -0.09491090766039956, "random_state": 3}