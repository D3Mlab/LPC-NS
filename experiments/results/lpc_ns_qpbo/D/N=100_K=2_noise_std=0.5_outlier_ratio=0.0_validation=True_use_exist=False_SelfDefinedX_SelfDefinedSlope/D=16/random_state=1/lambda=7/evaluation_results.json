{"time_milp": 1.064945936203003, "time_greedy": 1.4397771596908568, "time_refit_milp_assignment": 1.8009870052337646, "mse_refit_ground_truth_assignment": 0.15832898862283953, "r2_refit_ground_truth_assignment": 0.9995621724683236, "weight_mismatch_refit_ground_truth_assignment": 1.2184001075621946, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.34190681919176613, "r2_milp": 0.9990545242535044, "weight_mismatch_milp": 1.2986030351743667, "refit-weight_mismatch_milp": 1.8377335320494255, "rand_score_milp": 0.9344632768361582, "label_mismatch_milp": 0.03333333333333333, "mse_refit_milp_assignment": 0.3416462661416904, "r2_refit_milp_assignment": 0.9990552447614782, "weight_mismatch_refit_milp_assignment": 1.3164752449315449, "refit-weight_mismatch_refit_milp_assignment": 1.9487780067225327, "rand_score_refit_milp_assignment": 0.9344632768361582, "label_mismatch_refit_milp_assignment": 0.03333333333333333, "mse_greedy": 36.048660340892354, "r2_greedy": 0.9003145531682, "weight_mismatch_greedy": 37.46075497592024, "refit-weight_mismatch_greedy": 36.9577659749663, "rand_score_greedy": 0.5077966101694915, "label_mismatch_greedy": 0.42666666666666664, "mse_greedy_sem": 2.541570425963387, "r2_greedy_sem": 0.0070282107898264464, "weight_mismatch_greedy_sem": 2.7656179894819446, "refit-weight_mismatch_greedy_sem": 2.709875458163671, "rand_score_greedy_sem": 0.004296757817363059, "label_mismatch_greedy_sem": 0.011747837924760147, "mse_ground_truth": 0.2594939593127937, "r2_ground_truth": 0.9993164663034297, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 254.05380271886685, "r2_baseline_sklearn": 0.29746441049794414, "mse_milp_val": 47.80165756020317, "r2_milp_val": 0.8712847127029607, "label_mismatch_milp_val": 0.175, "mse_refit_milp_assignment_val": 47.90378893544594, "r2_refit_milp_assignment_val": 0.8710097040531067, "label_mismatch_refit_milp_assignment_val": 0.175, "mse_greedy_val": 840.0066395204219, "label_mismatch_greedy_val": 0.4125, "mse_greedy_val_sem": 47.44677483681241, "label_mismatch_greedy_val_sem": 0.015966659341462627, "r2_greedy_val": -1.261881730798125, "r2_greedy_val_sem": 0.1277596963399586, "mse_refit_ground_truth_assignment_val": 46.02232037464663, "r2_refit_ground_truth_assignment_val": 0.8760759251572312, "label_mismatch_refit_ground_truth_assignment_val": 0.2, "mse_ground_truth_val": 48.29281067174403, "r2_ground_truth_val": 0.869962187144528, "label_mismatch_ground_truth_val": 0.2, "mse_baseline_sklearn_val": 430.1885904021713, "r2_baseline_sklearn_val": -0.1583666933680381, "random_state": 7}