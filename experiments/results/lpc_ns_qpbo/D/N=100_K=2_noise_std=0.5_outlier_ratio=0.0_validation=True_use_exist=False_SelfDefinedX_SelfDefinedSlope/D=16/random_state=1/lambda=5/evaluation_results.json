{"time_milp": 19.853557109832764, "time_greedy": 1.3335028171539307, "time_refit_milp_assignment": 20.570767164230347, "mse_refit_ground_truth_assignment": 0.0749303523670835, "r2_refit_ground_truth_assignment": 0.9997667612714473, "weight_mismatch_refit_ground_truth_assignment": 0.7499198481920302, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.07649285465549159, "r2_milp": 0.9997618976075835, "weight_mismatch_milp": 0.62633301434443, "refit-weight_mismatch_milp": 0.531917312283064, "rand_score_milp": 0.9666666666666667, "label_mismatch_milp": 0.016666666666666666, "mse_refit_milp_assignment": 0.07628551188001727, "r2_refit_milp_assignment": 0.9997625430117995, "weight_mismatch_refit_milp_assignment": 0.6893397973509896, "refit-weight_mismatch_refit_milp_assignment": 0.529388027743602, "rand_score_refit_milp_assignment": 0.9666666666666667, "label_mismatch_refit_milp_assignment": 0.016666666666666666, "mse_greedy": 34.42336923901479, "r2_greedy": 0.8928489908271617, "weight_mismatch_greedy": 37.85729088730786, "refit-weight_mismatch_greedy": 37.886455606658046, "rand_score_greedy": 0.5063841807909604, "label_mismatch_greedy": 0.43166666666666675, "mse_greedy_sem": 2.381581960922165, "r2_greedy_sem": 0.007413246180777985, "weight_mismatch_greedy_sem": 2.7495069266173138, "refit-weight_mismatch_greedy_sem": 2.781883704879086, "rand_score_greedy_sem": 0.004747479264202526, "label_mismatch_greedy_sem": 0.011778908695565965, "mse_ground_truth": 0.2187746024833642, "r2_ground_truth": 0.999239297478292, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 221.5640520114027, "r2_baseline_sklearn": 0.3103286431783202, "mse_milp_val": 4.448186228773797, "r2_milp_val": 0.9812354303386273, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 4.506509771139633, "r2_refit_milp_assignment_val": 0.980989393838055, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 775.1530615407432, "label_mismatch_greedy_val": 0.41624999999999995, "mse_greedy_val_sem": 68.43490531846082, "label_mismatch_greedy_val_sem": 0.01384536308470704, "r2_greedy_val": -2.269965076421105, "r2_greedy_val_sem": 0.28869104890684816, "mse_refit_ground_truth_assignment_val": 4.246935468030907, "r2_refit_ground_truth_assignment_val": 0.9820844019700162, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 4.228246182254269, "r2_ground_truth_val": 0.9821632422853359, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 237.17778674651072, "r2_baseline_sklearn_val": -0.0005289510466286451, "random_state": 5}