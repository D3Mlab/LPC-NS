{"time_milp": 0.3192710876464844, "time_greedy": 0.85569908618927, "time_refit_milp_assignment": 0.7525491714477539, "mse_refit_ground_truth_assignment": 0.15771072104605982, "r2_refit_ground_truth_assignment": 0.9982510184387788, "weight_mismatch_refit_ground_truth_assignment": 0.5427918855272094, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.3081728882987248, "r2_milp": 0.996582421944889, "weight_mismatch_milp": 0.6323046660499027, "refit-weight_mismatch_milp": 0.20633471836166967, "rand_score_milp": 0.844632768361582, "label_mismatch_milp": 0.08333333333333333, "mse_refit_milp_assignment": 0.3081177453488118, "r2_refit_milp_assignment": 0.996583033469597, "weight_mismatch_refit_milp_assignment": 0.615367651496669, "refit-weight_mismatch_refit_milp_assignment": 0.2039473338510131, "rand_score_refit_milp_assignment": 0.844632768361582, "label_mismatch_refit_milp_assignment": 0.08333333333333333, "mse_greedy": 5.0821791980925335, "r2_greedy": 0.9436396102349335, "weight_mismatch_greedy": 4.000473416622467, "refit-weight_mismatch_greedy": 3.6070363346974625, "rand_score_greedy": 0.832683615819209, "label_mismatch_greedy": 0.11416666666666667, "mse_greedy_sem": 2.199516654676414, "r2_greedy_sem": 0.02439221662999316, "weight_mismatch_greedy_sem": 1.7440473098568763, "refit-weight_mismatch_greedy_sem": 1.7592916126748956, "rand_score_greedy_sem": 0.04105751570174659, "label_mismatch_greedy_sem": 0.03151336391537973, "mse_ground_truth": 0.2787092705375627, "r2_ground_truth": 0.9971542198404661, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 73.12416379755966, "r2_baseline_sklearn": 0.18906708869654587, "mse_milp_val": 48.252345016912486, "r2_milp_val": 0.5318432526399078, "label_mismatch_milp_val": 0.2, "mse_refit_milp_assignment_val": 48.285593017122366, "r2_refit_milp_assignment_val": 0.5315206719315707, "label_mismatch_refit_milp_assignment_val": 0.2, "mse_greedy_val": 64.14959640291406, "label_mismatch_greedy_val": 0.19749999999999998, "mse_greedy_val_sem": 10.98156133846695, "label_mismatch_greedy_val_sem": 0.023779413918677418, "r2_greedy_val": 0.37760400275002926, "r2_greedy_val_sem": 0.10654595202264411, "mse_refit_ground_truth_assignment_val": 48.43030323318588, "r2_refit_ground_truth_assignment_val": 0.5301166559394292, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 50.85981581309831, "r2_ground_truth_val": 0.5065448957134014, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 113.93685837399524, "r2_baseline_sklearn_val": -0.10544490639991211, "random_state": 12}