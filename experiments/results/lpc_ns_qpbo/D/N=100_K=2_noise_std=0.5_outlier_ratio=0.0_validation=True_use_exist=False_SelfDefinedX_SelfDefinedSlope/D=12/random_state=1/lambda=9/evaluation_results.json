{"time_milp": 0.3984217643737793, "time_greedy": 0.9284326553344726, "time_refit_milp_assignment": 0.8238325119018555, "mse_refit_ground_truth_assignment": 0.1468546064180364, "r2_refit_ground_truth_assignment": 0.9986610479539523, "weight_mismatch_refit_ground_truth_assignment": 0.5246600807107313, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.3920863685312744, "r2_milp": 0.996425138726136, "weight_mismatch_milp": 0.8326419039580715, "refit-weight_mismatch_milp": 0.6580237911811249, "rand_score_milp": 0.8734463276836159, "label_mismatch_milp": 0.06666666666666667, "mse_refit_milp_assignment": 0.3920109433694485, "r2_refit_milp_assignment": 0.9964258264177053, "weight_mismatch_refit_milp_assignment": 0.8336364301789514, "refit-weight_mismatch_refit_milp_assignment": 0.6640055007568512, "rand_score_refit_milp_assignment": 0.8734463276836159, "label_mismatch_refit_milp_assignment": 0.06666666666666667, "mse_greedy": 15.784362617211439, "r2_greedy": 0.8560855179325232, "weight_mismatch_greedy": 16.33375064749053, "refit-weight_mismatch_greedy": 16.1767932259365, "rand_score_greedy": 0.5898870056497175, "label_mismatch_greedy": 0.33166666666666667, "mse_greedy_sem": 2.099982196768442, "r2_greedy_sem": 0.01914666163772182, "weight_mismatch_greedy_sem": 2.163594212992957, "refit-weight_mismatch_greedy_sem": 2.1664356367216864, "rand_score_greedy_sem": 0.0346284945500736, "label_mismatch_greedy_sem": 0.03246455557097699, "mse_ground_truth": 0.2731688425583087, "r2_ground_truth": 0.9977363692432765, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 102.47691024711214, "r2_baseline_sklearn": 0.06566316171631958, "mse_milp_val": 46.583134859534006, "r2_milp_val": 0.6574103743398438, "label_mismatch_milp_val": 0.25, "mse_refit_milp_assignment_val": 46.675975938101786, "r2_refit_milp_assignment_val": 0.6567275866646834, "label_mismatch_refit_milp_assignment_val": 0.25, "mse_greedy_val": 165.58210997495638, "label_mismatch_greedy_val": 0.33999999999999997, "mse_greedy_val_sem": 15.50637369819777, "label_mismatch_greedy_val_sem": 0.024494897427831782, "r2_greedy_val": -0.2177521595185012, "r2_greedy_val_sem": 0.11403961490850185, "mse_refit_ground_truth_assignment_val": 45.26355175937689, "r2_refit_ground_truth_assignment_val": 0.6671150771614438, "label_mismatch_refit_ground_truth_assignment_val": 0.25, "mse_ground_truth_val": 46.63482116126487, "r2_ground_truth_val": 0.6570302541350717, "label_mismatch_ground_truth_val": 0.25, "mse_baseline_sklearn_val": 137.9844136117097, "r2_baseline_sklearn_val": -0.014788479751632444, "random_state": 9}