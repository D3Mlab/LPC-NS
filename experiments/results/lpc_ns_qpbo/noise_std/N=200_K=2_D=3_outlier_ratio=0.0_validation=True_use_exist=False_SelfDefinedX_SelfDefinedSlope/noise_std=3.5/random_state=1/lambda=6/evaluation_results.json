{"time_milp": 0.8348500728607178, "time_greedy": 1.5950528144836427, "time_refit_milp_assignment": 1.5294437408447266, "mse_refit_ground_truth_assignment": 11.987288696973252, "r2_refit_ground_truth_assignment": 0.8600125498545169, "weight_mismatch_refit_ground_truth_assignment": 1.7728647196863232, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 11.090666957619357, "r2_milp": 0.8704832905040562, "weight_mismatch_milp": 1.576262966663712, "refit-weight_mismatch_milp": 0.5308873301043966, "rand_score_milp": 0.9669467787114846, "label_mismatch_milp": 0.016666666666666666, "mse_refit_milp_assignment": 11.090661377546578, "r2_refit_milp_assignment": 0.8704833556680961, "weight_mismatch_refit_milp_assignment": 1.5688427510886302, "refit-weight_mismatch_refit_milp_assignment": 0.5314804913686909, "rand_score_refit_milp_assignment": 0.9669467787114846, "label_mismatch_refit_milp_assignment": 0.016666666666666666, "mse_greedy": 19.693363131265638, "r2_greedy": 0.7700210815619187, "weight_mismatch_greedy": 7.630527339740984, "refit-weight_mismatch_greedy": 6.244790858934698, "rand_score_greedy": 0.7821918767507002, "label_mismatch_greedy": 0.17541666666666664, "mse_greedy_sem": 2.471679148580091, "r2_greedy_sem": 0.02886424698145881, "weight_mismatch_greedy_sem": 1.8033253276728418, "refit-weight_mismatch_greedy_sem": 1.793562233584468, "rand_score_greedy_sem": 0.049398150111765085, "label_mismatch_greedy_sem": 0.04391926321429526, "mse_ground_truth": 11.444958620353946, "r2_ground_truth": 0.8693850105768063, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 80.43545496965731, "r2_baseline_sklearn": 0.060675476570673514, "mse_milp_val": 10.176133025599967, "r2_milp_val": 0.8876435223867416, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 10.17410531169398, "r2_refit_milp_assignment_val": 0.8876659107332295, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 27.008224386233064, "label_mismatch_greedy_val": 0.15375, "mse_greedy_val_sem": 4.7731102512991415, "label_mismatch_greedy_val_sem": 0.04278638033422859, "r2_greedy_val": 0.7017974361192333, "r2_greedy_val_sem": 0.052700751232965276, "mse_refit_ground_truth_assignment_val": 10.669822848667351, "r2_refit_ground_truth_assignment_val": 0.882192606069726, "label_mismatch_refit_ground_truth_assignment_val": 0.025, "mse_ground_truth_val": 10.390686662989776, "r2_ground_truth_val": 0.8852745978752806, "label_mismatch_ground_truth_val": 0.025, "mse_baseline_sklearn_val": 90.63050565638022, "r2_baseline_sklearn_val": -0.0006673806486530154, "random_state": 6}