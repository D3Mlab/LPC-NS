{"time_milp": 0.7499728202819824, "time_greedy": 1.477656650543213, "time_refit_milp_assignment": 1.472681999206543, "mse_refit_ground_truth_assignment": 15.791065120306431, "r2_refit_ground_truth_assignment": 0.8504925163097918, "weight_mismatch_refit_ground_truth_assignment": 2.5350752539397394, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 14.316448019256795, "r2_milp": 0.8644539742928238, "weight_mismatch_milp": 2.6861854154987537, "refit-weight_mismatch_milp": 0.28823888463727393, "rand_score_milp": 0.9833333333333333, "label_mismatch_milp": 0.008333333333333333, "mse_refit_milp_assignment": 14.316442219384689, "r2_refit_milp_assignment": 0.8644540292051605, "weight_mismatch_refit_milp_assignment": 2.68723017862592, "refit-weight_mismatch_refit_milp_assignment": 0.2877788104600138, "rand_score_refit_milp_assignment": 0.9833333333333333, "label_mismatch_refit_milp_assignment": 0.008333333333333333, "mse_greedy": 19.424186202580664, "r2_greedy": 0.8160946598755118, "weight_mismatch_greedy": 4.563459718580541, "refit-weight_mismatch_greedy": 2.7597817504327997, "rand_score_greedy": 0.8841666666666667, "label_mismatch_greedy": 0.08208333333333331, "mse_greedy_sem": 2.4944074057156076, "r2_greedy_sem": 0.023616682705411073, "weight_mismatch_greedy_sem": 0.8865210863214439, "refit-weight_mismatch_greedy_sem": 1.1619492497196533, "rand_score_greedy_sem": 0.0381675558624243, "label_mismatch_greedy_sem": 0.030703704512000402, "mse_ground_truth": 17.720596549003943, "r2_ground_truth": 0.82394060608585, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 102.21051821648389, "r2_baseline_sklearn": 0.03228583576874289, "mse_milp_val": 17.57793912687699, "r2_milp_val": 0.8109402635285143, "label_mismatch_milp_val": 0.05, "mse_refit_milp_assignment_val": 17.58185243432374, "r2_refit_milp_assignment_val": 0.8108981739030312, "label_mismatch_refit_milp_assignment_val": 0.05, "mse_greedy_val": 25.846998006655628, "label_mismatch_greedy_val": 0.11062499999999997, "mse_greedy_val_sem": 3.499489926613438, "label_mismatch_greedy_val_sem": 0.029178373277228175, "r2_greedy_val": 0.7220023009269847, "r2_greedy_val_sem": 0.03763880614983685, "mse_refit_ground_truth_assignment_val": 19.449222296931538, "r2_refit_ground_truth_assignment_val": 0.7908136548037693, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 16.787023775947084, "r2_ground_truth_val": 0.8194469631329876, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 93.33544936154559, "r2_baseline_sklearn_val": -0.0038705523084037186, "random_state": 12}