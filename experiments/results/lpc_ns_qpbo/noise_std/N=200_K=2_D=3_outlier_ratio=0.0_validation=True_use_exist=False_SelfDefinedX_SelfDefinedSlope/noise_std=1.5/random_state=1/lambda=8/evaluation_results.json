{"time_milp": 0.3874680995941162, "time_greedy": 0.9559069991111755, "time_refit_milp_assignment": 0.8053524494171143, "mse_refit_ground_truth_assignment": 2.4744398587509955, "r2_refit_ground_truth_assignment": 0.970626458349566, "weight_mismatch_refit_ground_truth_assignment": 0.630381297633589, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.474443716796, "r2_milp": 0.9706264125515461, "weight_mismatch_milp": 0.6289228685813983, "refit-weight_mismatch_milp": 0.006373098994343357, "rand_score_milp": 1.0, "label_mismatch_milp": 0.0, "mse_refit_milp_assignment": 2.4744398587509955, "r2_refit_milp_assignment": 0.970626458349566, "weight_mismatch_refit_milp_assignment": 0.630381297633589, "refit-weight_mismatch_refit_milp_assignment": 0.0, "rand_score_refit_milp_assignment": 1.0, "label_mismatch_refit_milp_assignment": 0.0, "mse_greedy": 8.903577805495754, "r2_greedy": 0.8943075490064164, "weight_mismatch_greedy": 4.53487356325664, "refit-weight_mismatch_greedy": 4.110350167736437, "rand_score_greedy": 0.8831442577030814, "label_mismatch_greedy": 0.09958333333333333, "mse_greedy_sem": 2.5566761806002645, "r2_greedy_sem": 0.030349751282878826, "weight_mismatch_greedy_sem": 1.67130505545701, "refit-weight_mismatch_greedy_sem": 1.7469973753616863, "rand_score_greedy_sem": 0.04684710627924254, "label_mismatch_greedy_sem": 0.040862748982245, "mse_ground_truth": 2.776818365613562, "r2_ground_truth": 0.9680471371454366, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 83.91352763823791, "r2_baseline_sklearn": 0.003880843645103993, "mse_milp_val": 3.385574041631402, "r2_milp_val": 0.9627224758603021, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 3.387023052731275, "r2_refit_milp_assignment_val": 0.9627065212406158, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 13.86203477611534, "label_mismatch_greedy_val": 0.090625, "mse_greedy_val_sem": 4.204439057858598, "label_mismatch_greedy_val_sem": 0.03679015663190359, "r2_greedy_val": 0.8473693590399314, "r2_greedy_val_sem": 0.046293797313523996, "mse_refit_ground_truth_assignment_val": 3.387023052731275, "r2_refit_ground_truth_assignment_val": 0.9627065212406158, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 2.9480439852893197, "r2_ground_truth_val": 0.9675399859890353, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 90.95805618271484, "r2_baseline_sklearn_val": -0.0015114404106426615, "random_state": 8}