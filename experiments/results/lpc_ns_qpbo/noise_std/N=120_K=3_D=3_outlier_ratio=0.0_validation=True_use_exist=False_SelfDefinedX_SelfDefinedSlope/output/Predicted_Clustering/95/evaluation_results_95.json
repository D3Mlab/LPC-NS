{"time_milp": 3753.8087797164917, "time_greedy": 0.5806190729141235, "time_refit_milp_assignment": 3761.399025440216, "mse_refit_ground_truth_assignment": 1.780199686123876, "r2_refit_ground_truth_assignment": 0.9844063723287833, "weight_mismatch_refit_ground_truth_assignment": 1.9036816680888633, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 9.705245278933608, "r2_milp": 0.9149870755976567, "weight_mismatch_milp": 6.208236084099941, "refit-weight_mismatch_milp": 6.655093939943436, "rand_score_milp": 0.7574334898278561, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 11.476084836289127, "r2_refit_milp_assignment": 0.8994754378088706, "weight_mismatch_refit_milp_assignment": 7.115338713529362, "refit-weight_mismatch_refit_milp_assignment": 6.341703588864782, "rand_score_refit_milp_assignment": 0.7574334898278561, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 114.28273575601676, "r2_greedy": -0.001057602985872208, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.308388098259247, "rand_score_greedy": 0.9103286384976524, "label_mismatch_greedy": 0.07499999999999998, "mse_greedy_sem": 0.0, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.288704698705366e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 0.0031259756424785864, "label_mismatch_greedy_sem": 0.0029203193502102594, "mse_ground_truth": 2.0705388677552294, "r2_ground_truth": 0.9814797986606001, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.93389244685628, "r2_baseline_sklearn": 0.028276530762907814, "mse_milp_val": 10.515807065995794, "r2_milp_val": 0.9024254267891039, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 13.15415217556592, "r2_refit_milp_assignment_val": 0.8779446240857326, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 109.31975710243867, "label_mismatch_greedy_val": 0.16666666666666663, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 6.367565748859375e-18, "r2_greedy_val": -0.014361387180813034, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 2.0137883016897686, "r2_refit_ground_truth_assignment_val": 0.9813143648565154, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 2.0551898567443754, "r2_ground_truth_val": 0.9809302061286719, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 108.57972570569764, "r2_baseline_sklearn_val": -0.00749474848665499}