{"time_milp": 18126.45106267929, "time_greedy": 0.7024737000465393, "time_refit_milp_assignment": 18138.64196920395, "mse_refit_ground_truth_assignment": 1.7303409765702757, "r2_refit_ground_truth_assignment": 0.9845909643660895, "weight_mismatch_refit_ground_truth_assignment": 1.7724914756296835, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.244071466679669, "r2_milp": 0.9443952833380507, "weight_mismatch_milp": 27.431234991733092, "refit-weight_mismatch_milp": 26.385366898843372, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4861111111111111, "mse_refit_milp_assignment": 6.646590074582768, "r2_refit_milp_assignment": 0.940810773893684, "weight_mismatch_refit_milp_assignment": 25.124907264508145, "refit-weight_mismatch_refit_milp_assignment": 24.033972274339263, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4861111111111111, "mse_greedy": 112.58744075355908, "r2_greedy": -0.002613883617939239, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.890784815616332, "rand_score_greedy": 0.8877151799687011, "label_mismatch_greedy": 0.09722222222222224, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.2089121657132306e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 2.2007365372477987, "r2_ground_truth": 0.9809426437393735, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.80857251792428, "r2_baseline_sklearn": 0.0043220952206398655, "mse_milp_val": 10.32876504919963, "r2_milp_val": 0.9141110141384184, "label_mismatch_milp_val": 0.4583333333333333, "mse_refit_milp_assignment_val": 9.350080929879638, "r2_refit_milp_assignment_val": 0.9222492752070776, "label_mismatch_refit_milp_assignment_val": 0.4583333333333333, "mse_greedy_val": 120.59788664888454, "label_mismatch_greedy_val": 0.0625, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.0028333621670775244, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 2.9670918923068164, "r2_refit_ground_truth_assignment_val": 0.9753271071251542, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 2.9820116932046528, "r2_ground_truth_val": 0.9752030413184225, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 120.25748700185049, "r2_baseline_sklearn_val": -2.7642851303522065e-06}