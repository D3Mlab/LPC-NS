{"time_milp": 4085.9247436523438, "time_greedy": 0.5933316111564636, "time_refit_milp_assignment": 4094.1139204502106, "mse_refit_ground_truth_assignment": 0.9299020858290667, "r2_refit_ground_truth_assignment": 0.9919373458638825, "weight_mismatch_refit_ground_truth_assignment": 1.120784575138204, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.5629593000455015, "r2_milp": 0.9517667316881252, "weight_mismatch_milp": 4.5652723483374515, "refit-weight_mismatch_milp": 4.061888445213558, "rand_score_milp": 0.7746478873239436, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 6.39928420332706, "r2_refit_milp_assignment": 0.9445154322843075, "weight_mismatch_refit_milp_assignment": 3.225239866456783, "refit-weight_mismatch_refit_milp_assignment": 2.463727573503603, "rand_score_refit_milp_assignment": 0.7746478873239436, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 115.97699695761567, "r2_greedy": -0.005570832095861178, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.37059550968677, "rand_score_greedy": 0.8748043818466353, "label_mismatch_greedy": 0.11111111111111112, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.363836858469928e-15, "refit-weight_mismatch_greedy_sem": 7.514375104812096e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 1.0349658056917446, "r2_ground_truth": 0.9909750947914672, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 107.83709703571071, "r2_baseline_sklearn": 0.06500562834343049, "mse_milp_val": 7.524634809102622, "r2_milp_val": 0.9337179484030016, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 8.452440072524455, "r2_refit_milp_assignment_val": 0.9255452147219332, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 113.59619245501388, "label_mismatch_greedy_val": 0.02083333333333333, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 7.959457186074219e-19, "r2_greedy_val": -0.0006317755670239844, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 1.3487279020432918, "r2_refit_ground_truth_assignment_val": 0.9881194962065931, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 1.3749106892700391, "r2_ground_truth_val": 0.987888860581351, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 113.8169211664793, "r2_baseline_sklearn_val": -0.0025761027288673244}