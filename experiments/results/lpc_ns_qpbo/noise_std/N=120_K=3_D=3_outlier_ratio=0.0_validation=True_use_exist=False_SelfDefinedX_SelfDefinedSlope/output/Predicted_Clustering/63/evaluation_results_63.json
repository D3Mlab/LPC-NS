{"time_milp": 7133.632564306259, "time_greedy": 0.6662071466445922, "time_refit_milp_assignment": 7145.714193582535, "mse_refit_ground_truth_assignment": 0.8988095078548359, "r2_refit_ground_truth_assignment": 0.9918935753665921, "weight_mismatch_refit_ground_truth_assignment": 1.3057679168858565, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.085748780088042, "r2_milp": 0.9451122141093266, "weight_mismatch_milp": 17.42936825379375, "refit-weight_mismatch_milp": 18.21780490954802, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4444444444444444, "mse_refit_milp_assignment": 6.83929115847081, "r2_refit_milp_assignment": 0.9383159636857881, "weight_mismatch_refit_milp_assignment": 15.116038326253744, "refit-weight_mismatch_refit_milp_assignment": 15.859267881135345, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4444444444444444, "mse_greedy": 111.23385566933567, "r2_greedy": -0.0032257778613475896, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.610760873352962, "rand_score_greedy": 0.9311424100156496, "label_mismatch_greedy": 0.05555555555555556, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4693494276736472e-15, "refit-weight_mismatch_greedy_sem": 6.313337881910559e-16, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 1.5918914372148438e-18, "mse_ground_truth": 0.8002855248618094, "r2_ground_truth": 0.9928060796475773, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 105.65015709775506, "r2_baseline_sklearn": 0.04713398274489633, "mse_milp_val": 7.081170283374483, "r2_milp_val": 0.9366251412247789, "label_mismatch_milp_val": 0.3541666666666667, "mse_refit_milp_assignment_val": 6.622004738933306, "r2_refit_milp_assignment_val": 0.9407345681088815, "label_mismatch_refit_milp_assignment_val": 0.3541666666666667, "mse_greedy_val": 112.58385478679345, "label_mismatch_greedy_val": 0.0625, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.007599819232549931, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 1.1435282095393327, "r2_refit_ground_truth_assignment_val": 0.9897656833708424, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 0.9910157426450676, "r2_ground_truth_val": 0.9911306351604607, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 111.8431886210077, "r2_baseline_sklearn_val": -0.0009710259995352466}