{"time_milp": 18107.263053655624, "time_greedy": 0.5987902998924255, "time_refit_milp_assignment": 18118.00237584114, "mse_refit_ground_truth_assignment": 5.967910715109727, "r2_refit_ground_truth_assignment": 0.949325226363006, "weight_mismatch_refit_ground_truth_assignment": 3.2917698833122646, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 9.938858562405214, "r2_milp": 0.9156070806178735, "weight_mismatch_milp": 17.82703048770457, "refit-weight_mismatch_milp": 17.479190648451432, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4861111111111111, "mse_refit_milp_assignment": 11.077748483206596, "r2_refit_milp_assignment": 0.9059365289475972, "weight_mismatch_refit_milp_assignment": 18.071606978497652, "refit-weight_mismatch_refit_milp_assignment": 17.747662025827935, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4861111111111111, "mse_greedy": 117.91793321304215, "r2_greedy": -0.0012657458470743954, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 24.807750132790336, "rand_score_greedy": 0.8309859154929577, "label_mismatch_greedy": 0.16666666666666663, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.3268026938822534e-15, "refit-weight_mismatch_greedy_sem": 1.4350408191326673e-15, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 6.367565748859375e-18, "mse_ground_truth": 7.590295403977103, "r2_ground_truth": 0.9380114183228507, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.05044161474032, "r2_baseline_sklearn": 0.006100306105519482, "mse_milp_val": 18.33054531944695, "r2_milp_val": 0.8583897647993307, "label_mismatch_milp_val": 0.4791666666666667, "mse_refit_milp_assignment_val": 16.118120078393265, "r2_refit_milp_assignment_val": 0.8754815672138025, "label_mismatch_refit_milp_assignment_val": 0.4791666666666667, "mse_greedy_val": 129.76560133414188, "label_mismatch_greedy_val": 0.0625, "mse_greedy_val_sem": 1.3040774653664e-14, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.002487214954199457, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 11.780684835305335, "r2_refit_ground_truth_assignment_val": 0.908989857023911, "label_mismatch_refit_ground_truth_assignment_val": 0.2708333333333333, "mse_ground_truth_val": 12.581050938903617, "r2_ground_truth_val": 0.9028067331614171, "label_mismatch_ground_truth_val": 0.2708333333333333, "mse_baseline_sklearn_val": 129.47463972597598, "r2_baseline_sklearn_val": -0.00023942902919382725}