{"time_milp": 6630.072613954544, "time_greedy": 0.5321119904518128, "time_refit_milp_assignment": 6636.992231607437, "mse_refit_ground_truth_assignment": 1.9805197830925734, "r2_refit_ground_truth_assignment": 0.9835457090421825, "weight_mismatch_refit_ground_truth_assignment": 3.6192534400128076, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 7.156904632205005, "r2_milp": 0.9405399571461144, "weight_mismatch_milp": 4.965224090227965, "refit-weight_mismatch_milp": 6.293061212067453, "rand_score_milp": 0.7574334898278561, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 7.875218511557083, "r2_refit_milp_assignment": 0.9345721573438616, "weight_mismatch_refit_milp_assignment": 2.533892758064185, "refit-weight_mismatch_refit_milp_assignment": 3.5728193595546838, "rand_score_refit_milp_assignment": 0.7574334898278561, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 121.4462308940621, "r2_greedy": -0.008983417343512379, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 24.736191680402676, "rand_score_greedy": 0.9014084507042253, "label_mismatch_greedy": 0.08333333333333331, "mse_greedy_sem": 6.520387326832e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.363836858469928e-15, "refit-weight_mismatch_greedy_sem": 0.0, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 1.9152087576773515, "r2_ground_truth": 0.9831599866193781, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 112.24153959736964, "r2_baseline_sklearn": 0.06748977422247604, "mse_milp_val": 8.92739583455632, "r2_milp_val": 0.9137735464969052, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 9.781656604634543, "r2_refit_milp_assignment_val": 0.9055225539414342, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 103.69771700807205, "label_mismatch_greedy_val": 0.0625, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.0015783482303692864, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 1.9089472075105274, "r2_refit_ground_truth_assignment_val": 0.9815621766214145, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 1.6464819639265917, "r2_ground_truth_val": 0.9840972324810938, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 103.95077555884649, "r2_baseline_sklearn_val": -0.004022548282242244}