{"time_milp": 18120.133340597153, "time_greedy": 0.5749081015586853, "time_refit_milp_assignment": 18130.836369276047, "mse_refit_ground_truth_assignment": 1.068220704923486, "r2_refit_ground_truth_assignment": 0.9904067662455465, "weight_mismatch_refit_ground_truth_assignment": 1.3926718737090376, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.695613312102097, "r2_milp": 0.9488501302903631, "weight_mismatch_milp": 27.06625921466654, "refit-weight_mismatch_milp": 26.24610942676349, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4861111111111111, "mse_refit_milp_assignment": 6.120375319171875, "r2_refit_milp_assignment": 0.9450355241841062, "weight_mismatch_refit_milp_assignment": 25.697567334120954, "refit-weight_mismatch_refit_milp_assignment": 24.83126201915998, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4861111111111111, "mse_greedy": 111.6886848089679, "r2_greedy": -0.0030283593657354224, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.677124111443806, "rand_score_greedy": 0.8877151799687011, "label_mismatch_greedy": 0.09722222222222224, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.2494455620143562e-15, "refit-weight_mismatch_greedy_sem": 1.0309637589642927e-15, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 1.3586179643213454, "r2_ground_truth": 0.9881073384295981, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.89714543581933, "r2_baseline_sklearn": 0.004080117559930985, "mse_milp_val": 9.092044544806262, "r2_milp_val": 0.9233210095506518, "label_mismatch_milp_val": 0.4583333333333333, "mse_refit_milp_assignment_val": 8.624042980024145, "r2_refit_milp_assignment_val": 0.92726796420308, "label_mismatch_refit_milp_assignment_val": 0.4583333333333333, "mse_greedy_val": 118.91833508154055, "label_mismatch_greedy_val": 0.04166666666666666, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 1.5918914372148438e-18, "r2_greedy_val": -0.002913902921726219, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 1.9739647619542768, "r2_refit_ground_truth_assignment_val": 0.9833523005322597, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 2.002882054965284, "r2_ground_truth_val": 0.9831084226207861, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 118.57152256632014, "r2_baseline_sklearn_val": 1.098744932803708e-05}