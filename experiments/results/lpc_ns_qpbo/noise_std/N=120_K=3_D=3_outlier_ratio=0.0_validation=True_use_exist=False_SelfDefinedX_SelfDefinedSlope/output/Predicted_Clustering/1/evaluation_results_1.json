{"time_milp": 3535.417248725891, "time_greedy": 0.5708339929580688, "time_refit_milp_assignment": 3546.0178711414337, "mse_refit_ground_truth_assignment": 0.06916627084679045, "r2_refit_ground_truth_assignment": 0.9993888553810183, "weight_mismatch_refit_ground_truth_assignment": 0.3056685204922358, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.2441938528671255, "r2_milp": 0.9624988277763257, "weight_mismatch_milp": 11.664591988363046, "refit-weight_mismatch_milp": 11.504417283430751, "rand_score_milp": 0.775039123630673, "label_mismatch_milp": 0.3194444444444444, "mse_refit_milp_assignment": 4.713027921397001, "r2_refit_milp_assignment": 0.9583562679032916, "weight_mismatch_refit_milp_assignment": 3.3694309360221695, "refit-weight_mismatch_refit_milp_assignment": 3.1719890595400733, "rand_score_refit_milp_assignment": 0.775039123630673, "label_mismatch_refit_milp_assignment": 0.3194444444444444, "mse_greedy": 113.8734921423566, "r2_greedy": -0.0061720997161618385, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.06446041095434, "rand_score_greedy": 0.8748043818466353, "label_mismatch_greedy": 0.11111111111111112, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4350408191326673e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 0.07698092769608018, "r2_ground_truth": 0.9993132840449835, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 105.6000807124676, "r2_baseline_sklearn": 0.06693074093283169, "mse_milp_val": 6.344360650985315, "r2_milp_val": 0.9425123022841961, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 7.175640501982197, "r2_refit_milp_assignment_val": 0.9349798861085921, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 110.50081534955136, "label_mismatch_greedy_val": 0.04166666666666666, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 1.5918914372148438e-18, "r2_greedy_val": -0.001273070625060324, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.0913023435583541, "r2_refit_ground_truth_assignment_val": 0.9991726886575384, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.08643972864633735, "r2_ground_truth_val": 0.9992167499194289, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 110.5794112552547, "r2_baseline_sklearn_val": -0.0019852460383658066}