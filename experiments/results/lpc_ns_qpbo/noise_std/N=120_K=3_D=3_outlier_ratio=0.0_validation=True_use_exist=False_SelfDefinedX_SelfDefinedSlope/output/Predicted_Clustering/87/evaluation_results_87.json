{"time_milp": 2958.38587975502, "time_greedy": 0.5986521244049072, "time_refit_milp_assignment": 2970.0027244091034, "mse_refit_ground_truth_assignment": 4.36719940472028, "r2_refit_ground_truth_assignment": 0.9611846100359611, "weight_mismatch_refit_ground_truth_assignment": 4.2775064194583665, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 10.865711428213542, "r2_milp": 0.9034262493562883, "weight_mismatch_milp": 17.12915945797502, "refit-weight_mismatch_milp": 15.45613355414393, "rand_score_milp": 0.7198748043818466, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 11.575921255344534, "r2_refit_milp_assignment": 0.8971139496782414, "weight_mismatch_refit_milp_assignment": 16.719460839379202, "refit-weight_mismatch_refit_milp_assignment": 15.366586163755855, "rand_score_refit_milp_assignment": 0.7198748043818466, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 112.95644219503167, "r2_greedy": -0.0039496589076390975, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.635909402401392, "rand_score_greedy": 0.8712832550860721, "label_mismatch_greedy": 0.11527777777777778, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 1.1669717376104429e-15, "rand_score_greedy_sem": 0.0018861528422986365, "label_mismatch_greedy_sem": 0.0022754945053031265, "mse_ground_truth": 5.026329368154601, "r2_ground_truth": 0.9568257143628767, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 112.38435264433512, "r2_baseline_sklearn": 0.0011350365566065168, "mse_milp_val": 9.116454161620497, "r2_milp_val": 0.9254100384262413, "label_mismatch_milp_val": 0.3958333333333333, "mse_refit_milp_assignment_val": 9.751432912441425, "r2_refit_milp_assignment_val": 0.9202147026318399, "label_mismatch_refit_milp_assignment_val": 0.3958333333333333, "mse_greedy_val": 123.18574313129334, "label_mismatch_greedy_val": 0.20833333333333334, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.007894043418827934, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 7.18966827125785, "r2_refit_ground_truth_assignment_val": 0.9411748174702752, "label_mismatch_refit_ground_truth_assignment_val": 0.16666666666666666, "mse_ground_truth_val": 4.606141758683177, "r2_ground_truth_val": 0.9623129858723063, "label_mismatch_ground_truth_val": 0.16666666666666666, "mse_baseline_sklearn_val": 122.32084341277043, "r2_baseline_sklearn_val": -0.0008175161170869139}