{"time_milp": 3281.680207490921, "time_greedy": 0.5077977895736694, "time_refit_milp_assignment": 3288.467309951782, "mse_refit_ground_truth_assignment": 3.0067491227625185, "r2_refit_ground_truth_assignment": 0.9739979716850109, "weight_mismatch_refit_ground_truth_assignment": 2.562374481138743, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 8.122370277372482, "r2_milp": 0.9297586551740564, "weight_mismatch_milp": 5.9801278128928, "refit-weight_mismatch_milp": 5.0615911730384555, "rand_score_milp": 0.7656494522691706, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 9.172083409579166, "r2_refit_milp_assignment": 0.9206808540433866, "weight_mismatch_refit_milp_assignment": 3.3892979444, "refit-weight_mismatch_refit_milp_assignment": 1.7273030656756874, "rand_score_refit_milp_assignment": 0.7656494522691706, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 115.77767716007229, "r2_greedy": -0.001232333276261599, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 22.157861006100298, "rand_score_greedy": 0.8827856025039124, "label_mismatch_greedy": 0.10000000000000002, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 6.81918429234964e-16, "rand_score_greedy_sem": 0.0017771641356170225, "label_mismatch_greedy_sem": 0.001911797782254681, "mse_ground_truth": 3.356025610130487, "r2_ground_truth": 0.9710088756309849, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.82629669037125, "r2_baseline_sklearn": 0.04158664825990399, "mse_milp_val": 5.411276327905537, "r2_milp_val": 0.9533253793002717, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 6.613392086139484, "r2_refit_milp_assignment_val": 0.9429566060843505, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 116.20665698452108, "label_mismatch_greedy_val": 0.17291666666666664, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.004301545010073032, "r2_greedy_val": -0.0023331482011559324, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 4.969799747135922, "r2_refit_ground_truth_assignment_val": 0.957133307542445, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 3.344889043033548, "r2_ground_truth_val": 0.9711488717437766, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 115.9628386600329, "r2_baseline_sklearn_val": -0.00023010871000250788}