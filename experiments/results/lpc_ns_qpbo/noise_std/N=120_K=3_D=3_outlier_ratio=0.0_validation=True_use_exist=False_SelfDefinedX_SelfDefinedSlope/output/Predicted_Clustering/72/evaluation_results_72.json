{"time_milp": 18176.35951280594, "time_greedy": 0.7208442330360413, "time_refit_milp_assignment": 18188.51380252838, "mse_refit_ground_truth_assignment": 0.26384810461133557, "r2_refit_ground_truth_assignment": 0.9977627685353482, "weight_mismatch_refit_ground_truth_assignment": 0.9724865373206582, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.359400936496384, "r2_milp": 0.9545563519416732, "weight_mismatch_milp": 24.301108844564226, "refit-weight_mismatch_milp": 24.913130890847647, "rand_score_milp": 0.7374804381846636, "label_mismatch_milp": 0.4027777777777778, "mse_refit_milp_assignment": 6.1208577219628495, "r2_refit_milp_assignment": 0.9480997769288353, "weight_mismatch_refit_milp_assignment": 22.845342749197624, "refit-weight_mismatch_refit_milp_assignment": 23.528173501470775, "rand_score_refit_milp_assignment": 0.7374804381846636, "label_mismatch_refit_milp_assignment": 0.4027777777777778, "mse_greedy": 118.10538282756954, "r2_greedy": -0.0014439140876623124, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.008482475785296, "rand_score_greedy": 0.947183098591549, "label_mismatch_greedy": 0.04166666666666666, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 7.290014651212247e-16, "rand_score_greedy_sem": 5.0940525990875e-17, "label_mismatch_greedy_sem": 1.5918914372148438e-18, "mse_ground_truth": 0.35857255035350094, "r2_ground_truth": 0.996829673968944, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 116.94789888097047, "r2_baseline_sklearn": 0.008370670364158506, "mse_milp_val": 6.313146730428335, "r2_milp_val": 0.940192689572523, "label_mismatch_milp_val": 0.4791666666666667, "mse_refit_milp_assignment_val": 7.220771616946888, "r2_refit_milp_assignment_val": 0.9315943462015246, "label_mismatch_refit_milp_assignment_val": 0.4791666666666667, "mse_greedy_val": 106.8016522546418, "label_mismatch_greedy_val": 0.08333333333333331, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 3.1837828744296875e-18, "r2_greedy_val": -0.01178062910751243, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.5153672566053803, "r2_refit_ground_truth_assignment_val": 0.9951176915702917, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.46882545217397187, "r2_ground_truth_val": 0.9955586032525862, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 106.0550012301657, "r2_baseline_sklearn_val": -0.004707264348444706}