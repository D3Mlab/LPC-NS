{"time_milp": 10459.682924509048, "time_greedy": 0.6345044255256653, "time_refit_milp_assignment": 10470.394620656967, "mse_refit_ground_truth_assignment": 0.39304794642482527, "r2_refit_ground_truth_assignment": 0.9963987507587957, "weight_mismatch_refit_ground_truth_assignment": 1.283251925837512, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.061951931314315, "r2_milp": 0.9444581761807066, "weight_mismatch_milp": 17.454738143866585, "refit-weight_mismatch_milp": 16.93500787897583, "rand_score_milp": 0.7257433489827856, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 6.8493927618092405, "r2_refit_milp_assignment": 0.9372433548870008, "weight_mismatch_refit_milp_assignment": 15.396082214434774, "refit-weight_mismatch_refit_milp_assignment": 14.81518713002086, "rand_score_refit_milp_assignment": 0.7257433489827856, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 109.44536480279494, "r2_greedy": -0.002778517314499407, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 22.472037734310977, "rand_score_greedy": 0.9311424100156496, "label_mismatch_greedy": 0.05555555555555556, "mse_greedy_sem": 0.0, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.363836858469928e-15, "refit-weight_mismatch_greedy_sem": 1.1669717376104429e-15, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 1.5918914372148438e-18, "mse_ground_truth": 0.4523696431339141, "r2_ground_truth": 0.9959560213171762, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.07803753763274, "r2_baseline_sklearn": 0.0005870696246300655, "mse_milp_val": 5.664564056896094, "r2_milp_val": 0.9511032231066846, "label_mismatch_milp_val": 0.3958333333333333, "mse_refit_milp_assignment_val": 5.729508184135113, "r2_refit_milp_assignment_val": 0.9505426224199872, "label_mismatch_refit_milp_assignment_val": 0.3958333333333333, "mse_greedy_val": 116.75015874036337, "label_mismatch_greedy_val": 0.125, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.007792728062958831, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.7781127934468134, "r2_refit_ground_truth_assignment_val": 0.9932832946583623, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 0.5739259375768268, "r2_ground_truth_val": 0.9950458449686315, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 116.00740575806476, "r2_baseline_sklearn_val": -0.001381250233860376}