{"time_milp": 18214.635525226593, "time_greedy": 0.5478383421897888, "time_refit_milp_assignment": 18225.412358283997, "mse_refit_ground_truth_assignment": 4.954481075479519, "r2_refit_ground_truth_assignment": 0.9609516841811304, "weight_mismatch_refit_ground_truth_assignment": 4.214108328389517, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 10.780255414979646, "r2_milp": 0.9150363455548243, "weight_mismatch_milp": 14.5563644831161, "refit-weight_mismatch_milp": 13.642103849109521, "rand_score_milp": 0.7304381846635368, "label_mismatch_milp": 0.4027777777777778, "mse_refit_milp_assignment": 11.31297519433327, "r2_refit_milp_assignment": 0.9108377605021716, "weight_mismatch_refit_milp_assignment": 12.497531762345488, "refit-weight_mismatch_refit_milp_assignment": 13.703005883217072, "rand_score_refit_milp_assignment": 0.7304381846635368, "label_mismatch_refit_milp_assignment": 0.4027777777777778, "mse_greedy": 126.99966621479317, "r2_greedy": -0.0009369295585213155, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.50028608407282, "rand_score_greedy": 0.8877151799687011, "label_mismatch_greedy": 0.09722222222222224, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4693494276736472e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 6.733195667749073, "r2_ground_truth": 0.9456600485060339, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 125.03087224310713, "r2_baseline_sklearn": 0.014579950537996655, "mse_milp_val": 15.748481295176823, "r2_milp_val": 0.8674578473892609, "label_mismatch_milp_val": 0.4583333333333333, "mse_refit_milp_assignment_val": 15.957352705841515, "r2_refit_milp_assignment_val": 0.8656999466831896, "label_mismatch_refit_milp_assignment_val": 0.4583333333333333, "mse_greedy_val": 120.69868805488565, "label_mismatch_greedy_val": 0.125, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.015822645513516642, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 9.186310290612992, "r2_refit_ground_truth_assignment_val": 0.9226863011329907, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 8.60372489193483, "r2_ground_truth_val": 0.9275894483871985, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 119.8778240998217, "r2_baseline_sklearn_val": -0.00891410153613248}