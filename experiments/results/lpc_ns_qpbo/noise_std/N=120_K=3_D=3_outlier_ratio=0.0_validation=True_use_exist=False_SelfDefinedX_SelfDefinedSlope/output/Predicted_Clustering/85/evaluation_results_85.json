{"time_milp": 8391.060497522354, "time_greedy": 0.503508734703064, "time_refit_milp_assignment": 8400.570642232895, "mse_refit_ground_truth_assignment": 2.1399277083129378, "r2_refit_ground_truth_assignment": 0.9806243388168182, "weight_mismatch_refit_ground_truth_assignment": 2.9942544936208564, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 8.042966352948653, "r2_milp": 0.9271761422794405, "weight_mismatch_milp": 16.76806769745524, "refit-weight_mismatch_milp": 15.716855843427933, "rand_score_milp": 0.7257433489827856, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 8.304305702217217, "r2_refit_milp_assignment": 0.9248098835195813, "weight_mismatch_refit_milp_assignment": 15.752654504525546, "refit-weight_mismatch_refit_milp_assignment": 14.747342968181936, "rand_score_refit_milp_assignment": 0.7257433489827856, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 110.82472050642875, "r2_greedy": -0.0034461570415660336, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.942813798733816, "rand_score_greedy": 0.8986697965571204, "label_mismatch_greedy": 0.08611111111111111, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 0.0, "rand_score_greedy_sem": 0.0012565807019514366, "label_mismatch_greedy_sem": 0.0012745318548364548, "mse_ground_truth": 2.4629013903957544, "r2_ground_truth": 0.9783699911490027, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.3495200490274, "r2_baseline_sklearn": 0.0008564757160426373, "mse_milp_val": 6.476561137298643, "r2_milp_val": 0.9455395232226363, "label_mismatch_milp_val": 0.3958333333333333, "mse_refit_milp_assignment_val": 6.6939500629224495, "r2_refit_milp_assignment_val": 0.943711530822872, "label_mismatch_refit_milp_assignment_val": 0.3958333333333333, "mse_greedy_val": 119.86019807691484, "label_mismatch_greedy_val": 0.16666666666666663, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 6.367565748859375e-18, "r2_greedy_val": -0.007887271580777844, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 3.544158829076302, "r2_refit_ground_truth_assignment_val": 0.9701976750447684, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 2.272274643159038, "r2_ground_truth_val": 0.9808927673479555, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 119.0461696215085, "r2_baseline_sklearn_val": -0.001042222664855652}