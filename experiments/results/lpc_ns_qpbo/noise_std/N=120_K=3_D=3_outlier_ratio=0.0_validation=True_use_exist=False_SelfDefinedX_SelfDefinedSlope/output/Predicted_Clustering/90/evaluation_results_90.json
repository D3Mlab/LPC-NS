{"time_milp": 2227.159871816635, "time_greedy": 0.6353975892066955, "time_refit_milp_assignment": 2239.3409128189087, "mse_refit_ground_truth_assignment": 9.182036748424391, "r2_refit_ground_truth_assignment": 0.921767174330962, "weight_mismatch_refit_ground_truth_assignment": 6.202384308214626, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 14.750935202477486, "r2_milp": 0.874319023788625, "weight_mismatch_milp": 16.70085398619473, "refit-weight_mismatch_milp": 14.449019621929507, "rand_score_milp": 0.7147887323943662, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 16.448365390528565, "r2_refit_milp_assignment": 0.8598565724147564, "weight_mismatch_refit_milp_assignment": 19.734944900203775, "refit-weight_mismatch_refit_milp_assignment": 17.79732866776027, "rand_score_refit_milp_assignment": 0.7147887323943662, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 117.91738976327483, "r2_greedy": -0.004680208700021282, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.322518117684773, "rand_score_greedy": 0.8351330203442882, "label_mismatch_greedy": 0.1611111111111111, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 1.363836858469928e-15, "rand_score_greedy_sem": 0.0019743004057759437, "label_mismatch_greedy_sem": 0.0029203193502102586, "mse_ground_truth": 10.567857496545049, "r2_ground_truth": 0.913337702466464, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.1742776811995, "r2_baseline_sklearn": 0.0016512577885581248, "mse_milp_val": 14.069374100934645, "r2_milp_val": 0.8907353444487929, "label_mismatch_milp_val": 0.375, "mse_refit_milp_assignment_val": 20.77976497376361, "r2_refit_milp_assignment_val": 0.8386215444976698, "label_mismatch_refit_milp_assignment_val": 0.375, "mse_greedy_val": 129.7699785642332, "label_mismatch_greedy_val": 0.1875, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.0026178369268230976, "r2_greedy_val": -0.00781114404844252, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 15.629165808039621, "r2_refit_ground_truth_assignment_val": 0.8786217918212362, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 10.573311885920186, "r2_ground_truth_val": 0.9178862348131175, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 128.83292696450476, "r2_baseline_sklearn_val": -0.0005338750282637417}