{"time_milp": 1080.8692169189453, "time_greedy": 0.5602108359336853, "time_refit_milp_assignment": 1088.3410727977753, "mse_refit_ground_truth_assignment": 5.50370341156184, "r2_refit_ground_truth_assignment": 0.9537177038398033, "weight_mismatch_refit_ground_truth_assignment": 3.466741945070063, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 10.285359679140917, "r2_milp": 0.9135073191291283, "weight_mismatch_milp": 6.060488691822024, "refit-weight_mismatch_milp": 4.84520975880579, "rand_score_milp": 0.7656494522691706, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 11.31722813679071, "r2_refit_milp_assignment": 0.9048300271342531, "weight_mismatch_refit_milp_assignment": 4.967364787045927, "refit-weight_mismatch_refit_milp_assignment": 3.1132089399786294, "rand_score_refit_milp_assignment": 0.7656494522691706, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 118.99749385609111, "r2_greedy": -0.000685691274539435, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.942347425551297, "rand_score_greedy": 0.8720657276995306, "label_mismatch_greedy": 0.11111111111111112, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 0.0, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 6.14303649743608, "r2_ground_truth": 0.9483212311247168, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.85566777050114, "r2_baseline_sklearn": 0.04255346968707319, "mse_milp_val": 7.250441177526459, "r2_milp_val": 0.9389615270631434, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 7.894644749383588, "r2_refit_milp_assignment_val": 0.9335382429727204, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 118.98341839598075, "label_mismatch_greedy_val": 0.22916666666666669, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 6.367565748859375e-18, "r2_greedy_val": -0.0016723101221594039, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 8.064376989651572, "r2_refit_ground_truth_assignment_val": 0.9321093372688547, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 5.295060758235091, "r2_ground_truth_val": 0.9554230680758647, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 118.81730145404968, "r2_baseline_sklearn_val": -0.0002738401234174681}