{"time_milp": 18149.413363695145, "time_greedy": 0.6778233170509338, "time_refit_milp_assignment": 18161.605260372162, "mse_refit_ground_truth_assignment": 0.06596202615283389, "r2_refit_ground_truth_assignment": 0.999436890180975, "weight_mismatch_refit_ground_truth_assignment": 0.48624326866032586, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.208628730166483, "r2_milp": 0.9555345681041306, "weight_mismatch_milp": 24.50134769730206, "refit-weight_mismatch_milp": 24.792047379585313, "rand_score_milp": 0.7374804381846636, "label_mismatch_milp": 0.4027777777777778, "mse_refit_milp_assignment": 5.780000748745493, "r2_refit_milp_assignment": 0.9506568344633767, "weight_mismatch_refit_milp_assignment": 23.41979598754865, "refit-weight_mismatch_refit_milp_assignment": 23.759685768949044, "rand_score_refit_milp_assignment": 0.7374804381846636, "label_mismatch_refit_milp_assignment": 0.4027777777777778, "mse_greedy": 117.31762566644852, "r2_greedy": -0.001526344936823243, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 22.976736090478244, "rand_score_greedy": 0.947183098591549, "label_mismatch_greedy": 0.04166666666666666, "mse_greedy_sem": 0.0, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4693494276736472e-15, "refit-weight_mismatch_greedy_sem": 6.81918429234964e-16, "rand_score_greedy_sem": 5.0940525990875e-17, "label_mismatch_greedy_sem": 1.5918914372148438e-18, "mse_ground_truth": 0.08964313758837524, "r2_ground_truth": 0.999200816771906, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 116.22670839344076, "r2_baseline_sklearn": 0.007786683543400841, "mse_milp_val": 5.697243838004044, "r2_milp_val": 0.9454581148661327, "label_mismatch_milp_val": 0.4583333333333333, "mse_refit_milp_assignment_val": 6.408628855897717, "r2_refit_milp_assignment_val": 0.9386477551491957, "label_mismatch_refit_milp_assignment_val": 0.4583333333333333, "mse_greedy_val": 105.61567900127197, "label_mismatch_greedy_val": 0.08333333333333331, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 3.1837828744296875e-18, "r2_greedy_val": -0.01109912024423343, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.12884181415134452, "r2_refit_ground_truth_assignment_val": 0.9987665482419753, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.11720636304349293, "r2_ground_truth_val": 0.9988779388469502, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 104.8869182939203, "r2_baseline_sklearn_val": -0.004122416434347631}