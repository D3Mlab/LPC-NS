{"time_milp": 3382.9035391807556, "time_greedy": 0.7626933455467224, "time_refit_milp_assignment": 3397.0209546089172, "mse_refit_ground_truth_assignment": 5.775621212742569, "r2_refit_ground_truth_assignment": 0.949290773930099, "weight_mismatch_refit_ground_truth_assignment": 4.91913238237712, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 11.951273578013762, "r2_milp": 0.8950693247760693, "weight_mismatch_milp": 17.2659487714431, "refit-weight_mismatch_milp": 15.213942928381568, "rand_score_milp": 0.7147887323943662, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 13.733722448729926, "r2_refit_milp_assignment": 0.8794196484185255, "weight_mismatch_refit_milp_assignment": 18.699780995497733, "refit-weight_mismatch_refit_milp_assignment": 16.923140260900716, "rand_score_refit_milp_assignment": 0.7147887323943662, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 114.37497604640085, "r2_greedy": -0.004197869534865006, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.511816399173266, "rand_score_greedy": 0.8648669796557119, "label_mismatch_greedy": 0.12361111111111109, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4693494276736472e-15, "refit-weight_mismatch_greedy_sem": 4.07524207927e-16, "rand_score_greedy_sem": 0.0040575562323831495, "label_mismatch_greedy_sem": 0.0051279122535952, "mse_ground_truth": 6.647320589384458, "r2_ground_truth": 0.943683528029697, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.74930417076953, "r2_baseline_sklearn": 0.0012954506498052965, "mse_milp_val": 11.23039099421772, "r2_milp_val": 0.9095703942354649, "label_mismatch_milp_val": 0.3958333333333333, "mse_refit_milp_assignment_val": 18.499704113031818, "r2_refit_milp_assignment_val": 0.8510362684110138, "label_mismatch_refit_milp_assignment_val": 0.3958333333333333, "mse_greedy_val": 125.16769922875702, "label_mismatch_greedy_val": 0.225, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 0.0019117977822546797, "r2_greedy_val": -0.007878149704515058, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 9.795027068605668, "r2_refit_ground_truth_assignment_val": 0.9211282637689979, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 6.387399627003713, "r2_ground_truth_val": 0.9485672377366128, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 124.27819488136966, "r2_baseline_sklearn_val": -0.000715662886247248}