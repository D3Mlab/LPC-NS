{"time_milp": 18229.683659553528, "time_greedy": 0.5837874293327332, "time_refit_milp_assignment": 18240.464958429337, "mse_refit_ground_truth_assignment": 0.5936582353755051, "r2_refit_ground_truth_assignment": 0.9950059743623358, "weight_mismatch_refit_ground_truth_assignment": 1.4587298059809894, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.628295370143285, "r2_milp": 0.9526531433408604, "weight_mismatch_milp": 15.490248148830384, "refit-weight_mismatch_milp": 15.884248533377411, "rand_score_milp": 0.7374804381846636, "label_mismatch_milp": 0.4027777777777778, "mse_refit_milp_assignment": 5.9809507799149495, "r2_refit_milp_assignment": 0.9496865035257037, "weight_mismatch_refit_milp_assignment": 16.84979249601135, "refit-weight_mismatch_refit_milp_assignment": 17.32034718188017, "rand_score_refit_milp_assignment": 0.7374804381846636, "label_mismatch_refit_milp_assignment": 0.4027777777777778, "mse_greedy": 119.03567529659385, "r2_greedy": -0.001362701305463787, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.051336498335, "rand_score_greedy": 0.9380281690140844, "label_mismatch_greedy": 0.049999999999999996, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4350408191326673e-15, "refit-weight_mismatch_greedy_sem": 7.058526334438275e-16, "rand_score_greedy_sem": 0.004200569775094787, "label_mismatch_greedy_sem": 0.003823595564509362, "mse_ground_truth": 0.806788238295377, "r2_ground_truth": 0.9929363031132942, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.79724298157605, "r2_baseline_sklearn": 0.009055351309941284, "mse_milp_val": 7.139944439447741, "r2_milp_val": 0.9332037399326875, "label_mismatch_milp_val": 0.4791666666666667, "mse_refit_milp_assignment_val": 7.643226654439242, "r2_refit_milp_assignment_val": 0.9284953882074147, "label_mismatch_refit_milp_assignment_val": 0.4791666666666667, "mse_greedy_val": 108.22203823409859, "label_mismatch_greedy_val": 0.0875, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0019117977822546816, "r2_greedy_val": -0.012448692312039933, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 1.2543675541229657, "r2_refit_ground_truth_assignment_val": 0.9882650261391002, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 1.1733574429276123, "r2_ground_truth_val": 0.989022899327243, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 107.4592599475075, "r2_baseline_sklearn_val": -0.005312679246820995}