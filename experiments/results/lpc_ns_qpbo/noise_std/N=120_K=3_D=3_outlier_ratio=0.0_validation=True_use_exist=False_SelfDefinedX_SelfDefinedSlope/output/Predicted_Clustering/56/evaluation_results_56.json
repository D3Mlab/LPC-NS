{"time_milp": 12879.81704735756, "time_greedy": 0.6653835296630859, "time_refit_milp_assignment": 12888.768720149994, "mse_refit_ground_truth_assignment": 2.9202562107844576, "r2_refit_ground_truth_assignment": 0.9760015896770274, "weight_mismatch_refit_ground_truth_assignment": 4.394807748586976, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 7.653700527720517, "r2_milp": 0.9371025579621837, "weight_mismatch_milp": 4.7501089376949395, "refit-weight_mismatch_milp": 6.296240180859748, "rand_score_milp": 0.7574334898278561, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 8.323634431682176, "r2_refit_milp_assignment": 0.9315970996886358, "weight_mismatch_refit_milp_assignment": 2.554020159125652, "refit-weight_mismatch_refit_milp_assignment": 3.817603150971335, "rand_score_refit_milp_assignment": 0.7574334898278561, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 122.84686222698788, "r2_greedy": -0.00954477751833549, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 25.20058181064121, "rand_score_greedy": 0.8804381846635367, "label_mismatch_greedy": 0.10555555555555556, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.5028750209624192e-15, "refit-weight_mismatch_greedy_sem": 4.464204028220871e-16, "rand_score_greedy_sem": 0.003338914436613812, "label_mismatch_greedy_sem": 0.003823595564509363, "mse_ground_truth": 2.823955770248749, "r2_ground_truth": 0.9753841821603813, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.34510818564951, "r2_baseline_sklearn": 0.06853980678282978, "mse_milp_val": 10.368299630484865, "r2_milp_val": 0.9003092641970637, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 10.861349055206908, "r2_refit_milp_assignment_val": 0.8955686160976167, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 104.1699912389269, "label_mismatch_greedy_val": 0.09166666666666665, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.003823595564509363, "r2_greedy_val": -0.0015897924728869306, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 3.7594661698769536, "r2_refit_ground_truth_assignment_val": 0.9638529014343546, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 3.1776850855260306, "r2_ground_truth_val": 0.9694467004604407, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 104.46778425727943, "r2_baseline_sklearn_val": -0.00445305898471271}