{"time_milp": 5493.083042621613, "time_greedy": 0.5294982194900513, "time_refit_milp_assignment": 5499.956259250641, "mse_refit_ground_truth_assignment": 0.333888067185933, "r2_refit_ground_truth_assignment": 0.9970354604242881, "weight_mismatch_refit_ground_truth_assignment": 1.0942073558301384, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.955518483923194, "r2_milp": 0.9560007316596291, "weight_mismatch_milp": 4.671641692858751, "refit-weight_mismatch_milp": 4.822999118422215, "rand_score_milp": 0.7746478873239436, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 5.315088890214596, "r2_refit_milp_assignment": 0.9528081626388498, "weight_mismatch_refit_milp_assignment": 5.751440812027452, "refit-weight_mismatch_refit_milp_assignment": 5.471719318901806, "rand_score_refit_milp_assignment": 0.7746478873239436, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 113.0888154043748, "r2_greedy": -0.004097785411244503, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.384061384435153, "rand_score_greedy": 0.9014084507042253, "label_mismatch_greedy": 0.08333333333333331, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 0.37561230787383754, "r2_ground_truth": 0.996675589326915, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 103.53758954984133, "r2_baseline_sklearn": 0.08070604504897527, "mse_milp_val": 6.698282838726464, "r2_milp_val": 0.9409927480732614, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 8.494771615218268, "r2_refit_milp_assignment_val": 0.925166921011267, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 113.83318311274465, "label_mismatch_greedy_val": 0.04166666666666666, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 1.5918914372148438e-18, "r2_greedy_val": -0.002791831172268333, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.49059801357050664, "r2_refit_ground_truth_assignment_val": 0.9956781698715165, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.41005080008320133, "r2_ground_truth_val": 0.9963877352680033, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 113.53791157032644, "r2_baseline_sklearn_val": -0.0001906925357308964}