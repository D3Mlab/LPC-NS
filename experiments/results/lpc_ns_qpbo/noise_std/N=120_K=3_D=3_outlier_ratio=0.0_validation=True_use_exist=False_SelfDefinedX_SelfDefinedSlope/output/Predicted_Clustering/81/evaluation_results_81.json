{"time_milp": 16290.224456071854, "time_greedy": 0.5158617615699768, "time_refit_milp_assignment": 16299.812255859375, "mse_refit_ground_truth_assignment": 0.09826198660620625, "r2_refit_ground_truth_assignment": 0.9990991968649965, "weight_mismatch_refit_ground_truth_assignment": 0.6416259629187541, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.587885448616941, "r2_milp": 0.9487738350912129, "weight_mismatch_milp": 23.91325931205456, "refit-weight_mismatch_milp": 23.87440944707998, "rand_score_milp": 0.7323943661971831, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 6.146179937813566, "r2_refit_milp_assignment": 0.9436557477871269, "weight_mismatch_refit_milp_assignment": 25.467236038117818, "refit-weight_mismatch_refit_milp_assignment": 25.442465162354992, "rand_score_refit_milp_assignment": 0.7323943661971831, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 109.35915120034845, "r2_greedy": -0.0025348524387871496, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 22.70494573442544, "rand_score_greedy": 0.9311424100156496, "label_mismatch_greedy": 0.05555555555555556, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.363836858469928e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 1.5918914372148438e-18, "mse_ground_truth": 0.11309241078347845, "r2_ground_truth": 0.998985946657813, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.02599687548043, "r2_baseline_sklearn": 0.0005192936317961472, "mse_milp_val": 4.790236802418106, "r2_milp_val": 0.9583762674223938, "label_mismatch_milp_val": 0.375, "mse_refit_milp_assignment_val": 5.127870944349476, "r2_refit_milp_assignment_val": 0.9554424681526528, "label_mismatch_refit_milp_assignment_val": 0.375, "mse_greedy_val": 115.9740072417142, "label_mismatch_greedy_val": 0.125, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.007731196283590869, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.5001778501869288, "r2_refit_ground_truth_assignment_val": 0.9956538121316021, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 0.433520151543715, "r2_ground_truth_val": 0.99623301986955, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 115.25899823179016, "r2_baseline_sklearn_val": -0.0015182792510481935}