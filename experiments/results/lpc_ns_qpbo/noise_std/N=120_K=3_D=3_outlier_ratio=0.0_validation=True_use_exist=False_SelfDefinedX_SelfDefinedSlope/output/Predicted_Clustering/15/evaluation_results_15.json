{"time_milp": 2143.7404148578644, "time_greedy": 0.5023759245872498, "time_refit_milp_assignment": 2150.639978170395, "mse_refit_ground_truth_assignment": 2.039179335852781, "r2_refit_ground_truth_assignment": 0.9821593697858042, "weight_mismatch_refit_ground_truth_assignment": 2.110190749173083, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 7.32702910533493, "r2_milp": 0.9358963605904412, "weight_mismatch_milp": 5.94973069463876, "refit-weight_mismatch_milp": 5.1877112563285115, "rand_score_milp": 0.7656494522691706, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 8.492076005853372, "r2_refit_milp_assignment": 0.9257034508404745, "weight_mismatch_refit_milp_assignment": 3.440139078366548, "refit-weight_mismatch_refit_milp_assignment": 1.9584771014860085, "rand_score_refit_milp_assignment": 0.7656494522691706, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 114.47905844246013, "r2_greedy": -0.0015688728461542567, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 22.278833201357408, "rand_score_greedy": 0.9014084507042253, "label_mismatch_greedy": 0.08333333333333331, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4350408191326673e-15, "refit-weight_mismatch_greedy_sem": 1.630096831708e-15, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 2.2760588912995687, "r2_ground_truth": 0.9801241843082801, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.60398186722662, "r2_baseline_sklearn": 0.04108281399445268, "mse_milp_val": 4.831617378585661, "r2_milp_val": 0.9579217631026528, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 6.782482706024773, "r2_refit_milp_assignment_val": 0.9409318057093723, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 115.13518864524993, "label_mismatch_greedy_val": 0.16666666666666663, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 6.367565748859375e-18, "r2_greedy_val": -0.002704759799038392, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 3.2878170573556975, "r2_refit_ground_truth_assignment_val": 0.9713666182202844, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 2.2120739722988136, "r2_ground_truth_val": 0.9807351937565693, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 114.84858840531005, "r2_baseline_sklearn_val": -0.00020877722300149948}