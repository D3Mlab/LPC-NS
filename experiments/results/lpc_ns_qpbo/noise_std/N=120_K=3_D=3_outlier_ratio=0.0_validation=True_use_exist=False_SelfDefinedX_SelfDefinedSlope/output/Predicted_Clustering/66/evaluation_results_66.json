{"time_milp": 7308.985481977463, "time_greedy": 0.7604236483573914, "time_refit_milp_assignment": 7322.758074998856, "mse_refit_ground_truth_assignment": 3.2068635527166336, "r2_refit_ground_truth_assignment": 0.9718721519943269, "weight_mismatch_refit_ground_truth_assignment": 2.4664505096732645, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 7.565301096523781, "r2_milp": 0.9336436877147744, "weight_mismatch_milp": 16.320421678731105, "refit-weight_mismatch_milp": 17.624241068840888, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4444444444444444, "mse_refit_milp_assignment": 8.202485241779595, "r2_refit_milp_assignment": 0.9280548566046395, "weight_mismatch_refit_milp_assignment": 16.849844944140422, "refit-weight_mismatch_refit_milp_assignment": 18.225718973396603, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4444444444444444, "mse_greedy": 114.38530803108411, "r2_greedy": -0.0032895087334987583, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 24.286318667861007, "rand_score_greedy": 0.8877151799687011, "label_mismatch_greedy": 0.09722222222222224, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4693494276736472e-15, "refit-weight_mismatch_greedy_sem": 1.4350408191326673e-15, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 2.8553397121612694, "r2_ground_truth": 0.9746042970915589, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 108.40283233932729, "r2_baseline_sklearn": 0.049183620911452675, "mse_milp_val": 8.788285821253979, "r2_milp_val": 0.9200859447321673, "label_mismatch_milp_val": 0.4166666666666667, "mse_refit_milp_assignment_val": 9.29747504455379, "r2_refit_milp_assignment_val": 0.9154557612629228, "label_mismatch_refit_milp_assignment_val": 0.4166666666666667, "mse_greedy_val": 111.00426752113682, "label_mismatch_greedy_val": 0.08333333333333331, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 3.1837828744296875e-18, "r2_greedy_val": -0.009389242688930377, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 3.5408492112096055, "r2_refit_ground_truth_assignment_val": 0.9678021828926712, "label_mismatch_refit_ground_truth_assignment_val": 0.14583333333333334, "mse_ground_truth_val": 3.1549110078568225, "r2_ground_truth_val": 0.9713116143722565, "label_mismatch_ground_truth_val": 0.14583333333333334, "mse_baseline_sklearn_val": 110.13791173387007, "r2_baseline_sklearn_val": -0.0015112553688316765}