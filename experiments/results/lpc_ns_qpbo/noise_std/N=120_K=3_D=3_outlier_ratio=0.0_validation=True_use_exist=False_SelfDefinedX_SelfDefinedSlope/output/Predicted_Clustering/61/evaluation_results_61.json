{"time_milp": 5999.085076570511, "time_greedy": 0.5804595828056336, "time_refit_milp_assignment": 6009.899752855301, "mse_refit_ground_truth_assignment": 0.0998677230949818, "r2_refit_ground_truth_assignment": 0.9990870546407247, "weight_mismatch_refit_ground_truth_assignment": 0.43525597229528695, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.737520653502941, "r2_milp": 0.9475501924743007, "weight_mismatch_milp": 18.55124085314629, "refit-weight_mismatch_milp": 18.834977645059066, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4444444444444444, "mse_refit_milp_assignment": 6.5917332375696445, "r2_refit_milp_assignment": 0.9397413690597872, "weight_mismatch_refit_milp_assignment": 15.832443220281093, "refit-weight_mismatch_refit_milp_assignment": 16.08219615797134, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4444444444444444, "mse_greedy": 109.73559091033084, "r2_greedy": -0.0031529243300829624, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.16090802793321, "rand_score_greedy": 0.9158841940532081, "label_mismatch_greedy": 0.06944444444444445, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4350408191326673e-15, "refit-weight_mismatch_greedy_sem": 5.154818794821463e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 0.0, "mse_ground_truth": 0.08892061387353431, "r2_ground_truth": 0.9992002092061585, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 104.4404594362749, "r2_baseline_sklearn": 0.04525276227392849, "mse_milp_val": 5.308369130102463, "r2_milp_val": 0.9533625358457087, "label_mismatch_milp_val": 0.4166666666666667, "mse_refit_milp_assignment_val": 5.345796865053988, "r2_refit_milp_assignment_val": 0.9530337089302481, "label_mismatch_refit_milp_assignment_val": 0.4166666666666667, "mse_greedy_val": 114.54537279129185, "label_mismatch_greedy_val": 0.10416666666666667, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.006355358239883202, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.08796614500970677, "r2_refit_ground_truth_assignment_val": 0.9992271603887874, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.08323152377742439, "r2_ground_truth_val": 0.9992687571057061, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 113.89563141913696, "r2_baseline_sklearn_val": -0.0006469590666613456}