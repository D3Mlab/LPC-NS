{"time_milp": 4380.416841983795, "time_greedy": 0.5980593204498291, "time_refit_milp_assignment": 4388.2157616615295, "mse_refit_ground_truth_assignment": 5.195155454714449, "r2_refit_ground_truth_assignment": 0.9574469273774803, "weight_mismatch_refit_ground_truth_assignment": 2.649127177599364, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 9.413261043895263, "r2_milp": 0.9228967863796816, "weight_mismatch_milp": 5.354317534598937, "refit-weight_mismatch_milp": 4.103209783522469, "rand_score_milp": 0.7746478873239436, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 10.196410971041091, "r2_refit_milp_assignment": 0.9164820725150723, "weight_mismatch_refit_milp_assignment": 5.186521351285884, "refit-weight_mismatch_refit_milp_assignment": 3.317342490424176, "rand_score_refit_milp_assignment": 0.7746478873239436, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 122.63027913473631, "r2_greedy": -0.004454095594935037, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 24.00728459532196, "rand_score_greedy": 0.8748043818466353, "label_mismatch_greedy": 0.11111111111111112, "mse_greedy_sem": 9.780580990248002e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.363836858469928e-15, "refit-weight_mismatch_greedy_sem": 1.5356688824941101e-15, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 5.782123013616688, "r2_ground_truth": 0.9527771516210041, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 114.62718269927898, "r2_baseline_sklearn": 0.06109858069966967, "mse_milp_val": 13.639169878194508, "r2_milp_val": 0.8888495089837612, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 14.131082591558728, "r2_refit_milp_assignment_val": 0.8848407357141375, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 122.71354745919908, "label_mismatch_greedy_val": 0.10416666666666667, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -3.674536239817172e-05, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 7.10110174254839, "r2_refit_ground_truth_assignment_val": 0.9421305730121894, "label_mismatch_refit_ground_truth_assignment_val": 0.14583333333333334, "mse_ground_truth_val": 6.78138653118054, "r2_ground_truth_val": 0.944736047029029, "label_mismatch_ground_truth_val": 0.14583333333333334, "mse_baseline_sklearn_val": 123.16757990285221, "r2_baseline_sklearn_val": -0.0037368187173048018}