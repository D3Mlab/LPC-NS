{"time_milp": 2212.9935567379, "time_greedy": 0.7480255961418152, "time_refit_milp_assignment": 2226.0990290641785, "mse_refit_ground_truth_assignment": 7.380566993977275, "r2_refit_ground_truth_assignment": 0.9361075762100387, "weight_mismatch_refit_ground_truth_assignment": 5.560758345295873, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 13.247178568606923, "r2_milp": 0.8853212296809438, "weight_mismatch_milp": 16.97193693243204, "refit-weight_mismatch_milp": 14.797445785417027, "rand_score_milp": 0.7147887323943662, "label_mismatch_milp": 0.4166666666666667, "mse_refit_milp_assignment": 15.130818923836731, "r2_refit_milp_assignment": 0.8690148472658225, "weight_mismatch_refit_milp_assignment": 19.43788467535416, "refit-weight_mismatch_refit_milp_assignment": 17.604861217813507, "rand_score_refit_milp_assignment": 0.7147887323943662, "label_mismatch_refit_milp_assignment": 0.4166666666666667, "mse_greedy": 116.02862523581523, "r2_greedy": -0.004441813397640715, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.40735929966898, "rand_score_greedy": 0.83783255086072, "label_mismatch_greedy": 0.15694444444444441, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4350408191326673e-15, "refit-weight_mismatch_greedy_sem": 6.313337881910559e-16, "rand_score_greedy_sem": 0.001028281461341638, "label_mismatch_greedy_sem": 0.0014601596751051278, "mse_ground_truth": 8.494496632181276, "r2_ground_truth": 0.9291394551847586, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 115.34594584972436, "r2_baseline_sklearn": 0.0014680361687114951, "mse_milp_val": 12.536924089419658, "r2_milp_val": 0.9007922440654298, "label_mismatch_milp_val": 0.375, "mse_refit_milp_assignment_val": 20.31682674808194, "r2_refit_milp_assignment_val": 0.8392279657264827, "label_mismatch_refit_milp_assignment_val": 0.375, "mse_greedy_val": 127.36244437307035, "label_mismatch_greedy_val": 0.17604166666666665, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.0043999912779020415, "r2_greedy_val": -0.007850267455733917, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 12.13767100380145, "r2_refit_ground_truth_assignment_val": 0.9039516316785017, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 7.671487229530413, "r2_ground_truth_val": 0.9392936395487375, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 126.44888939861447, "r2_baseline_sklearn_val": -0.0006210828254213929}