{"time_milp": 784.9143357276917, "time_greedy": 0.5698903799057007, "time_refit_milp_assignment": 792.4800021648407, "mse_refit_ground_truth_assignment": 7.033087913451428, "r2_refit_ground_truth_assignment": 0.9418085994220314, "weight_mismatch_refit_ground_truth_assignment": 3.918925677035725, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 11.653007908871805, "r2_milp": 0.903583623650366, "weight_mismatch_milp": 6.109511910209468, "refit-weight_mismatch_milp": 4.756666182378379, "rand_score_milp": 0.7656494522691706, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 12.977622467150635, "r2_refit_milp_assignment": 0.8926238322584815, "weight_mismatch_refit_milp_assignment": 4.648777341763772, "refit-weight_mismatch_refit_milp_assignment": 2.640349849153655, "rand_score_refit_milp_assignment": 0.7656494522691706, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 120.9186918344978, "r2_greedy": -0.0004749152143226354, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.847984545281225, "rand_score_greedy": 0.8853677621283256, "label_mismatch_greedy": 0.09722222222222224, "mse_greedy_sem": 9.780580990248002e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 6.81918429234964e-16, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 7.850080665910758, "r2_ground_truth": 0.9349794813994586, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 115.66272402748642, "r2_baseline_sklearn": 0.0430126867958468, "mse_milp_val": 8.509947077827507, "r2_milp_val": 0.9293908306783152, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 9.575994662652796, "r2_refit_milp_assignment_val": 0.9205455659858914, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 120.68871146816934, "label_mismatch_greedy_val": 0.27083333333333326, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 1.273513149771875e-17, "r2_greedy_val": -0.0013845662419129656, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 8.601471316905812, "r2_refit_ground_truth_assignment_val": 0.9286314310680689, "label_mismatch_refit_ground_truth_assignment_val": 0.22916666666666666, "mse_ground_truth_val": 6.025863223309988, "r2_ground_truth_val": 0.9500018986307693, "label_mismatch_ground_truth_val": 0.22916666666666666, "mse_baseline_sklearn_val": 120.55751399334359, "r2_baseline_sklearn_val": -0.00029598782540496416}