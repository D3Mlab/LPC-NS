{"time_milp": 18115.50279045105, "time_greedy": 0.5544804334640503, "time_refit_milp_assignment": 18126.264583826065, "mse_refit_ground_truth_assignment": 0.07945443259761466, "r2_refit_ground_truth_assignment": 0.9992755262314292, "weight_mismatch_refit_ground_truth_assignment": 0.3798196019206438, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.966858199964924, "r2_milp": 0.9547116710743047, "weight_mismatch_milp": 26.102955252423904, "refit-weight_mismatch_milp": 25.880735311410838, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4861111111111111, "mse_refit_milp_assignment": 5.976887327591249, "r2_refit_milp_assignment": 0.9455021205868764, "weight_mismatch_refit_milp_assignment": 27.838122898539453, "refit-weight_mismatch_refit_milp_assignment": 27.608896445759974, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4861111111111111, "mse_greedy": 110.14045364527138, "r2_greedy": -0.004272095536685727, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 23.14239886755741, "rand_score_greedy": 0.8877151799687011, "label_mismatch_greedy": 0.09722222222222224, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.2494455620143562e-15, "refit-weight_mismatch_greedy_sem": 3.6450073256061235e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 0.1010542287511744, "r2_ground_truth": 0.9990970559926606, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.24701848142199, "r2_baseline_sklearn": 0.0038743390795629162, "mse_milp_val": 6.9556187531516365, "r2_milp_val": 0.939662561886487, "label_mismatch_milp_val": 0.4583333333333333, "mse_refit_milp_assignment_val": 11.002135263782394, "r2_refit_milp_assignment_val": 0.904560517309236, "label_mismatch_refit_milp_assignment_val": 0.4583333333333333, "mse_greedy_val": 115.6370683497208, "label_mismatch_greedy_val": 0.04166666666666666, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 1.5918914372148438e-18, "r2_greedy_val": -0.003109098240601016, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 0.5757417861285058, "r2_refit_ground_truth_assignment_val": 0.9950056514563637, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 0.5533729352377457, "r2_ground_truth_val": 0.9951996930224976, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 115.28478384055232, "r2_baseline_sklearn_val": -5.31595060817569e-05}