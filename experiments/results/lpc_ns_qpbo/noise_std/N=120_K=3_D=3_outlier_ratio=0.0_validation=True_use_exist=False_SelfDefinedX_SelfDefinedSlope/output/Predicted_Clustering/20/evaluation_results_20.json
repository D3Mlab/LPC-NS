{"time_milp": 787.962583065033, "time_greedy": 0.6752994298934937, "time_refit_milp_assignment": 796.703971862793, "mse_refit_ground_truth_assignment": 8.749743987000963, "r2_refit_ground_truth_assignment": 0.9288696133660228, "weight_mismatch_refit_ground_truth_assignment": 4.371109409001384, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 13.211425157833803, "r2_milp": 0.8925987113613056, "weight_mismatch_milp": 6.16382043986825, "refit-weight_mismatch_milp": 4.682412771431354, "rand_score_milp": 0.7656494522691706, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 14.584292230116947, "r2_refit_milp_assignment": 0.8814380915999007, "weight_mismatch_refit_milp_assignment": 5.387956729329424, "refit-weight_mismatch_refit_milp_assignment": 3.017690460756418, "rand_score_refit_milp_assignment": 0.7656494522691706, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 123.04741623316946, "r2_greedy": -0.00030472937039749404, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 21.762651219317426, "rand_score_greedy": 0.8597809076682313, "label_mismatch_greedy": 0.12291666666666667, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 6.571130405957371e-16, "rand_score_greedy_sem": 0.0011868142410499318, "label_mismatch_greedy_sem": 0.0011377472526515634, "mse_ground_truth": 9.766150650933355, "r2_ground_truth": 0.9204714116644204, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.66469409575194, "r2_baseline_sklearn": 0.04345370600172238, "mse_milp_val": 9.99606862845561, "r2_milp_val": 0.9183777289550306, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 11.605193370283438, "r2_refit_milp_assignment_val": 0.9052385218622788, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 122.60527945133035, "label_mismatch_greedy_val": 0.2968750000000001, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.003337100393318685, "r2_greedy_val": -0.0011257148068251066, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 11.989873941395567, "r2_refit_ground_truth_assignment_val": 0.9020974368009312, "label_mismatch_refit_ground_truth_assignment_val": 0.25, "mse_ground_truth_val": 9.031629894313099, "r2_ground_truth_val": 0.9262527929117103, "label_mismatch_ground_truth_val": 0.25, "mse_baseline_sklearn_val": 122.5063806274945, "r2_baseline_sklearn_val": -0.0003181626675590188}