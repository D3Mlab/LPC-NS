{"time_milp": 2404.686721801758, "time_greedy": 0.5347301483154296, "time_refit_milp_assignment": 2411.459979534149, "mse_refit_ground_truth_assignment": 1.2588811206029926, "r2_refit_ground_truth_assignment": 0.9888759578437373, "weight_mismatch_refit_ground_truth_assignment": 1.658007017207423, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.722456952528488, "r2_milp": 0.9405973341646673, "weight_mismatch_milp": 5.9264721449558495, "refit-weight_mismatch_milp": 5.324709032029244, "rand_score_milp": 0.7656494522691706, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 8.265146137182827, "r2_refit_milp_assignment": 0.926965435772319, "weight_mismatch_refit_milp_assignment": 3.4983943675032902, "refit-weight_mismatch_refit_milp_assignment": 2.3095897199612923, "rand_score_refit_milp_assignment": 0.7656494522691706, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 113.38796614511293, "r2_greedy": -0.0019472806192897263, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 22.408478185463927, "rand_score_greedy": 0.9014084507042253, "label_mismatch_greedy": 0.08333333333333331, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4350408191326673e-15, "refit-weight_mismatch_greedy_sem": 0.0, "rand_score_greedy_sem": 2.54702629954375e-17, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 1.4051179890165708, "r2_ground_truth": 0.9876171538743387, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 108.57658085536224, "r2_baseline_sklearn": 0.04056829286676966, "mse_milp_val": 4.478574079592845, "r2_milp_val": 0.9606872187269365, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 7.448229919590493, "r2_refit_milp_assignment_val": 0.9346196739193007, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 114.27499521695127, "label_mismatch_greedy_val": 0.1875, "mse_greedy_val_sem": 6.520387326832e-15, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.0031022848131150305, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 2.017791657595813, "r2_refit_ground_truth_assignment_val": 0.982287888805696, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 1.3739095639063692, "r2_ground_truth_val": 0.9879398654091859, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 113.9429922454442, "r2_baseline_sklearn_val": -0.00018797325570685253}