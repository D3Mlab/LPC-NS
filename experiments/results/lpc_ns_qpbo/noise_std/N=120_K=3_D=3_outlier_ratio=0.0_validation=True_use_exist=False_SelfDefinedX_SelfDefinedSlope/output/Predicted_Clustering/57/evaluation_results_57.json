{"time_milp": 6418.474505901337, "time_greedy": 0.6433325409889221, "time_refit_milp_assignment": 6426.724224090576, "mse_refit_ground_truth_assignment": 4.041877108352192, "r2_refit_ground_truth_assignment": 0.9671942538008546, "weight_mismatch_refit_ground_truth_assignment": 5.170362057161146, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 8.314786739170394, "r2_milp": 0.9325133406699619, "weight_mismatch_milp": 4.5766002279834845, "refit-weight_mismatch_milp": 6.300698990318569, "rand_score_milp": 0.7574334898278561, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 9.021094395742095, "r2_refit_milp_assignment": 0.9267806206740661, "weight_mismatch_refit_milp_assignment": 2.1495713645779007, "refit-weight_mismatch_refit_milp_assignment": 3.3578552147208254, "rand_score_refit_milp_assignment": 0.7574334898278561, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 124.45087470035416, "r2_greedy": -0.01010092593980838, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 25.687194235261938, "rand_score_greedy": 0.831964006259781, "label_mismatch_greedy": 0.16527777777777775, "mse_greedy_sem": 0.0, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.5028750209624192e-15, "refit-weight_mismatch_greedy_sem": 0.0, "rand_score_greedy_sem": 0.0006731682331882664, "label_mismatch_greedy_sem": 0.0009558988911273391, "mse_ground_truth": 3.908589301382351, "r2_ground_truth": 0.9662725514584362, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 114.62984821763719, "r2_baseline_sklearn": 0.06961107261188648, "mse_milp_val": 11.578721092875393, "r2_milp_val": 0.8893149495958427, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 12.650256820223058, "r2_refit_milp_assignment_val": 0.8790717642699338, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 104.77691005552644, "label_mismatch_greedy_val": 0.125, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.0015991816076998955, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 5.407704972721663, "r2_refit_ground_truth_assignment_val": 0.9483058541029363, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 4.404327401308928, "r2_ground_truth_val": 0.9578974917436905, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 105.12194092129414, "r2_baseline_sklearn_val": -0.0048974525015370585}