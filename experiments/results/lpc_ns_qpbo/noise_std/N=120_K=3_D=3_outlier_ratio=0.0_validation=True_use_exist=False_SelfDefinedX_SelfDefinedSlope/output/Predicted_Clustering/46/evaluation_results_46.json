{"time_milp": 18108.54668903351, "time_greedy": 0.6439290761947631, "time_refit_milp_assignment": 18120.645693063736, "mse_refit_ground_truth_assignment": 2.5513701134122937, "r2_refit_ground_truth_assignment": 0.9775025102198774, "weight_mismatch_refit_ground_truth_assignment": 2.152311077550332, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.942625068998767, "r2_milp": 0.9387812706138011, "weight_mismatch_milp": 27.798226362514104, "refit-weight_mismatch_milp": 26.525855200484422, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.4861111111111111, "mse_refit_milp_assignment": 7.297655401968344, "r2_refit_milp_assignment": 0.9356506815841545, "weight_mismatch_refit_milp_assignment": 25.411364927050233, "refit-weight_mismatch_refit_milp_assignment": 24.1033099217795, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.4861111111111111, "mse_greedy": 113.65974356626211, "r2_greedy": -0.0022297062472977913, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 24.111037126728142, "rand_score_greedy": 0.8748043818466353, "label_mismatch_greedy": 0.11111111111111112, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.2494455620143562e-15, "refit-weight_mismatch_greedy_sem": 3.1566689409552796e-16, "rand_score_greedy_sem": 0.0, "label_mismatch_greedy_sem": 3.1837828744296875e-18, "mse_ground_truth": 3.2449635676766007, "r2_ground_truth": 0.9722463163073335, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 112.87961567686885, "r2_baseline_sklearn": 0.004649311080117902, "mse_milp_val": 11.827319799762689, "r2_milp_val": 0.9032026504689429, "label_mismatch_milp_val": 0.4583333333333333, "mse_refit_milp_assignment_val": 10.492324111758265, "r2_refit_milp_assignment_val": 0.9141285446209562, "label_mismatch_refit_milp_assignment_val": 0.4583333333333333, "mse_greedy_val": 122.52238905781667, "label_mismatch_greedy_val": 0.0625, "mse_greedy_val_sem": 3.260193663416e-15, "label_mismatch_greedy_val_sem": 0.0, "r2_greedy_val": -0.0027497962173652635, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 3.9318250616912973, "r2_refit_ground_truth_assignment_val": 0.96782109123327, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 3.991073715057123, "r2_ground_truth_val": 0.9673361874083806, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 122.19078093558126, "r2_baseline_sklearn_val": -3.5843448793038135e-05}