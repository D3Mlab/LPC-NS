{"time_milp": 2584.080176591873, "time_greedy": 0.6799707293510437, "time_refit_milp_assignment": 2594.9198920726776, "mse_refit_ground_truth_assignment": 9.332083902542177, "r2_refit_ground_truth_assignment": 0.9229917863158945, "weight_mismatch_refit_ground_truth_assignment": 4.2074743988543934, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 13.47112694245299, "r2_milp": 0.888836466433019, "weight_mismatch_milp": 12.401805614373046, "refit-weight_mismatch_milp": 14.791510243096843, "rand_score_milp": 0.7570422535211268, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 13.761572887427775, "r2_refit_milp_assignment": 0.8864397109357599, "weight_mismatch_refit_milp_assignment": 28.63879508148954, "refit-weight_mismatch_refit_milp_assignment": 29.887149396000275, "rand_score_refit_milp_assignment": 0.7570422535211268, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 121.58484232315409, "r2_greedy": -0.003316259921229303, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 25.433484912874405, "rand_score_greedy": 0.8553012519561815, "label_mismatch_greedy": 0.1340277777777778, "mse_greedy_sem": 3.260193663416e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.39989162600147e-15, "refit-weight_mismatch_greedy_sem": 5.763262618457166e-16, "rand_score_greedy_sem": 0.0012415123624546203, "label_mismatch_greedy_sem": 0.0015197823747289327, "mse_ground_truth": 8.309137363071377, "r2_ground_truth": 0.928726482370374, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 114.97415597225437, "r2_baseline_sklearn": 0.051235022774590244, "mse_milp_val": 10.219657486754107, "r2_milp_val": 0.9066810187303497, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 9.99198063978445, "r2_refit_milp_assignment_val": 0.9087600092880501, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 110.85439392338326, "label_mismatch_greedy_val": 0.153125, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.002279673562093396, "r2_greedy_val": -0.012247144642837382, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 9.156834134956055, "r2_refit_ground_truth_assignment_val": 0.9163860007796933, "label_mismatch_refit_ground_truth_assignment_val": 0.16666666666666666, "mse_ground_truth_val": 8.313788567331805, "r2_ground_truth_val": 0.9240841211556998, "label_mismatch_ground_truth_val": 0.16666666666666666, "mse_baseline_sklearn_val": 109.789953925381, "r2_baseline_sklearn_val": -0.0025274004767550373}