{"time_milp": 2000.6861021518707, "time_greedy": 0.5476471543312073, "time_refit_milp_assignment": 2011.2628543376923, "mse_refit_ground_truth_assignment": 7.640326417489074, "r2_refit_ground_truth_assignment": 0.9368684319923474, "weight_mismatch_refit_ground_truth_assignment": 6.7678370679174185, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 9.814160756436898, "r2_milp": 0.9189061666508416, "weight_mismatch_milp": 24.488118510535806, "refit-weight_mismatch_milp": 25.636095553770467, "rand_score_milp": 0.7492175273865415, "label_mismatch_milp": 0.3611111111111111, "mse_refit_milp_assignment": 10.433998916714152, "r2_refit_milp_assignment": 0.9137844803731836, "weight_mismatch_refit_milp_assignment": 25.51835518215703, "refit-weight_mismatch_refit_milp_assignment": 23.755303871037484, "rand_score_refit_milp_assignment": 0.7492175273865415, "label_mismatch_refit_milp_assignment": 0.3611111111111111, "mse_greedy": 122.45232887390937, "r2_greedy": -0.011816394428243449, "weight_mismatch_greedy": 22.956050966705313, "refit-weight_mismatch_greedy": 27.081251473043107, "rand_score_greedy": 0.8360719874804381, "label_mismatch_greedy": 0.15972222222222218, "mse_greedy_sem": 9.780580990248002e-15, "r2_greedy_sem": 0.0, "weight_mismatch_greedy_sem": 1.4693494276736472e-15, "refit-weight_mismatch_greedy_sem": 8.15048415854e-16, "rand_score_greedy_sem": 0.0020210000753339828, "label_mismatch_greedy_sem": 0.002759442410552173, "mse_ground_truth": 7.813047799277766, "r2_ground_truth": 0.9337096539235052, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 115.5917570555856, "r2_baseline_sklearn": 0.04487210716881729, "mse_milp_val": 16.684167399068908, "r2_milp_val": 0.8519377974439992, "label_mismatch_milp_val": 0.3958333333333333, "mse_refit_milp_assignment_val": 16.62141153449635, "r2_refit_milp_assignment_val": 0.852494718943866, "label_mismatch_refit_milp_assignment_val": 0.3958333333333333, "mse_greedy_val": 112.8016752166247, "label_mismatch_greedy_val": 0.15624999999999997, "mse_greedy_val_sem": 0.0, "label_mismatch_greedy_val_sem": 0.004139163615828261, "r2_greedy_val": -0.0010487239244660884, "r2_greedy_val_sem": 0.0, "mse_refit_ground_truth_assignment_val": 10.089510875557801, "r2_refit_ground_truth_assignment_val": 0.9104615071752887, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 8.773575642411021, "r2_ground_truth_val": 0.9221396607433014, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 113.41735298711588, "r2_baseline_sklearn_val": -0.006512503122029001}