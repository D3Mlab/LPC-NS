==================== Evaluating with noise_std = 2.9 in Dataset 1 with random state = 12 ====================
ODS is enabled
mse 9.766150650933355
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 18000
using QPBO:
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8160 CPU @ 2.10GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 216 columns and 216 nonzeros
Model fingerprint: 0xdbcb945e
Model has 7884 quadratic objective terms
Variable types: 0 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [3e-03, 4e+02]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
Found heuristic solution: objective 1374.0783647
Presolve time: 0.08s
Presolved: 72 rows, 216 columns, 216 nonzeros
Presolved model has 7884 quadratic objective terms
Variable types: 0 continuous, 216 integer (216 binary)
Found heuristic solution: objective 5022.5067471

Root relaxation: objective 9.012354e+03, 302 iterations, 0.03 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0 9012.35437    0  213 5022.50675 9012.35437  79.4%     -    0s
H    0     0                    6447.0551904 9012.35437  39.8%     -    0s
     0     0 8911.30898    0  206 6447.05519 8911.30898  38.2%     -    0s
     0     2 8895.37065    0  206 6447.05519 8895.37065  38.0%     -    0s
 22666 13599 7310.17867   26  165 6447.05519 7666.46987  18.9%   5.5    5s
 63901 36351 6662.17917   27  165 6447.05519 7453.95796  15.6%   5.2   10s
 105562 58575 6451.18920   36  152 6447.05519 7364.14089  14.2%   5.1   15s
 151313 81578     cutoff   44      6447.05519 7302.30911  13.3%   5.0   20s
 198335 105072 7158.00087   26  172 6447.05519 7258.10979  12.6%   5.0   25s
 243235 127386 6643.63355   42  131 6447.05519 7226.14817  12.1%   4.9   30s
 289652 149293 7117.26436   35  147 6447.05519 7201.02281  11.7%   4.9   35s
 335998 171278 6540.52174   41  122 6447.05519 7178.13627  11.3%   4.9   40s
 376935 189472 6720.96778   28  164 6447.05519 7163.76463  11.1%   4.9   45s
 423823 210736 6608.84237   34  149 6447.05519 7146.32596  10.8%   4.9   50s
 471583 232156 6580.77429   41  127 6447.05519 7130.79809  10.6%   4.8   55s
 518332 252532 6558.17940   44  116 6447.05519 7117.19835  10.4%   4.8   60s
 561951 272457 6535.89799   40  129 6447.05519 7105.77472  10.2%   4.8   65s
 604528 290533 6623.55890   38  144 6447.05519 7095.47180  10.1%   4.8   70s
 651926 309817 6481.42187   38  144 6447.05519 7085.15302  9.90%   4.8   75s
 698739 328531 6482.69645   38  145 6447.05519 7075.92565  9.75%   4.8   80s
 746513 347920 6641.44302   36  140 6447.05519 7066.45916  9.61%   4.8   85s
 792680 364929 6763.58061   34  129 6447.05519 7058.84540  9.49%   4.8   90s
 833077 380904 6844.80890   33  145 6447.05519 7052.27473  9.39%   4.8   95s
 882307 400618 6584.75434   42  135 6447.05519 7044.44283  9.27%   4.7  100s
 929830 419213 6887.54902   35  151 6447.05519 7037.08207  9.15%   4.7  105s
 978356 437501 6669.86274   39  131 6447.05519 7030.45259  9.05%   4.7  110s
 1026855 455985     cutoff   33      6447.05519 7023.80908  8.95%   4.7  115s
 1069679 473108 6710.35798   31  149 6447.05519 7018.20459  8.86%   4.7  120s
 1117413 490289 6808.22958   35  139 6447.05519 7012.44910  8.77%   4.7  125s
 1165706 509098 6550.33726   40  144 6447.05519 7006.79635  8.68%   4.7  130s
 1210829 526144 6789.87612   35  135 6447.05519 7001.62255  8.60%   4.7  135s
 1258531 543678 6861.51500   31  161 6447.05519 6996.60534  8.52%   4.7  140s
 1309205 562067 6862.49606   30  150 6447.05519 6991.44275  8.44%   4.7  145s
 1350776 576932 6793.69735   33  172 6447.05519 6987.34841  8.38%   4.7  150s
 1400563 594941 6672.39380   41  128 6447.05519 6982.32257  8.30%   4.7  155s
 1449272 611869 6814.77042   31  143 6447.05519 6977.98758  8.24%   4.7  160s
 1498179 629267 6655.59585   39  134 6447.05519 6973.56939  8.17%   4.7  165s
 1546168 645781 6618.59501   37  158 6447.05519 6969.51775  8.10%   4.7  170s
 1587762 660025 6837.58926   37  138 6447.05519 6966.09782  8.05%   4.7  175s
 1637650 677136 6531.62273   37  140 6447.05519 6961.97504  7.99%   4.7  180s
 1684618 692774 6485.25667   43  107 6447.05519 6958.26481  7.93%   4.7  185s
 1733662 709063 6830.84172   31  164 6447.05519 6954.52802  7.87%   4.7  190s
 1781234 724128 6815.30699   35  134 6447.05519 6951.06853  7.82%   4.7  195s
 1822911 738378     cutoff   38      6447.05519 6948.07714  7.77%   4.7  200s
 1870165 753545 6599.51546   38  138 6447.05519 6944.71097  7.72%   4.6  205s
 1919178 769828 6793.82250   40  148 6447.05519 6941.26707  7.67%   4.6  210s
 1968711 785468 6619.50713   34  150 6447.05519 6937.98600  7.61%   4.6  215s
 2015499 799989 6579.89946   42  138 6447.05519 6935.00927  7.57%   4.6  220s
 2060110 814231 6779.06345   38  118 6447.05519 6932.17303  7.52%   4.6  225s
 2106894 828738 6643.54523   33  148 6447.05519 6929.43885  7.48%   4.6  230s
 2157772 844557 6453.69754   38  139 6447.05519 6926.33903  7.43%   4.6  235s
 2204229 859125 6463.58313   42  122 6447.05519 6923.54360  7.39%   4.6  240s
 2251585 872823 6505.68295   41  124 6447.05519 6920.92574  7.35%   4.6  245s
 2301732 887884 6645.05138   33  136 6447.05519 6918.08771  7.31%   4.6  250s
 2345113 901100     cutoff   50      6447.05519 6915.70426  7.27%   4.6  255s
 2393779 915470 6458.57178   41  117 6447.05519 6913.13360  7.23%   4.6  260s
 2441813 929551 6500.74842   42  143 6447.05519 6910.57159  7.19%   4.6  265s
 2491592 944229 6702.83219   36  156 6447.05519 6908.02667  7.15%   4.6  270s
 2539797 958571 6456.69389   44  130 6447.05519 6905.54070  7.11%   4.6  275s
 2584748 970517 6845.80244   35  138 6447.05519 6903.49806  7.08%   4.6  280s
 2631927 984335 6572.53797   36  147 6447.05519 6901.14249  7.04%   4.6  285s
 2680155 997752 6539.16761   42  157 6447.05519 6898.85094  7.01%   4.6  290s
 2730329 1012330 6674.25018   40  125 6447.05519 6896.44196  6.97%   4.6  295s
 2775915 1025126     cutoff   44      6447.05519 6894.28570  6.94%   4.6  300s
 2818663 1036557 6485.65441   42  134 6447.05519 6892.39183  6.91%   4.6  305s
 2869272 1050345 6585.60996   36  154 6447.05519 6890.19868  6.87%   4.6  310s
 2917347 1063571 6473.28087   35  154 6447.05519 6888.06121  6.84%   4.6  315s
 2966033 1076374 6487.16078   35  150 6447.05519 6886.05991  6.81%   4.6  320s
 3011109 1089266 6548.22577   44  127 6447.05519 6884.11795  6.78%   4.6  325s
 3058799 1101977     cutoff   33      6447.05519 6882.20036  6.75%   4.6  330s
 3108833 1115658 6460.61307   36  149 6447.05519 6880.18135  6.72%   4.6  335s
 3157173 1128803 6506.07819   42  129 6447.05519 6878.18060  6.69%   4.6  340s
 3206145 1141734 6488.48121   43  135 6447.05519 6876.24461  6.66%   4.6  345s
 3255540 1153692     cutoff   38      6447.05519 6874.34219  6.63%   4.6  350s
 3298783 1165671 6705.82857   41  132 6447.05519 6872.63811  6.60%   4.6  355s
 3348654 1177862     cutoff   42      6447.05519 6870.83038  6.57%   4.6  360s
 3396894 1190030 6672.97031   35  142 6447.05519 6869.02508  6.55%   4.6  365s
 3446401 1202868 6458.11837   38  152 6447.05519 6867.17107  6.52%   4.6  370s
 3494818 1215102 6553.20254   37  161 6447.05519 6865.37681  6.49%   4.6  375s
 3535585 1225452 6803.22618   31  172 6447.05519 6863.92448  6.47%   4.6  380s
 3585700 1238278     cutoff   40      6447.05519 6862.15917  6.44%   4.6  385s
 3635395 1250074 6746.89406   26  180 6447.05519 6860.46340  6.41%   4.6  390s
 3682711 1261682 6485.58299   36  163 6447.05519 6858.79808  6.39%   4.6  395s
 3733410 1274512 6597.33147   41  139 6447.05519 6857.07476  6.36%   4.6  400s
 3781150 1286112 6489.31495   33  166 6447.05519 6855.44825  6.33%   4.6  405s
 3826075 1297244 6467.99386   43  126 6447.05519 6853.92284  6.31%   4.6  410s
 3872600 1308929 6600.12028   38  144 6447.05519 6852.32425  6.29%   4.6  415s
 3921874 1321281 6554.58680   40  141 6447.05519 6850.75035  6.26%   4.6  420s
 3971995 1333479 6707.42737   45  117 6447.05519 6849.16606  6.24%   4.6  425s
 4022273 1345583     cutoff   39      6447.05519 6847.57512  6.21%   4.6  430s
 4057583 1356576 6452.65855   40  150 6447.05519 6846.47410  6.20%   4.6  436s
 4110581 1365807 6455.67434   35  143 6447.05519 6845.01231  6.17%   4.6  440s
 4161405 1377589 6471.45510   34  162 6447.05519 6843.46043  6.15%   4.6  445s
 4212048 1389214 6487.52695   43  127 6447.05519 6841.91815  6.12%   4.6  450s
 4259791 1400013 6635.97359   36  152 6447.05519 6840.53625  6.10%   4.6  455s
 4303259 1410506 6452.87858   49  114 6447.05519 6839.29177  6.08%   4.5  460s
 4354072 1422293 6805.76826   37  139 6447.05519 6837.76241  6.06%   4.5  465s
 4401784 1433199 6738.75810   37  151 6447.05519 6836.28957  6.04%   4.5  470s
 4452739 1444632 6762.10298   40  135 6447.05519 6834.86420  6.02%   4.5  475s
 4502723 1456310 6511.12053   33  155 6447.05519 6833.41533  5.99%   4.5  480s
 4550160 1467046 6519.25810   46  112 6447.05519 6832.14608  5.97%   4.5  485s
 4593825 1476644 6642.99404   36  139 6447.05519 6830.94163  5.95%   4.5  490s
 4644815 1487647 6509.06117   37  150 6447.05519 6829.55972  5.93%   4.5  495s
 4694697 1498112 6552.49387   30  162 6447.05519 6828.17733  5.91%   4.5  500s
 4737851 1507712 6457.47585   40  155 6447.05519 6827.02488  5.89%   4.5  505s
 4787924 1518727     cutoff   38      6447.05519 6825.64309  5.87%   4.5  510s
 4834148 1529217 6453.22976   45  132 6447.05519 6824.42799  5.85%   4.5  515s
 4884415 1539785 6737.44650   32  171 6447.05519 6823.13604  5.83%   4.5  520s
 4933993 1550125 6490.49591   32  146 6447.05519 6821.88203  5.81%   4.5  525s
 4982683 1560453 6455.77878   48  124 6447.05519 6820.60581  5.79%   4.5  530s
 5033230 1571035     cutoff   47      6447.05519 6819.34811  5.77%   4.5  535s
 5076840 1580011 6616.58741   35  140 6447.05519 6818.22137  5.76%   4.5  540s
 5126411 1590142     cutoff   42      6447.05519 6817.00308  5.74%   4.5  545s
 5176091 1600436 6525.08620   37  148 6447.05519 6815.77118  5.72%   4.5  550s
 5226058 1611178 6469.94241   38  135 6447.05519 6814.51757  5.70%   4.5  555s
 5274048 1621461 6490.56380   45  127 6447.05519 6813.32732  5.68%   4.5  560s
 5318140 1629740 6585.78952   40  132 6447.05519 6812.30841  5.67%   4.5  565s
 5368408 1640138 6670.44509   33  157 6447.05519 6811.11265  5.65%   4.5  570s
 5416643 1649798 6509.60975   45  106 6447.05519 6810.01838  5.63%   4.5  575s
 5467165 1659765 6479.05994   35  143 6447.05519 6808.89163  5.61%   4.5  580s
 5517451 1669759 6477.28682   38  142 6447.05519 6807.71346  5.59%   4.5  585s
 5558329 1677404 6761.10932   37  131 6447.05519 6806.74481  5.58%   4.5  590s
 5607408 1687468 6477.58907   44  122 6447.05519 6805.62092  5.56%   4.5  595s
 5658778 1697580 6624.97928   39  137 6447.05519 6804.45459  5.54%   4.5  600s
 5707051 1706830 6652.44380   31  163 6447.05519 6803.36413  5.53%   4.5  605s
 5752900 1715364 6719.86073   38  141 6447.05519 6802.37128  5.51%   4.5  610s
 5802489 1724735 6742.83042   34  149 6447.05519 6801.29471  5.49%   4.5  615s
 5852325 1734331 6474.06150   39  145 6447.05519 6800.16635  5.48%   4.5  620s
 5902379 1743759 6578.11823   31  159 6447.05519 6799.08576  5.46%   4.5  625s
 5952546 1753136 6622.58747   42  127 6447.05519 6798.04148  5.44%   4.5  630s
 5997613 1761473 6596.32477   30  162 6447.05519 6797.08142  5.43%   4.5  635s
 6047188 1770757 6592.10300   38  129 6447.05519 6796.03270  5.41%   4.5  640s
 6095429 1779217 6639.82299   36  120 6447.05519 6795.04763  5.40%   4.5  645s
 6147268 1788939 6457.15510   35  156 6447.05519 6793.96865  5.38%   4.5  650s
 6195194 1797758 6458.20428   34  152 6447.05519 6792.97326  5.37%   4.5  655s
 6247081 1807250 6678.07156   40  135 6447.05519 6791.91756  5.35%   4.5  660s
 6287726 1814657 6452.40340   41  132 6447.05519 6791.08288  5.34%   4.5  665s
 6339328 1823452 6453.90242   39  151 6447.05519 6790.06051  5.32%   4.5  670s
 6389177 1832359     cutoff   43      6447.05519 6789.08272  5.31%   4.5  675s
 6439192 1841242 6492.25617   33  138 6447.05519 6788.08027  5.29%   4.5  680s
 6489527 1850313 6549.41865   41  150 6447.05519 6787.06666  5.27%   4.5  685s
 6532647 1857963 6459.25529   41  131 6447.05519 6786.22717  5.26%   4.5  690s
 6582808 1867004 6502.53167   47  120 6447.05519 6785.25542  5.25%   4.5  695s
 6630769 1875455 6784.19121   35  150 6447.05519 6784.33291  5.23%   4.5  700s
 6684071 1884717 6451.48681   35  144 6447.05519 6783.31463  5.22%   4.5  705s
 6732703 1893176 6506.83195   40  152 6447.05519 6782.33400  5.20%   4.5  710s
 6776857 1901038 6467.86787   32  161 6447.05519 6781.46117  5.19%   4.5  715s
 6826944 1909310 6526.92386   35  157 6447.05519 6780.49093  5.17%   4.5  720s
 6876975 1917533 6454.80747   34  159 6447.05519 6779.54344  5.16%   4.5  725s
 6927800 1925763 6686.76844   44  127 6447.05519 6778.59378  5.14%   4.5  730s
 6977940 1934287 6692.27668   39  128 6447.05519 6777.66431  5.13%   4.5  735s
 7016638 1940479 6467.14948   36  133 6447.05519 6776.95882  5.12%   4.5  740s
 7067719 1948790 6508.41671   34  166 6447.05519 6776.02027  5.10%   4.5  745s
 7119843 1957366     cutoff   40      6447.05519 6775.05962  5.09%   4.5  750s
 7167986 1965065 6477.50674   43  135 6447.05519 6774.18032  5.07%   4.5  755s
 7218321 1973140 6525.37329   36  145 6447.05519 6773.30244  5.06%   4.5  760s
 7261416 1979940 6468.88962   41  150 6447.05519 6772.51216  5.05%   4.5  765s
 7311644 1987898     cutoff   39      6447.05519 6771.63465  5.03%   4.5  770s
 7361776 1995981 6499.23859   38  140 6447.05519 6770.76382  5.02%   4.5  775s
 7411913 2003731     cutoff   40      6447.05519 6769.90274  5.01%   4.5  780s

Explored 7440963 nodes (33442389 simplex iterations) in 782.83 seconds (610.84 work units)
Thread count was 16 (of 48 available processors)

Solution count 4: 6447.06 6268.96 5022.51 1374.08 

Optimal solution found (tolerance 5.00e-02)
Best objective 6.447055190359e+03, best bound 6.769380074256e+03, gap 4.9996%

Gurobi MIQP converged to an optimal solution.
Cluster Assignments from Gurobi MIQP using QPBO
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 0.192694   -0.00076446  0.00052499  0.00116526]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
117.66469409575194
Cluster assignments:  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
-----------------------------------
Regression weights for cluster 0: y = 0.0x_0 + 0.0x_1 + 0.0x_2 + 0.0
Regression weights for cluster 0 after refit: y = 0.0x_1 + 0.0x_2 + 0.0x_3 + 0.0
-----------------------------------
Regression weights for cluster 1: y = 0.7759x_0 + 1.1665x_1 + -0.1462x_2 + 6.0695
Regression weights for cluster 1 after refit: y = -0.2527x_1 + 1.409x_2 + -0.0218x_3 + 6.8798
-----------------------------------
Regression weights for cluster 2: y = -2.2628x_0 + -2.4053x_1 + -1.5897x_2 + -8.4422
Regression weights for cluster 2 after refit: y = -2.7332x_1 + -2.3943x_2 + -0.4326x_3 + -8.9716
{'time_milp': 787.962583065033, 'time_greedy': np.float64(0.6752994298934937), 'time_refit_milp_assignment': 796.703971862793, 'mse_refit_ground_truth_assignment': np.float64(8.749743987000963), 'r2_refit_ground_truth_assignment': 0.9288696133660228, 'weight_mismatch_refit_ground_truth_assignment': np.float64(4.371109409001384), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(13.211425157833803), 'r2_milp': 0.8925987113613056, 'weight_mismatch_milp': np.float64(6.16382043986825), 'refit-weight_mismatch_milp': np.float64(4.682412771431354), 'rand_score_milp': np.float64(0.7656494522691706), 'label_mismatch_milp': np.float64(0.3333333333333333), 'mse_refit_milp_assignment': np.float64(14.584292230116947), 'r2_refit_milp_assignment': 0.8814380915999007, 'weight_mismatch_refit_milp_assignment': np.float64(5.387956729329424), 'refit-weight_mismatch_refit_milp_assignment': np.float64(3.017690460756418), 'rand_score_refit_milp_assignment': np.float64(0.7656494522691706), 'label_mismatch_refit_milp_assignment': np.float64(0.3333333333333333), 'mse_greedy': np.float64(123.04741623316946), 'r2_greedy': np.float64(-0.00030472937039749404), 'weight_mismatch_greedy': np.float64(22.956050966705313), 'refit-weight_mismatch_greedy': np.float64(21.762651219317426), 'rand_score_greedy': np.float64(0.8597809076682313), 'label_mismatch_greedy': np.float64(0.12291666666666667), 'mse_greedy_sem': np.float64(3.260193663416e-15), 'r2_greedy_sem': np.float64(0.0), 'weight_mismatch_greedy_sem': np.float64(1.39989162600147e-15), 'refit-weight_mismatch_greedy_sem': np.float64(6.571130405957371e-16), 'rand_score_greedy_sem': np.float64(0.0011868142410499318), 'label_mismatch_greedy_sem': np.float64(0.0011377472526515634), 'mse_ground_truth': np.float64(9.766150650933355), 'r2_ground_truth': np.float64(0.9204714116644204), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(117.66469409575194), 'r2_baseline_sklearn': np.float64(0.04345370600172238), 'mse_milp_val': np.float64(9.99606862845561), 'r2_milp_val': 0.9183777289550306, 'label_mismatch_milp_val': np.float64(0.3333333333333333), 'mse_refit_milp_assignment_val': np.float64(11.605193370283438), 'r2_refit_milp_assignment_val': 0.9052385218622788, 'label_mismatch_refit_milp_assignment_val': np.float64(0.3333333333333333), 'mse_greedy_val': np.float64(122.60527945133035), 'label_mismatch_greedy_val': np.float64(0.2968750000000001), 'mse_greedy_val_sem': np.float64(6.520387326832e-15), 'label_mismatch_greedy_val_sem': np.float64(0.003337100393318685), 'r2_greedy_val': np.float64(-0.0011257148068251066), 'r2_greedy_val_sem': np.float64(0.0), 'mse_refit_ground_truth_assignment_val': np.float64(11.989873941395567), 'r2_refit_ground_truth_assignment_val': 0.9020974368009312, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.25), 'mse_ground_truth_val': np.float64(9.031629894313099), 'r2_ground_truth_val': 0.9262527929117103, 'label_mismatch_ground_truth_val': np.float64(0.25), 'mse_baseline_sklearn_val': np.float64(122.5063806274945), 'r2_baseline_sklearn_val': -0.0003181626675590188}
