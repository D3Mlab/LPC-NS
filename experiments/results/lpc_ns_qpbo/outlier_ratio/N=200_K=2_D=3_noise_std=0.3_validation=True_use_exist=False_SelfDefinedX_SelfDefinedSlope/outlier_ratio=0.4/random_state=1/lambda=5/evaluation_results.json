{"time_milp": 0.4270660877227783, "time_greedy": 1.0556880474090575, "time_refit_milp_assignment": 0.8685150146484375, "mse_refit_ground_truth_assignment": 28.635521237774928, "r2_refit_ground_truth_assignment": 0.8443037527190662, "weight_mismatch_refit_ground_truth_assignment": 7.6903512523859625, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 28.635532158457643, "r2_milp": 0.8443036933414386, "weight_mismatch_milp": 7.680952657677606, "refit-weight_mismatch_milp": 0.009661896524711378, "rand_score_milp": 1.0, "label_mismatch_milp": 0.0, "mse_refit_milp_assignment": 28.635521237774928, "r2_refit_milp_assignment": 0.8443037527190662, "weight_mismatch_refit_milp_assignment": 7.6903512523859625, "refit-weight_mismatch_refit_milp_assignment": 0.0, "rand_score_refit_milp_assignment": 1.0, "label_mismatch_refit_milp_assignment": 0.0, "mse_greedy": 49.65764599873718, "r2_greedy": 0.7300028497260482, "weight_mismatch_greedy": 10.423381355324114, "refit-weight_mismatch_greedy": 8.123327442491883, "rand_score_greedy": 0.7625910364145658, "label_mismatch_greedy": 0.1975, "mse_greedy_sem": 4.907713175987816, "r2_greedy_sem": 0.02668407946507035, "weight_mismatch_greedy_sem": 0.8252739201862249, "refit-weight_mismatch_greedy_sem": 2.107718769720819, "rand_score_greedy_sem": 0.05460747730888983, "label_mismatch_greedy_sem": 0.04632747975140628, "mse_ground_truth": 45.97285934994606, "r2_ground_truth": 0.7668938862301123, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 183.66589822875957, "r2_baseline_sklearn": 0.001376965683556386, "mse_milp_val": 37.05591172572369, "r2_milp_val": 0.8287063447358249, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 37.05536349298298, "r2_refit_milp_assignment_val": 0.8287088789816637, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 91.68227169553496, "label_mismatch_greedy_val": 0.17375000000000002, "mse_greedy_val_sem": 13.668161755738403, "label_mismatch_greedy_val_sem": 0.041654713197655645, "r2_greedy_val": 0.5761920106596785, "r2_greedy_val_sem": 0.06318207483901035, "mse_refit_ground_truth_assignment_val": 37.05536349298298, "r2_refit_ground_truth_assignment_val": 0.8287088789816637, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 53.541644967786944, "r2_ground_truth_val": 0.7524998401531076, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 217.72563988966402, "r2_baseline_sklearn_val": -0.0064526539645859415, "random_state": 5}