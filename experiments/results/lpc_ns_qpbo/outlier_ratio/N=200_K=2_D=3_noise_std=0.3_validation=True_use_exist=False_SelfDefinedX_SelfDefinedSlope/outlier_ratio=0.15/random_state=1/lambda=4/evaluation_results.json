{"time_milp": 0.39757704734802246, "time_greedy": 1.0153557777404785, "time_refit_milp_assignment": 0.9047071933746338, "mse_refit_ground_truth_assignment": 14.482606774627918, "r2_refit_ground_truth_assignment": 0.8950262219004244, "weight_mismatch_refit_ground_truth_assignment": 3.2010480858204113, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 14.482612666153956, "r2_milp": 0.8950261791970798, "weight_mismatch_milp": 3.195538050598292, "refit-weight_mismatch_milp": 0.006314374065157447, "rand_score_milp": 1.0, "label_mismatch_milp": 0.0, "mse_refit_milp_assignment": 14.482606774627918, "r2_refit_milp_assignment": 0.8950262219004244, "weight_mismatch_refit_milp_assignment": 3.2010480858204113, "refit-weight_mismatch_refit_milp_assignment": 0.0, "rand_score_refit_milp_assignment": 1.0, "label_mismatch_refit_milp_assignment": 0.0, "mse_greedy": 28.54517280164206, "r2_greedy": 0.7930970106332532, "weight_mismatch_greedy": 9.123829357345198, "refit-weight_mismatch_greedy": 8.030412585031684, "rand_score_greedy": 0.8099299719887956, "label_mismatch_greedy": 0.1575, "mse_greedy_sem": 3.9663294714772817, "r2_greedy_sem": 0.028749008813667806, "weight_mismatch_greedy_sem": 2.053078754087827, "refit-weight_mismatch_greedy_sem": 2.5863144420930873, "rand_score_greedy_sem": 0.05356180098669339, "label_mismatch_greedy_sem": 0.0449857839793186, "mse_ground_truth": 14.371799695020052, "r2_ground_truth": 0.8849041772002351, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 137.80532855373428, "r2_baseline_sklearn": 0.0011504002247920697, "mse_milp_val": 12.355663173165336, "r2_milp_val": 0.8824205100044185, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 12.359447804806782, "r2_refit_milp_assignment_val": 0.882384494531029, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 34.59286043984552, "label_mismatch_greedy_val": 0.145, "mse_greedy_val_sem": 6.467060824202532, "label_mismatch_greedy_val_sem": 0.0418958608682855, "r2_greedy_val": 0.670805942910521, "r2_greedy_val_sem": 0.061542120631096583, "mse_refit_ground_truth_assignment_val": 12.359447804806782, "r2_refit_ground_truth_assignment_val": 0.882384494531029, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 6.344099811209434, "r2_ground_truth_val": 0.9396280062163613, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 105.31744354945639, "r2_baseline_sklearn_val": -0.002226357795017897, "random_state": 4}