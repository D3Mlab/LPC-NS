{"time_milp": 0.4198310375213623, "time_greedy": 0.9911430358886719, "time_refit_milp_assignment": 0.8454980850219727, "mse_refit_ground_truth_assignment": 28.19547011518946, "r2_refit_ground_truth_assignment": 0.8567968962346738, "weight_mismatch_refit_ground_truth_assignment": 7.904176397576691, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 28.195481634874188, "r2_milp": 0.8567968377268851, "weight_mismatch_milp": 7.894371183653718, "refit-weight_mismatch_milp": 0.010184192257372535, "rand_score_milp": 1.0, "label_mismatch_milp": 0.0, "mse_refit_milp_assignment": 28.19547011518946, "r2_refit_milp_assignment": 0.8567968962346738, "weight_mismatch_refit_milp_assignment": 7.904176397576691, "refit-weight_mismatch_refit_milp_assignment": 0.0, "rand_score_refit_milp_assignment": 1.0, "label_mismatch_refit_milp_assignment": 0.0, "mse_greedy": 49.12734450576402, "r2_greedy": 0.7504851600547047, "weight_mismatch_greedy": 12.454875942299049, "refit-weight_mismatch_greedy": 11.067521861869325, "rand_score_greedy": 0.7605392156862745, "label_mismatch_greedy": 0.20125, "mse_greedy_sem": 4.854190954425983, "r2_greedy_sem": 0.024654145084422218, "weight_mismatch_greedy_sem": 1.8617480599634044, "refit-weight_mismatch_greedy_sem": 3.1020726289726785, "rand_score_greedy_sem": 0.05506665930755794, "label_mismatch_greedy_sem": 0.047025076519208626, "mse_ground_truth": 46.58914403562617, "r2_ground_truth": 0.7705584140639088, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 187.37011025237177, "r2_baseline_sklearn": 0.048358433770675724, "mse_milp_val": 32.159477507067, "r2_milp_val": 0.8480363686270835, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 32.15616644006231, "r2_refit_milp_assignment_val": 0.8480520144585695, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 85.36305722454355, "label_mismatch_greedy_val": 0.1875, "mse_greedy_val_sem": 12.546484819093793, "label_mismatch_greedy_val_sem": 0.045918978991033185, "r2_greedy_val": 0.5966327451033645, "r2_greedy_val_sem": 0.05928608117640244, "mse_refit_ground_truth_assignment_val": 32.15616644006231, "r2_refit_ground_truth_assignment_val": 0.8480520144585695, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 50.2298555897293, "r2_ground_truth_val": 0.7626481569212347, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 212.73887575666555, "r2_baseline_sklearn_val": -0.005258001690806147, "random_state": 6}