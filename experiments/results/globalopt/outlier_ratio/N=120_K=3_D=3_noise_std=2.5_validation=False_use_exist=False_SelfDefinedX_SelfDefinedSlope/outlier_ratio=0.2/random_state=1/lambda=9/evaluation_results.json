{"time_milp": 18405.424188375473, "time_refit_milp_assignment": 18408.310670137405, "mse_refit_ground_truth_assignment": 135.43315001992988, "r2_refit_ground_truth_assignment": 0.6399521851711432, "weight_mismatch_refit_ground_truth_assignment": 9.986709302142394, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 41.99496419945464, "r2_milp": 0.8883567642663213, "weight_mismatch_milp": 68.08647082875851, "refit-weight_mismatch_milp": 68.5926602311859, "rand_score_milp": 0.6981792717086834, "label_mismatch_milp": 0.38333333333333336, "mse_refit_milp_assignment": 41.99172393456685, "r2_refit_milp_assignment": 0.8883653784814682, "weight_mismatch_refit_milp_assignment": 68.75396728378762, "refit-weight_mismatch_refit_milp_assignment": 69.25894124950531, "rand_score_refit_milp_assignment": 0.6981792717086834, "label_mismatch_refit_milp_assignment": 0.38333333333333336, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": 159.97224309992856, "r2_ground_truth": 0.5747152262727104, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 368.9962816416903, "r2_baseline_sklearn": 0.019062697069529122, "random_state": 9}