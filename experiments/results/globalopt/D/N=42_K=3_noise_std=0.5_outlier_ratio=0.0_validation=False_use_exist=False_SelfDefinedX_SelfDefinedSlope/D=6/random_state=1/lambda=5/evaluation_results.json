{"time_milp": 2.3390941619873047, "time_refit_milp_assignment": 2.993438243865967, "mse_refit_ground_truth_assignment": 0.07405086702240424, "r2_refit_ground_truth_assignment": 0.9996663955071015, "weight_mismatch_refit_ground_truth_assignment": 1.0624116226225662, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.9477794005220485, "r2_milp": 0.9957301854926939, "weight_mismatch_milp": 9.383212383652191, "refit-weight_mismatch_milp": 9.576188512919764, "rand_score_milp": 0.7804878048780488, "label_mismatch_milp": 0.23809523809523808, "mse_refit_milp_assignment": 0.3952389187377628, "r2_refit_milp_assignment": 0.998219420185595, "weight_mismatch_refit_milp_assignment": 2.3400458700284275, "refit-weight_mismatch_refit_milp_assignment": 2.138000177692895, "rand_score_refit_milp_assignment": 0.7804878048780488, "label_mismatch_refit_milp_assignment": 0.23809523809523808, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": 0.19512351284168786, "r2_ground_truth": 0.9991209545117893, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 191.89526577255936, "r2_baseline_sklearn": 0.13549799750055358, "random_state": 5}