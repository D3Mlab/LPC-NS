{"time_milp": 18371.301022529602, "time_greedy": 0.46485373973846433, "time_refit_milp_assignment": 18374.0055975914, "mse_refit_ground_truth_assignment": 7.943690502449783, "r2_refit_ground_truth_assignment": 0.9354223646338279, "weight_mismatch_refit_ground_truth_assignment": 4.7463855026048805, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.539699197456092, "r2_milp": 0.9630948563070257, "weight_mismatch_milp": 6.389576361268242, "refit-weight_mismatch_milp": 5.232174293365237, "rand_score_milp": 0.832942097026604, "label_mismatch_milp": 0.1527777777777778, "mse_refit_milp_assignment": 4.539668822700307, "r2_refit_milp_assignment": 0.9630951032363217, "weight_mismatch_refit_milp_assignment": 6.398168966944074, "refit-weight_mismatch_refit_milp_assignment": 5.243984200721918, "rand_score_refit_milp_assignment": 0.832942097026604, "label_mismatch_refit_milp_assignment": 0.1527777777777778, "mse_greedy": 11.288715687037463, "r2_greedy": 0.9082292336080975, "weight_mismatch_greedy": 21.753349782177672, "refit-weight_mismatch_greedy": 21.190103049451082, "rand_score_greedy": 0.7170579029733959, "label_mismatch_greedy": 0.3555555555555555, "mse_greedy_sem": 1.2920642574730936, "r2_greedy_sem": 0.010503739346721717, "weight_mismatch_greedy_sem": 3.089152903692581, "refit-weight_mismatch_greedy_sem": 3.0250029721815572, "rand_score_greedy_sem": 0.018639089278104103, "label_mismatch_greedy_sem": 0.0307674735215712, "mse_ground_truth": 9.766150650933355, "r2_ground_truth": 0.9204714116644204, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.66469409575194, "r2_baseline_sklearn": 0.04345370600172238, "mse_milp_val": 9.957804176502277, "r2_milp_val": 0.9186901749360268, "label_mismatch_milp_val": 0.20833333333333334, "mse_refit_milp_assignment_val": 9.962069733489125, "r2_refit_milp_assignment_val": 0.9186553447981516, "label_mismatch_refit_milp_assignment_val": 0.20833333333333334, "mse_greedy_val": 28.196660529066104, "label_mismatch_greedy_val": 0.3864583333333334, "mse_greedy_val_sem": 6.947404000926428, "label_mismatch_greedy_val_sem": 0.022543563658545658, "r2_greedy_val": 0.7697619380368339, "r2_greedy_val_sem": 0.05672859135923446, "mse_refit_ground_truth_assignment_val": 11.540473490371118, "r2_refit_ground_truth_assignment_val": 0.9057669879799647, "label_mismatch_refit_ground_truth_assignment_val": 0.25, "mse_ground_truth_val": 9.031629894313099, "r2_ground_truth_val": 0.9262527929117103, "label_mismatch_ground_truth_val": 0.25, "mse_baseline_sklearn_val": 122.5063806274945, "r2_baseline_sklearn_val": -0.0003181626675590188}