{"time_milp": 26017.58664083481, "time_greedy": 0.4866502404212952, "time_refit_milp_assignment": 26020.344340085983, "mse_refit_ground_truth_assignment": 5.730970020424371, "r2_refit_ground_truth_assignment": 0.9507264225978003, "weight_mismatch_refit_ground_truth_assignment": 3.3575680526691425, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.620335123909915, "r2_milp": 0.9602754089550761, "weight_mismatch_milp": 2.594434178141954, "refit-weight_mismatch_milp": 1.8604264363010459, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 4.620286053489788, "r2_refit_milp_assignment": 0.9602758308513931, "weight_mismatch_refit_milp_assignment": 2.614197514104324, "refit-weight_mismatch_refit_milp_assignment": 1.8400224284024036, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 10.385483093555141, "r2_greedy": 0.9107079773152202, "weight_mismatch_greedy": 16.183036701480003, "refit-weight_mismatch_greedy": 15.958928650971146, "rand_score_greedy": 0.7661189358372457, "label_mismatch_greedy": 0.2875, "mse_greedy_sem": 1.498829811339112, "r2_greedy_sem": 0.012886597985775784, "weight_mismatch_greedy_sem": 3.4535951369747875, "refit-weight_mismatch_greedy_sem": 3.581971582407074, "rand_score_greedy_sem": 0.025520984292229546, "label_mismatch_greedy_sem": 0.04149697414147188, "mse_ground_truth": 7.141246298992527, "r2_ground_truth": 0.9381302916021929, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.19922323433212, "r2_baseline_sklearn": 0.02673881244754417, "mse_milp_val": 4.62866495999431, "r2_milp_val": 0.9592124071221679, "label_mismatch_milp_val": 0.08333333333333333, "mse_refit_milp_assignment_val": 4.6366474789186105, "r2_refit_milp_assignment_val": 0.9591420655150656, "label_mismatch_refit_milp_assignment_val": 0.08333333333333333, "mse_greedy_val": 21.149379467395544, "label_mismatch_greedy_val": 0.2885416666666667, "mse_greedy_val_sem": 4.664666706183526, "label_mismatch_greedy_val_sem": 0.034738574365920774, "r2_greedy_val": 0.8136325945406145, "r2_greedy_val_sem": 0.041104838688265165, "mse_refit_ground_truth_assignment_val": 7.109919605234938, "r2_refit_ground_truth_assignment_val": 0.9373476998748262, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 8.082729921457956, "r2_ground_truth_val": 0.928775337980327, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 114.50804777619537, "r2_baseline_sklearn_val": -0.009039901202211542}