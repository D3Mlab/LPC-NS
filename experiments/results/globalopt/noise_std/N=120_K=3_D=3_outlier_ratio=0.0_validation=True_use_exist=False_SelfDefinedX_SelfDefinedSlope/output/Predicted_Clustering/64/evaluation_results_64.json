{"time_milp": 1776.901282787323, "time_greedy": 0.47652621269226075, "time_refit_milp_assignment": 1779.6607995033264, "mse_refit_ground_truth_assignment": 1.2014726082670435, "r2_refit_ground_truth_assignment": 0.9892279517985201, "weight_mismatch_refit_ground_truth_assignment": 0.8992422099018971, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.103471284180509, "r2_milp": 0.9901066026970967, "weight_mismatch_milp": 1.5678394244753302, "refit-weight_mismatch_milp": 0.7995002055219853, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 1.103434030515074, "r2_refit_milp_assignment": 0.9901069367024473, "weight_mismatch_refit_milp_assignment": 1.5664192666053596, "refit-weight_mismatch_refit_milp_assignment": 0.7706055079676233, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 5.378815621306356, "r2_greedy": 0.9517751293363593, "weight_mismatch_greedy": 9.360509387972517, "refit-weight_mismatch_greedy": 9.020958576861705, "rand_score_greedy": 0.8000782472613457, "label_mismatch_greedy": 0.24375, "mse_greedy_sem": 1.3833371806415724, "r2_greedy_sem": 0.012402592190814467, "weight_mismatch_greedy_sem": 1.9868335304104277, "refit-weight_mismatch_greedy_sem": 2.021021506768812, "rand_score_greedy_sem": 0.027894584061602615, "label_mismatch_greedy_sem": 0.0394059583886779, "mse_ground_truth": 1.1954882531886288, "r2_ground_truth": 0.9892708059146813, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 106.21621036961967, "r2_baseline_sklearn": 0.04769685966426451, "mse_milp_val": 1.576090603290896, "r2_milp_val": 0.9858245668078062, "label_mismatch_milp_val": 0.10416666666666667, "mse_refit_milp_assignment_val": 1.580315254027649, "r2_refit_milp_assignment_val": 0.9857865700999049, "label_mismatch_refit_milp_assignment_val": 0.10416666666666667, "mse_greedy_val": 10.420267542616813, "label_mismatch_greedy_val": 0.24374999999999997, "mse_greedy_val_sem": 3.477541169050499, "label_mismatch_greedy_val_sem": 0.03784864729867081, "r2_greedy_val": 0.9062796224489084, "r2_greedy_val_sem": 0.031277169226216525, "mse_refit_ground_truth_assignment_val": 1.5657317451850805, "r2_refit_ground_truth_assignment_val": 0.9859177348659874, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 1.4962557366673233, "r2_ground_truth_val": 0.9865426053621045, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 111.30637152311243, "r2_baseline_sklearn_val": -0.0010947531169145375}