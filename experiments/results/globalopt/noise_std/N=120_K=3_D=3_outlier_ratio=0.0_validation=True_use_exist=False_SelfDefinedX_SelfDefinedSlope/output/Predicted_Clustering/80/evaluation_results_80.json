{"time_milp": 12762.676701545715, "time_greedy": 0.48396323919296264, "time_refit_milp_assignment": 12765.370958328247, "mse_refit_ground_truth_assignment": 5.823542393480068, "r2_refit_ground_truth_assignment": 0.954775007164429, "weight_mismatch_refit_ground_truth_assignment": 3.2020132492582154, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.090141189062531, "r2_milp": 0.9682364111955425, "weight_mismatch_milp": 4.699039751554855, "refit-weight_mismatch_milp": 4.196732790751801, "rand_score_milp": 0.8748043818466353, "label_mismatch_milp": 0.1111111111111111, "mse_refit_milp_assignment": 4.090111372275988, "r2_refit_milp_assignment": 0.9682366427494433, "weight_mismatch_refit_milp_assignment": 4.681845118075157, "refit-weight_mismatch_refit_milp_assignment": 4.175975523378119, "rand_score_refit_milp_assignment": 0.8748043818466353, "label_mismatch_refit_milp_assignment": 0.1111111111111111, "mse_greedy": 8.645006602565832, "r2_greedy": 0.9328638249285819, "weight_mismatch_greedy": 15.511623340695994, "refit-weight_mismatch_greedy": 15.191517822237296, "rand_score_greedy": 0.7693661971830986, "label_mismatch_greedy": 0.2645833333333333, "mse_greedy_sem": 1.4626621199086032, "r2_greedy_sem": 0.011358873933464766, "weight_mismatch_greedy_sem": 2.1024194611742533, "refit-weight_mismatch_greedy_sem": 2.149929782247758, "rand_score_greedy_sem": 0.018825306073807346, "label_mismatch_greedy_sem": 0.027914048057337874, "mse_ground_truth": 8.37665319020262, "r2_ground_truth": 0.9336325374126864, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 126.73457376421844, "r2_baseline_sklearn": 0.01579317136544056, "mse_milp_val": 9.82994637128805, "r2_milp_val": 0.9192247458085564, "label_mismatch_milp_val": 0.08333333333333333, "mse_refit_milp_assignment_val": 9.828558388836194, "r2_refit_milp_assignment_val": 0.9192361512253437, "label_mismatch_refit_milp_assignment_val": 0.08333333333333333, "mse_greedy_val": 27.41334201446183, "label_mismatch_greedy_val": 0.28124999999999994, "mse_greedy_val_sem": 6.71471553072197, "label_mismatch_greedy_val_sem": 0.029790478138480722, "r2_greedy_val": 0.7747373601220384, "r2_greedy_val_sem": 0.055176583201056804, "mse_refit_ground_truth_assignment_val": 10.994009745038346, "r2_refit_ground_truth_assignment_val": 0.9096593309672028, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 10.456355118434693, "r2_ground_truth_val": 0.9140773804143458, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 122.85658802447313, "r2_baseline_sklearn_val": -0.00954488986392521}