{"time_milp": 11767.517142534256, "time_greedy": 0.47654922008514405, "time_refit_milp_assignment": 11770.23599743843, "mse_refit_ground_truth_assignment": 5.011362370533162, "r2_refit_ground_truth_assignment": 0.9598859519023044, "weight_mismatch_refit_ground_truth_assignment": 4.046616588946403, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.4851120320320716, "r2_milp": 0.9721030048633424, "weight_mismatch_milp": 4.242848302245932, "refit-weight_mismatch_milp": 2.0507499967631504, "rand_score_milp": 0.8513302034428795, "label_mismatch_milp": 0.1388888888888889, "mse_refit_milp_assignment": 3.4850658872834552, "r2_refit_milp_assignment": 0.9721033742344892, "weight_mismatch_refit_milp_assignment": 4.245971911462988, "refit-weight_mismatch_refit_milp_assignment": 2.0258341977356236, "rand_score_refit_milp_assignment": 0.8513302034428795, "label_mismatch_refit_milp_assignment": 0.1388888888888889, "mse_greedy": 10.114683634490575, "r2_greedy": 0.9190358078687966, "weight_mismatch_greedy": 18.018711222518984, "refit-weight_mismatch_greedy": 18.14311177863655, "rand_score_greedy": 0.7197378716744913, "label_mismatch_greedy": 0.36180555555555555, "mse_greedy_sem": 1.676204371185892, "r2_greedy_sem": 0.01341737790958527, "weight_mismatch_greedy_sem": 2.23879826628577, "refit-weight_mismatch_greedy_sem": 2.4293109565046542, "rand_score_greedy_sem": 0.019247898714745866, "label_mismatch_greedy_sem": 0.03071917582159219, "mse_ground_truth": 5.16910935107816, "r2_ground_truth": 0.9559057160796678, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 116.09575969333264, "r2_baseline_sklearn": 0.07069763789973371, "mse_milp_val": 5.632495204283686, "r2_milp_val": 0.9465350122335838, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 5.637066342806815, "r2_refit_milp_assignment_val": 0.9464916218965567, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 26.95569203514939, "label_mismatch_greedy_val": 0.3125, "mse_greedy_val_sem": 5.093939445549377, "label_mismatch_greedy_val_sem": 0.035638495186824125, "r2_greedy_val": 0.744130142570121, "r2_greedy_val_sem": 0.04835288806496162, "mse_refit_ground_truth_assignment_val": 6.00380680732597, "r2_refit_ground_truth_assignment_val": 0.9430104339438259, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 5.83078894391807, "r2_ground_truth_val": 0.9446527607661265, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 105.91324555089061, "r2_baseline_sklearn_val": -0.005353785898153607}