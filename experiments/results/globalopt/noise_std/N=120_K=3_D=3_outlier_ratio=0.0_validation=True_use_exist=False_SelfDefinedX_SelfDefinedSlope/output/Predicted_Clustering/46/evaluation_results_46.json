{"time_milp": 6656.461123466492, "time_greedy": 0.4676403641700745, "time_refit_milp_assignment": 6659.16123342514, "mse_refit_ground_truth_assignment": 2.362298916489836, "r2_refit_ground_truth_assignment": 0.979169703583207, "weight_mismatch_refit_ground_truth_assignment": 2.5373198787521436, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.0085153180226842, "r2_milp": 0.9822892991483698, "weight_mismatch_milp": 5.450289565304141, "refit-weight_mismatch_milp": 3.734690455079275, "rand_score_milp": 0.8137715179968701, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 2.008455756933658, "r2_refit_milp_assignment": 0.98228982434657, "weight_mismatch_refit_milp_assignment": 5.488810860850823, "refit-weight_mismatch_refit_milp_assignment": 3.732989915919477, "rand_score_refit_milp_assignment": 0.8137715179968701, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 5.920632363499784, "r2_greedy": 0.9477930052603958, "weight_mismatch_greedy": 11.796445981241657, "refit-weight_mismatch_greedy": 10.736899136703512, "rand_score_greedy": 0.7741588419405321, "label_mismatch_greedy": 0.26875000000000004, "mse_greedy_sem": 1.534351934107002, "r2_greedy_sem": 0.013529619546462656, "weight_mismatch_greedy_sem": 2.561093359564875, "refit-weight_mismatch_greedy_sem": 2.6979321964362257, "rand_score_greedy_sem": 0.02066164976428027, "label_mismatch_greedy_sem": 0.03079839374877971, "mse_ground_truth": 3.2449635676766007, "r2_ground_truth": 0.9722463163073335, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 112.87961567686885, "r2_baseline_sklearn": 0.004649311080117902, "mse_milp_val": 5.852595858947118, "r2_milp_val": 0.9521010865848163, "label_mismatch_milp_val": 0.14583333333333334, "mse_refit_milp_assignment_val": 5.850689439404834, "r2_refit_milp_assignment_val": 0.9521166891356825, "label_mismatch_refit_milp_assignment_val": 0.14583333333333334, "mse_greedy_val": 16.3067881623901, "label_mismatch_greedy_val": 0.23541666666666666, "mse_greedy_val_sem": 4.478390365484123, "label_mismatch_greedy_val_sem": 0.03322006523049177, "r2_greedy_val": 0.8665417101924098, "r2_greedy_val_sem": 0.036652117714191114, "mse_refit_ground_truth_assignment_val": 3.939938032570423, "r2_refit_ground_truth_assignment_val": 0.9677546929206161, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 3.991073715057123, "r2_ground_truth_val": 0.9673361874083806, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 122.19078093558126, "r2_baseline_sklearn_val": -3.5843448793038135e-05}