{"time_milp": 12078.708760023117, "time_greedy": 0.47141193151474, "time_refit_milp_assignment": 12081.456960201263, "mse_refit_ground_truth_assignment": 4.415772932908744, "r2_refit_ground_truth_assignment": 0.9623547915970968, "weight_mismatch_refit_ground_truth_assignment": 4.191078567562805, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.161998317734197, "r2_milp": 0.9730434314786374, "weight_mismatch_milp": 4.224694652228386, "refit-weight_mismatch_milp": 0.7395742709328155, "rand_score_milp": 0.8877151799687011, "label_mismatch_milp": 0.09722222222222222, "mse_refit_milp_assignment": 3.161950907534935, "r2_refit_milp_assignment": 0.9730438356585757, "weight_mismatch_refit_milp_assignment": 4.21856598237616, "refit-weight_mismatch_refit_milp_assignment": 0.7060698591034885, "rand_score_refit_milp_assignment": 0.8877151799687011, "label_mismatch_refit_milp_assignment": 0.09722222222222222, "mse_greedy": 7.120979469342622, "r2_greedy": 0.9392924499902635, "weight_mismatch_greedy": 15.223103174092296, "refit-weight_mismatch_greedy": 14.139311348527766, "rand_score_greedy": 0.758528951486698, "label_mismatch_greedy": 0.3006944444444445, "mse_greedy_sem": 1.0729035885097327, "r2_greedy_sem": 0.009146683898681845, "weight_mismatch_greedy_sem": 2.102514346575542, "refit-weight_mismatch_greedy_sem": 2.418433616881685, "rand_score_greedy_sem": 0.020696394787210377, "label_mismatch_greedy_sem": 0.03220045834369224, "mse_ground_truth": 4.914509257809676, "r2_ground_truth": 0.9573579348094251, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.36273813128292, "r2_baseline_sklearn": 0.05061389048631315, "mse_milp_val": 4.3912240759560435, "r2_milp_val": 0.9607310015533458, "label_mismatch_milp_val": 0.1875, "mse_refit_milp_assignment_val": 4.387917910739005, "r2_refit_milp_assignment_val": 0.9607605672950448, "label_mismatch_refit_milp_assignment_val": 0.1875, "mse_greedy_val": 20.316923195816393, "label_mismatch_greedy_val": 0.290625, "mse_greedy_val_sem": 4.95992892776211, "label_mismatch_greedy_val_sem": 0.024948549029637185, "r2_greedy_val": 0.8183137066983749, "r2_greedy_val_sem": 0.04435470337901185, "mse_refit_ground_truth_assignment_val": 6.056679671573714, "r2_refit_ground_truth_assignment_val": 0.9458374839222641, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 6.51934463287349, "r2_ground_truth_val": 0.9417000522329811, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 112.4188372457419, "r2_baseline_sklearn_val": -0.005317667424336037}