{"time_milp": 21110.755553245544, "time_greedy": 0.493445611000061, "time_refit_milp_assignment": 21113.52223300934, "mse_refit_ground_truth_assignment": 7.967024108919448, "r2_refit_ground_truth_assignment": 0.9382268991659877, "weight_mismatch_refit_ground_truth_assignment": 5.1022556991067844, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.009096756483481, "r2_milp": 0.9611614782639907, "weight_mismatch_milp": 3.9931877620575076, "refit-weight_mismatch_milp": 4.716822025080544, "rand_score_milp": 0.8063380281690141, "label_mismatch_milp": 0.20833333333333334, "mse_refit_milp_assignment": 5.009057633838833, "r2_refit_milp_assignment": 0.9611617816052433, "weight_mismatch_refit_milp_assignment": 3.9884671406266863, "refit-weight_mismatch_refit_milp_assignment": 4.688111778859771, "rand_score_refit_milp_assignment": 0.8063380281690141, "label_mismatch_refit_milp_assignment": 0.20833333333333334, "mse_greedy": 14.200101802055453, "r2_greedy": 0.8898981214968883, "weight_mismatch_greedy": 22.16231123762348, "refit-weight_mismatch_greedy": 22.03187479392088, "rand_score_greedy": 0.6892410015649453, "label_mismatch_greedy": 0.3979166666666666, "mse_greedy_sem": 1.8510025819196179, "r2_greedy_sem": 0.014351929600530057, "weight_mismatch_greedy_sem": 2.3654267504312965, "refit-weight_mismatch_greedy_sem": 2.5374975850362986, "rand_score_greedy_sem": 0.016642642988365163, "label_mismatch_greedy_sem": 0.025155361150396703, "mse_ground_truth": 8.217809006156392, "r2_ground_truth": 0.9317656064770126, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 119.57109697584694, "r2_baseline_sklearn": 0.0728938020843718, "mse_milp_val": 9.004732106793854, "r2_milp_val": 0.9160259697838803, "label_mismatch_milp_val": 0.14583333333333334, "mse_refit_milp_assignment_val": 9.008220572810387, "r2_refit_milp_assignment_val": 0.915993437938712, "label_mismatch_refit_milp_assignment_val": 0.14583333333333334, "mse_greedy_val": 37.489825998556725, "label_mismatch_greedy_val": 0.3572916666666666, "mse_greedy_val_sem": 5.219707036190006, "label_mismatch_greedy_val_sem": 0.03127831319719764, "r2_greedy_val": 0.650386958338866, "r2_greedy_val_sem": 0.04867661038417903, "mse_refit_ground_truth_assignment_val": 10.396152641982633, "r2_refit_ground_truth_assignment_val": 0.9030502156271168, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 10.768742144179479, "r2_ground_truth_val": 0.8995756156340664, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 107.9072987068288, "r2_baseline_sklearn_val": -0.006294318884898065}