{"time_milp": 25667.21156978607, "time_greedy": 0.5539579749107361, "time_refit_milp_assignment": 25670.297330141068, "mse_refit_ground_truth_assignment": 6.403933766503624, "r2_refit_ground_truth_assignment": 0.949515644760212, "weight_mismatch_refit_ground_truth_assignment": 4.574436144026592, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.232702869075526, "r2_milp": 0.9666321853007631, "weight_mismatch_milp": 4.539982342980331, "refit-weight_mismatch_milp": 2.3664781782525357, "rand_score_milp": 0.8407668231611893, "label_mismatch_milp": 0.1527777777777778, "mse_refit_milp_assignment": 4.232656792673462, "r2_refit_milp_assignment": 0.9666325485364765, "weight_mismatch_refit_milp_assignment": 4.543323534421125, "refit-weight_mismatch_refit_milp_assignment": 2.3399156495111435, "rand_score_refit_milp_assignment": 0.8407668231611893, "label_mismatch_refit_milp_assignment": 0.1527777777777778, "mse_greedy": 11.703868261486111, "r2_greedy": 0.9077344856245849, "weight_mismatch_greedy": 21.873157957618197, "refit-weight_mismatch_greedy": 22.526691217486714, "rand_score_greedy": 0.6978482003129891, "label_mismatch_greedy": 0.3909722222222222, "mse_greedy_sem": 1.810992524351426, "r2_greedy_sem": 0.014276660763447338, "weight_mismatch_greedy_sem": 2.900877992234463, "refit-weight_mismatch_greedy_sem": 3.0767482614218276, "rand_score_greedy_sem": 0.017418680383917307, "label_mismatch_greedy_sem": 0.026299768718239296, "mse_ground_truth": 6.605515919336174, "r2_ground_truth": 0.9443719771597339, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.74284261273591, "r2_baseline_sklearn": 0.07179372708453713, "mse_milp_val": 7.438931697046789, "r2_milp_val": 0.9299690386383782, "label_mismatch_milp_val": 0.08333333333333333, "mse_refit_milp_assignment_val": 7.444309895717818, "r2_refit_milp_assignment_val": 0.929918407655508, "label_mismatch_refit_milp_assignment_val": 0.08333333333333333, "mse_greedy_val": 31.496033192132423, "label_mismatch_greedy_val": 0.353125, "mse_greedy_val_sem": 5.078933517388973, "label_mismatch_greedy_val_sem": 0.0320431153141371, "r2_greedy_val": 0.7034927092557884, "r2_greedy_val_sem": 0.04781366618216388, "mse_refit_ground_truth_assignment_val": 9.237793890186198, "r2_refit_ground_truth_assignment_val": 0.9130343423845277, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 9.698841224253563, "r2_ground_truth_val": 0.9086939895821531, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 106.84169814606882, "r2_baseline_sklearn_val": -0.005820074628162475}