{"time_milp": 6206.143426179886, "time_greedy": 0.47674992084503176, "time_refit_milp_assignment": 6208.896144151688, "mse_refit_ground_truth_assignment": 3.3389587394395037, "r2_refit_ground_truth_assignment": 0.9711420767897517, "weight_mismatch_refit_ground_truth_assignment": 3.644416145704805, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.4379992181218757, "r2_milp": 0.9789288818121135, "weight_mismatch_milp": 3.8882496862662537, "refit-weight_mismatch_milp": 0.8007669525184193, "rand_score_milp": 0.9014084507042254, "label_mismatch_milp": 0.08333333333333333, "mse_refit_milp_assignment": 2.437951596687296, "r2_refit_milp_assignment": 0.9789292933942292, "weight_mismatch_refit_milp_assignment": 3.8820538532757958, "refit-weight_mismatch_refit_milp_assignment": 0.7718449526496889, "rand_score_refit_milp_assignment": 0.9014084507042254, "label_mismatch_refit_milp_assignment": 0.08333333333333333, "mse_greedy": 5.80730996153394, "r2_greedy": 0.94980863256903, "weight_mismatch_greedy": 15.46048599118052, "refit-weight_mismatch_greedy": 14.906785040859313, "rand_score_greedy": 0.762460876369327, "label_mismatch_greedy": 0.2951388888888889, "mse_greedy_sem": 0.7560149213448775, "r2_greedy_sem": 0.006534079109235909, "weight_mismatch_greedy_sem": 2.1269017144401454, "refit-weight_mismatch_greedy_sem": 2.415629249987591, "rand_score_greedy_sem": 0.017220837533938056, "label_mismatch_greedy_sem": 0.028745479487532664, "mse_ground_truth": 3.716075053164218, "r2_ground_truth": 0.9674584228728109, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.48988883422828, "r2_baseline_sklearn": 0.05370175229922969, "mse_milp_val": 3.914236982950689, "r2_milp_val": 0.9649319508189377, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 3.913577254249201, "r2_refit_milp_assignment_val": 0.9649378613958012, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 13.5537054776751, "label_mismatch_greedy_val": 0.30104166666666665, "mse_greedy_val_sem": 2.480542654185298, "label_mismatch_greedy_val_sem": 0.0257594355477142, "r2_greedy_val": 0.878570967382142, "r2_greedy_val_sem": 0.02222343516031024, "mse_refit_ground_truth_assignment_val": 4.128677328934891, "r2_refit_ground_truth_assignment_val": 0.9630107578425969, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 3.997414523911695, "r2_ground_truth_val": 0.9641867547283878, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 112.14893959228004, "r2_baseline_sklearn_val": -0.004753811881198944}