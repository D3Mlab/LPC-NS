{"time_milp": 13828.411437988281, "time_greedy": 0.4757463335990906, "time_refit_milp_assignment": 13831.192416191101, "mse_refit_ground_truth_assignment": 4.339064842602691, "r2_refit_ground_truth_assignment": 0.9637396511423355, "weight_mismatch_refit_ground_truth_assignment": 3.323267814126435, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.9569298831841597, "r2_milp": 0.9752897656519929, "weight_mismatch_milp": 3.989152334651857, "refit-weight_mismatch_milp": 1.4361276051038208, "rand_score_milp": 0.8748043818466353, "label_mismatch_milp": 0.1111111111111111, "mse_refit_milp_assignment": 2.956883613832075, "r2_refit_milp_assignment": 0.9752901523120012, "weight_mismatch_refit_milp_assignment": 3.990903548781295, "refit-weight_mismatch_refit_milp_assignment": 1.4015641384940392, "rand_score_refit_milp_assignment": 0.8748043818466353, "label_mismatch_refit_milp_assignment": 0.1111111111111111, "mse_greedy": 8.950941288553489, "r2_greedy": 0.9251994921715114, "weight_mismatch_greedy": 18.329103527944245, "refit-weight_mismatch_greedy": 17.63884150093671, "rand_score_greedy": 0.7298904538341158, "label_mismatch_greedy": 0.33194444444444443, "mse_greedy_sem": 1.7929526534642959, "r2_greedy_sem": 0.014983202846282899, "weight_mismatch_greedy_sem": 2.6423472212341963, "refit-weight_mismatch_greedy_sem": 2.802385087291735, "rand_score_greedy_sem": 0.02078309019076382, "label_mismatch_greedy_sem": 0.03179790952299362, "mse_ground_truth": 5.519414190701667, "r2_ground_truth": 0.9545737261399825, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.8583222520023, "r2_baseline_sklearn": 0.06523134946797671, "mse_milp_val": 8.620656729093641, "r2_milp_val": 0.9306082990339931, "label_mismatch_milp_val": 0.16666666666666666, "mse_refit_milp_assignment_val": 8.64525476330607, "r2_refit_milp_assignment_val": 0.93041029794335, "label_mismatch_refit_milp_assignment_val": 0.16666666666666666, "mse_greedy_val": 28.41003868079365, "label_mismatch_greedy_val": 0.3177083333333333, "mse_greedy_val_sem": 7.186909875597745, "label_mismatch_greedy_val_sem": 0.022765399887055438, "r2_greedy_val": 0.771314301157936, "r2_greedy_val_sem": 0.05785080146783133, "mse_refit_ground_truth_assignment_val": 8.910021004884934, "r2_refit_ground_truth_assignment_val": 0.9282790705393485, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 7.541046571574378, "r2_ground_truth_val": 0.9392985865103066, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 124.2876000190792, "r2_baseline_sklearn_val": -0.0004490661598794965}