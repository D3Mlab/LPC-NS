{"time_milp": 2055.5253553390503, "time_greedy": 0.47827935218811035, "time_refit_milp_assignment": 2058.2618613243103, "mse_refit_ground_truth_assignment": 1.6360897823253577, "r2_refit_ground_truth_assignment": 0.9855265068202065, "weight_mismatch_refit_ground_truth_assignment": 2.551091301988807, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.2214062646237347, "r2_milp": 0.9891949601838702, "weight_mismatch_milp": 2.1899970570265315, "refit-weight_mismatch_milp": 0.5838498821032627, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 1.2213582909607985, "r2_refit_milp_assignment": 0.9891953845777456, "weight_mismatch_refit_milp_assignment": 2.1810469742733556, "refit-weight_mismatch_refit_milp_assignment": 0.5447622197464479, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 3.89167274467329, "r2_greedy": 0.9655727335159069, "weight_mismatch_greedy": 11.722331953627501, "refit-weight_mismatch_greedy": 11.014816752357953, "rand_score_greedy": 0.8055555555555556, "label_mismatch_greedy": 0.2263888888888889, "mse_greedy_sem": 0.7478865955643192, "r2_greedy_sem": 0.006616098735592834, "weight_mismatch_greedy_sem": 2.152851925298588, "refit-weight_mismatch_greedy_sem": 2.3452855135948134, "rand_score_greedy_sem": 0.02193712410411333, "label_mismatch_greedy_sem": 0.032558302281190867, "mse_ground_truth": 1.8208767760504665, "r2_ground_truth": 0.9838263772465263, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 106.22751057031242, "r2_baseline_sklearn": 0.060269695248234334, "mse_milp_val": 1.944530928723945, "r2_milp_val": 0.9825843411605824, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.9440848856197779, "r2_refit_milp_assignment_val": 0.9825883360235156, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 9.23690126071481, "label_mismatch_greedy_val": 0.2041666666666667, "mse_greedy_val_sem": 2.240092528858162, "label_mismatch_greedy_val_sem": 0.033408632056796825, "r2_greedy_val": 0.9172722229748429, "r2_greedy_val_sem": 0.02006277538456197, "mse_refit_ground_truth_assignment_val": 2.309049928062524, "r2_refit_ground_truth_assignment_val": 0.9793196265503947, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 2.3332152711562046, "r2_ground_truth_val": 0.9791031962715855, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 112.06786471980661, "r2_baseline_sklearn_val": -0.0037051455401375666}