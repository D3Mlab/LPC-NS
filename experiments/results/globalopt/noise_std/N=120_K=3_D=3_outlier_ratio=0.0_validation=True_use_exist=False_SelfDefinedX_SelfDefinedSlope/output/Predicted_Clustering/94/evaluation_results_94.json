{"time_milp": 952.3202750682831, "time_greedy": 0.5573203086853027, "time_refit_milp_assignment": 955.4381527900696, "mse_refit_ground_truth_assignment": 1.0258097225907528, "r2_refit_ground_truth_assignment": 0.9910092659395239, "weight_mismatch_refit_ground_truth_assignment": 1.4205095607555651, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.0093324650824005, "r2_milp": 0.9911536812604563, "weight_mismatch_milp": 1.6752804136350674, "refit-weight_mismatch_milp": 0.6433498209551682, "rand_score_milp": 0.9640062597809077, "label_mismatch_milp": 0.027777777777777776, "mse_refit_milp_assignment": 1.0092881242004852, "r2_refit_milp_assignment": 0.9911540698871856, "weight_mismatch_refit_milp_assignment": 1.6895770477439163, "refit-weight_mismatch_refit_milp_assignment": 0.6111323594882593, "rand_score_refit_milp_assignment": 0.9640062597809077, "label_mismatch_refit_milp_assignment": 0.027777777777777776, "mse_greedy": 5.066534547258605, "r2_greedy": 0.9555942357345056, "weight_mismatch_greedy": 12.473879053682621, "refit-weight_mismatch_greedy": 11.93835998022138, "rand_score_greedy": 0.8390258215962442, "label_mismatch_greedy": 0.1965277777777778, "mse_greedy_sem": 1.4106293085699495, "r2_greedy_sem": 0.012363494605251964, "weight_mismatch_greedy_sem": 3.7542015134884097, "refit-weight_mismatch_greedy_sem": 3.871823314493494, "rand_score_greedy_sem": 0.03036614701994419, "label_mismatch_greedy_sem": 0.04408520522820547, "mse_ground_truth": 1.2782408316244023, "r2_ground_truth": 0.9885223527945853, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.83544551120625, "r2_baseline_sklearn": 0.02858006400159374, "mse_milp_val": 1.3053450310438033, "r2_milp_val": 0.9877803212532714, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.3097668584875404, "r2_refit_milp_assignment_val": 0.9877389273615792, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 10.541989454689856, "label_mismatch_greedy_val": 0.20833333333333334, "mse_greedy_val_sem": 3.975274890988748, "label_mismatch_greedy_val_sem": 0.037633776977479196, "r2_greedy_val": 0.9013136592823268, "r2_greedy_val_sem": 0.037213595595468975, "mse_refit_ground_truth_assignment_val": 1.237333620229781, "r2_refit_ground_truth_assignment_val": 0.9884169939884444, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 1.2173246429995945, "r2_ground_truth_val": 0.9886043032959368, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 107.58049736386818, "r2_baseline_sklearn_val": -0.007089379386955752}