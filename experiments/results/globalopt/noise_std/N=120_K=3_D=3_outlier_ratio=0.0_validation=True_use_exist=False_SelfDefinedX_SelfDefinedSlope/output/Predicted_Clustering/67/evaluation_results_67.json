{"time_milp": 12505.502991199493, "time_greedy": 0.5759241580963135, "time_refit_milp_assignment": 12508.87031173706, "mse_refit_ground_truth_assignment": 3.9718102752629525, "r2_refit_ground_truth_assignment": 0.9656195904690807, "weight_mismatch_refit_ground_truth_assignment": 1.6349858361791783, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.9091268337472993, "r2_milp": 0.9748182906558907, "weight_mismatch_milp": 2.4711156295026653, "refit-weight_mismatch_milp": 1.2210815659677217, "rand_score_milp": 0.9014084507042254, "label_mismatch_milp": 0.08333333333333333, "mse_refit_milp_assignment": 2.9090767105747495, "r2_refit_milp_assignment": 0.9748187245273698, "weight_mismatch_refit_milp_assignment": 2.46495416744484, "refit-weight_mismatch_refit_milp_assignment": 1.198432220242999, "rand_score_refit_milp_assignment": 0.9014084507042254, "label_mismatch_refit_milp_assignment": 0.08333333333333333, "mse_greedy": 7.757882683352058, "r2_greedy": 0.9328469475474096, "weight_mismatch_greedy": 13.908225711848058, "refit-weight_mismatch_greedy": 13.338792889424724, "rand_score_greedy": 0.7536189358372457, "label_mismatch_greedy": 0.3104166666666666, "mse_greedy_sem": 1.3932387144188385, "r2_greedy_sem": 0.012060021566080456, "weight_mismatch_greedy_sem": 2.6174516371060723, "refit-weight_mismatch_greedy_sem": 2.6420508007623518, "rand_score_greedy_sem": 0.020666289122536593, "label_mismatch_greedy_sem": 0.03204242220849813, "mse_ground_truth": 3.952027283268194, "r2_ground_truth": 0.9650896016367458, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.77090328587008, "r2_baseline_sklearn": 0.04981145926027608, "mse_milp_val": 3.657568040049263, "r2_milp_val": 0.9666314278824508, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 3.658382002876285, "r2_refit_milp_assignment_val": 0.9666240019707529, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 15.98735389542179, "label_mismatch_greedy_val": 0.3104166666666667, "mse_greedy_val_sem": 4.135763384376441, "label_mismatch_greedy_val_sem": 0.03426267533413921, "r2_greedy_val": 0.8541448400722093, "r2_greedy_val_sem": 0.03773122392846192, "mse_refit_ground_truth_assignment_val": 4.360924784916186, "r2_refit_ground_truth_assignment_val": 0.9602145929778183, "label_mismatch_refit_ground_truth_assignment_val": 0.16666666666666666, "mse_ground_truth_val": 4.263602431868547, "r2_ground_truth_val": 0.9611024802080108, "label_mismatch_ground_truth_val": 0.16666666666666666, "mse_baseline_sklearn_val": 109.80230206049835, "r2_baseline_sklearn_val": -0.0017437802549540304}