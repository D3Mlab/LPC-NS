{"time_milp": 895.7137608528137, "time_greedy": 0.5426334857940673, "time_refit_milp_assignment": 898.8463218212128, "mse_refit_ground_truth_assignment": 0.9924893118240562, "r2_refit_ground_truth_assignment": 0.9913023848578362, "weight_mismatch_refit_ground_truth_assignment": 1.5893889545887974, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.7416859012146799, "r2_milp": 0.9935002841357774, "weight_mismatch_milp": 2.0644968671981774, "refit-weight_mismatch_milp": 0.9952423534722735, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 0.7416397363524935, "r2_refit_milp_assignment": 0.9935006886985265, "weight_mismatch_refit_milp_assignment": 2.0587956978518833, "refit-weight_mismatch_refit_milp_assignment": 0.9598767701119235, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 5.190372225904808, "r2_greedy": 0.9545145126222792, "weight_mismatch_greedy": 13.139192943233528, "refit-weight_mismatch_greedy": 12.410049922396402, "rand_score_greedy": 0.7813380281690141, "label_mismatch_greedy": 0.26041666666666663, "mse_greedy_sem": 1.4276508836951234, "r2_greedy_sem": 0.012511125103130053, "weight_mismatch_greedy_sem": 2.475124600944674, "refit-weight_mismatch_greedy_sem": 2.558468066866836, "rand_score_greedy_sem": 0.02474263639679375, "label_mismatch_greedy_sem": 0.03610373012736789, "mse_ground_truth": 1.2624747014648428, "r2_ground_truth": 0.9890093409437852, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 105.40883925653267, "r2_baseline_sklearn": 0.07625653444008651, "mse_milp_val": 2.979024777649324, "r2_milp_val": 0.9743168251068973, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 2.9910561021887534, "r2_refit_milp_assignment_val": 0.9742130990101356, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 20.519895731596044, "label_mismatch_greedy_val": 0.24479166666666666, "mse_greedy_val_sem": 7.517238990422725, "label_mismatch_greedy_val_sem": 0.030185638783081763, "r2_greedy_val": 0.8230910750333983, "r2_greedy_val_sem": 0.06480864649156136, "mse_refit_ground_truth_assignment_val": 2.8114900832311496, "r2_refit_ground_truth_assignment_val": 0.9757611980740801, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 2.4808118426769643, "r2_ground_truth_val": 0.978612086441715, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 116.02082506425597, "r2_baseline_sklearn_val": -0.00025456777792465246}