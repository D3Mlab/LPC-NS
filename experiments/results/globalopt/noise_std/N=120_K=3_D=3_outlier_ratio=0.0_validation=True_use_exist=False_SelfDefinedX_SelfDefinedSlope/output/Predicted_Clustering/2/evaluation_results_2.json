{"time_milp": 236.58288192749023, "time_greedy": 0.4732991337776184, "time_refit_milp_assignment": 239.3749134540558, "mse_refit_ground_truth_assignment": 0.2631099384322978, "r2_refit_ground_truth_assignment": 0.9976893277446811, "weight_mismatch_refit_ground_truth_assignment": 0.5122428613449738, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.2580691821397465, "r2_milp": 0.9977335964476439, "weight_mismatch_milp": 0.5189387679589356, "refit-weight_mismatch_milp": 0.15525004214345728, "rand_score_milp": 0.9816118935837246, "label_mismatch_milp": 0.013888888888888888, "mse_refit_milp_assignment": 0.25801421697363336, "r2_refit_milp_assignment": 0.997734079160251, "weight_mismatch_refit_milp_assignment": 0.546205414975016, "refit-weight_mismatch_refit_milp_assignment": 0.14137849963697907, "rand_score_refit_milp_assignment": 0.9816118935837246, "label_mismatch_refit_milp_assignment": 0.013888888888888888, "mse_greedy": 6.17868778045801, "r2_greedy": 0.9457378063571097, "weight_mismatch_greedy": 15.038431900638608, "refit-weight_mismatch_greedy": 14.940219588387162, "rand_score_greedy": 0.7938575899843505, "label_mismatch_greedy": 0.24583333333333335, "mse_greedy_sem": 1.7921923185091804, "r2_greedy_sem": 0.015739310689856043, "weight_mismatch_greedy_sem": 3.210540068173531, "refit-weight_mismatch_greedy_sem": 3.2681820646815005, "rand_score_greedy_sem": 0.030698556478210605, "label_mismatch_greedy_sem": 0.04038099297803532, "mse_ground_truth": 0.3079237107843207, "r2_ground_truth": 0.9972735582535627, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 106.32610617901041, "r2_baseline_sklearn": 0.06622765742788495, "mse_milp_val": 0.356906901392169, "r2_milp_val": 0.9967963258438615, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 0.35865195067455025, "r2_refit_milp_assignment_val": 0.9967806619010647, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 13.374355059607604, "label_mismatch_greedy_val": 0.21458333333333335, "mse_greedy_val_sem": 4.286773008726836, "label_mismatch_greedy_val_sem": 0.04036055971739929, "r2_greedy_val": 0.8799488732429813, "r2_greedy_val_sem": 0.0384790090853421, "mse_refit_ground_truth_assignment_val": 0.36228072992422344, "r2_refit_ground_truth_assignment_val": 0.9967480891874099, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.3457589145853495, "r2_ground_truth_val": 0.996896392603811, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 111.65085453053668, "r2_baseline_sklearn_val": -0.00220241125916254}