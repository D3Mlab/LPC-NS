{"time_milp": 1985.3860795497894, "time_greedy": 0.4812069654464722, "time_refit_milp_assignment": 1988.2096655368805, "mse_refit_ground_truth_assignment": 1.2002476338506205, "r2_refit_ground_truth_assignment": 0.9890648950494658, "weight_mismatch_refit_ground_truth_assignment": 1.8483010525302035, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.1355919954508944, "r2_milp": 0.9896539536500452, "weight_mismatch_milp": 2.164959522776514, "refit-weight_mismatch_milp": 0.5165488130957895, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 1.1355497485062402, "r2_refit_milp_assignment": 0.9896543385495947, "weight_mismatch_refit_milp_assignment": 2.163875833377145, "refit-weight_mismatch_refit_milp_assignment": 0.49445492121427714, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 4.970080217915209, "r2_greedy": 0.9547190535830368, "weight_mismatch_greedy": 10.263509499766194, "refit-weight_mismatch_greedy": 9.418589873330788, "rand_score_greedy": 0.8300273865414711, "label_mismatch_greedy": 0.19027777777777777, "mse_greedy_sem": 1.4783641274678547, "r2_greedy_sem": 0.013468942935635804, "weight_mismatch_greedy_sem": 2.69004423692215, "refit-weight_mismatch_greedy_sem": 2.796855148500969, "rand_score_greedy_sem": 0.02724380175883068, "label_mismatch_greedy_sem": 0.03642882055271072, "mse_ground_truth": 1.5204646338667667, "r2_ground_truth": 0.9865357571208291, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.6796389801541, "r2_baseline_sklearn": 0.0007409059937749651, "mse_milp_val": 1.9640673708458312, "r2_milp_val": 0.9832975989666709, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 1.9710397433151385, "r2_refit_milp_assignment_val": 0.9832383060101946, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 13.39169308265069, "label_mismatch_greedy_val": 0.240625, "mse_greedy_val_sem": 4.7529227494131066, "label_mismatch_greedy_val_sem": 0.03257340310609686, "r2_greedy_val": 0.8861172321775472, "r2_greedy_val_sem": 0.04041878757292496, "mse_refit_ground_truth_assignment_val": 2.3244537748445246, "r2_refit_ground_truth_assignment_val": 0.9802328781042937, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 1.6010751244924715, "r2_ground_truth_val": 0.9863844798754311, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 117.72884729884582, "r2_baseline_sklearn_val": -0.0011644457644395256}