{"time_milp": 447.75438046455383, "time_greedy": 0.47939610481262207, "time_refit_milp_assignment": 450.48662209510803, "mse_refit_ground_truth_assignment": 0.6761391447364999, "r2_refit_ground_truth_assignment": 0.9939283984204867, "weight_mismatch_refit_ground_truth_assignment": 1.6399872655588075, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.6301344395108404, "r2_milp": 0.9943415119683231, "weight_mismatch_milp": 1.6800419877645454, "refit-weight_mismatch_milp": 0.9264675114000163, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 0.6300869908408759, "r2_refit_milp_assignment": 0.9943419380484011, "weight_mismatch_refit_milp_assignment": 1.660815199220554, "refit-weight_mismatch_refit_milp_assignment": 0.8878452619439359, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 3.422677897005048, "r2_greedy": 0.969265000129937, "weight_mismatch_greedy": 8.665169616981622, "refit-weight_mismatch_greedy": 8.075702759044365, "rand_score_greedy": 0.8480242566510171, "label_mismatch_greedy": 0.16666666666666666, "mse_greedy_sem": 1.0417073926415819, "r2_greedy_sem": 0.009354335272243575, "weight_mismatch_greedy_sem": 2.4105631441951334, "refit-weight_mismatch_greedy_sem": 2.5525034137353204, "rand_score_greedy_sem": 0.0259291257397629, "label_mismatch_greedy_sem": 0.03292883223260019, "mse_ground_truth": 0.7525051982657541, "r2_ground_truth": 0.9932661113149157, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 104.00113272372771, "r2_baseline_sklearn": 0.06608950741546515, "mse_milp_val": 1.2734315317956997, "r2_milp_val": 0.9886442603936837, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.2741041844886387, "r2_refit_milp_assignment_val": 0.9886382620587628, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 8.450326776091078, "label_mismatch_greedy_val": 0.15416666666666665, "mse_greedy_val_sem": 2.9731145685801033, "label_mismatch_greedy_val_sem": 0.033640307989633904, "r2_greedy_val": 0.9246447821798023, "r2_greedy_val_sem": 0.026512548195608648, "mse_refit_ground_truth_assignment_val": 1.0521758258066078, "r2_refit_ground_truth_assignment_val": 0.9906172931959112, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 1.0714600685944966, "r2_ground_truth_val": 0.9904453272643817, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 112.46751758338921, "r2_baseline_sklearn_val": -0.002921485731413709}