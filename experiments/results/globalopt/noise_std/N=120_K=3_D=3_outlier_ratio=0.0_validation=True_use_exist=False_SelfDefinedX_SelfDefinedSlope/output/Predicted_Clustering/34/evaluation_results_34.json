{"time_milp": 1019.4272911548615, "time_greedy": 0.47668594121932983, "time_refit_milp_assignment": 1022.1941039562225, "mse_refit_ground_truth_assignment": 1.0100350186804503, "r2_refit_ground_truth_assignment": 0.9909797244814463, "weight_mismatch_refit_ground_truth_assignment": 2.0044288801308077, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.8341975977367414, "r2_milp": 0.9925500680379067, "weight_mismatch_milp": 1.75268103098476, "refit-weight_mismatch_milp": 0.5635106382594333, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 0.8341496176478381, "r2_refit_milp_assignment": 0.992550496531586, "weight_mismatch_refit_milp_assignment": 1.7385316458953097, "refit-weight_mismatch_refit_milp_assignment": 0.5221423435485223, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 3.4675583805665093, "r2_greedy": 0.9690324281921999, "weight_mismatch_greedy": 11.114746259857668, "refit-weight_mismatch_greedy": 10.576945254525194, "rand_score_greedy": 0.8172535211267606, "label_mismatch_greedy": 0.19930555555555554, "mse_greedy_sem": 0.6376810150903046, "r2_greedy_sem": 0.005694909921618572, "weight_mismatch_greedy_sem": 2.221190057883414, "refit-weight_mismatch_greedy_sem": 2.4072421381267075, "rand_score_greedy_sem": 0.020711906474818166, "label_mismatch_greedy_sem": 0.027191827971783055, "mse_ground_truth": 1.124112703582176, "r2_ground_truth": 0.9899657094231166, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 104.8379816034512, "r2_baseline_sklearn": 0.06372802785823839, "mse_milp_val": 1.4101234151888564, "r2_milp_val": 0.9873978967730783, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.4095542478794219, "r2_refit_milp_assignment_val": 0.9874029833528128, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 8.623691544884053, "label_mismatch_greedy_val": 0.19583333333333336, "mse_greedy_val_sem": 2.101743824628621, "label_mismatch_greedy_val_sem": 0.029863236018507374, "r2_greedy_val": 0.9229311066852925, "r2_greedy_val_sem": 0.018783031576684987, "mse_refit_ground_truth_assignment_val": 1.172112520288987, "r2_refit_ground_truth_assignment_val": 0.9895249714917534, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 0.9572708107655057, "r2_ground_truth_val": 0.991444985989563, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 112.25668750079501, "r2_baseline_sklearn_val": -0.003224504011124063}