{"time_milp": 380.53007555007935, "time_greedy": 0.5404047489166259, "time_refit_milp_assignment": 383.6934087276459, "mse_refit_ground_truth_assignment": 0.664393671551641, "r2_refit_ground_truth_assignment": 0.9941441742045974, "weight_mismatch_refit_ground_truth_assignment": 1.300409144665857, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.5196274933921758, "r2_milp": 0.9954201127884016, "weight_mismatch_milp": 1.7748939578196925, "refit-weight_mismatch_milp": 1.025190962013597, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 0.5195818349284694, "r2_refit_milp_assignment": 0.9954205152124779, "weight_mismatch_refit_milp_assignment": 1.766862557101999, "refit-weight_mismatch_refit_milp_assignment": 0.9899699580131167, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 5.919800698246341, "r2_greedy": 0.9478241242854182, "weight_mismatch_greedy": 13.522088895924682, "refit-weight_mismatch_greedy": 12.892557613092734, "rand_score_greedy": 0.7801447574334899, "label_mismatch_greedy": 0.2673611111111111, "mse_greedy_sem": 1.7343025940319463, "r2_greedy_sem": 0.015285777547290394, "weight_mismatch_greedy_sem": 2.773203452624534, "refit-weight_mismatch_greedy_sem": 2.841679866562938, "rand_score_greedy_sem": 0.028844861765880112, "label_mismatch_greedy_sem": 0.04118723935680756, "mse_ground_truth": 0.8451276927161343, "r2_ground_truth": 0.9925900397923523, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 104.60273691210877, "r2_baseline_sklearn": 0.07805352262144893, "mse_milp_val": 1.9500151592509667, "r2_milp_val": 0.9830335537787459, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.95957452603053, "r2_refit_milp_assignment_val": 0.9829503808446253, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 23.34206510985376, "label_mismatch_greedy_val": 0.23958333333333334, "mse_greedy_val_sem": 7.774787643317122, "label_mismatch_greedy_val_sem": 0.036005172427311986, "r2_greedy_val": 0.7969083006865098, "r2_greedy_val_sem": 0.06764589280561273, "mse_refit_ground_truth_assignment_val": 1.8576750196182557, "r2_refit_ground_truth_assignment_val": 0.9838369752320146, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 1.4884368776089492, "r2_ground_truth_val": 0.9870495959388419, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 114.95978370876087, "r2_baseline_sklearn_val": -0.00022760266689236808}