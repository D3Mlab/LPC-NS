{"time_milp": 3421.55388212204, "time_greedy": 0.5575485825538635, "time_refit_milp_assignment": 3424.9649658203125, "mse_refit_ground_truth_assignment": 1.6021127599723453, "r2_refit_ground_truth_assignment": 0.9857328625154049, "weight_mismatch_refit_ground_truth_assignment": 2.0895575472133094, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.461618391593446, "r2_milp": 0.9869839932220275, "weight_mismatch_milp": 3.0159082985446495, "refit-weight_mismatch_milp": 1.3101674642222298, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 1.4615725812659361, "r2_refit_milp_assignment": 0.9869844011722398, "weight_mismatch_refit_milp_assignment": 3.0511752689688816, "refit-weight_mismatch_refit_milp_assignment": 1.3084519968942383, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 5.517498975236871, "r2_greedy": 0.9508655580196642, "weight_mismatch_greedy": 11.339918959088505, "refit-weight_mismatch_greedy": 10.284043073071732, "rand_score_greedy": 0.7910602503912363, "label_mismatch_greedy": 0.24652777777777782, "mse_greedy_sem": 1.7098985904126693, "r2_greedy_sem": 0.015226992059256768, "weight_mismatch_greedy_sem": 2.9910132756402477, "refit-weight_mismatch_greedy_sem": 3.0726121854776602, "rand_score_greedy_sem": 0.02427939839778695, "label_mismatch_greedy_sem": 0.03645354674788621, "mse_ground_truth": 2.2007365372477987, "r2_ground_truth": 0.9809426437393735, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.80857251792428, "r2_baseline_sklearn": 0.0043220952206399765, "mse_milp_val": 3.184967223459047, "r2_milp_val": 0.9735153618537898, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 3.186663347957419, "r2_refit_milp_assignment_val": 0.973501257707518, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 13.482859067270173, "label_mismatch_greedy_val": 0.2072916666666667, "mse_greedy_val_sem": 4.564507004386188, "label_mismatch_greedy_val_sem": 0.037980444481492, "r2_greedy_val": 0.8878831025503674, "r2_greedy_val_sem": 0.03795621990599877, "mse_refit_ground_truth_assignment_val": 2.946061497574883, "r2_refit_ground_truth_assignment_val": 0.9755019856577949, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 2.9820116932046528, "r2_ground_truth_val": 0.9752030413184225, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 120.25748700185049, "r2_baseline_sklearn_val": -2.7642851303522065e-06}