{"time_milp": 2937.171877384186, "time_greedy": 0.4733778238296509, "time_refit_milp_assignment": 2939.8764295578003, "mse_refit_ground_truth_assignment": 1.85676186129395, "r2_refit_ground_truth_assignment": 0.9845738981423336, "weight_mismatch_refit_ground_truth_assignment": 2.463157923705827, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.5265464205658694, "r2_milp": 0.9873173501325073, "weight_mismatch_milp": 2.6468556694715484, "refit-weight_mismatch_milp": 1.080116239426095, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 1.5265034043874266, "r2_refit_milp_assignment": 0.9873177075137979, "weight_mismatch_refit_milp_assignment": 2.645744529258976, "refit-weight_mismatch_refit_milp_assignment": 1.051715548538528, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 9.081220385029585, "r2_greedy": 0.924552613034739, "weight_mismatch_greedy": 16.25336253829456, "refit-weight_mismatch_greedy": 15.713844291976582, "rand_score_greedy": 0.7538928012519561, "label_mismatch_greedy": 0.3034722222222222, "mse_greedy_sem": 2.0505588524950706, "r2_greedy_sem": 0.01703618023567355, "weight_mismatch_greedy_sem": 3.1572836363739225, "refit-weight_mismatch_greedy_sem": 3.2875713289723563, "rand_score_greedy_sem": 0.029389941896292824, "label_mismatch_greedy_sem": 0.04379638773486328, "mse_ground_truth": 1.9152087576773515, "r2_ground_truth": 0.9831599866193781, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 112.24153959736964, "r2_baseline_sklearn": 0.06748977422247604, "mse_milp_val": 2.037667100256162, "r2_milp_val": 0.9803189182230592, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 2.040555855745478, "r2_refit_milp_assignment_val": 0.9802910167895955, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 22.149943198841942, "label_mismatch_greedy_val": 0.2635416666666667, "mse_greedy_val_sem": 5.418910551545689, "label_mismatch_greedy_val_sem": 0.04532399909546649, "r2_greedy_val": 0.7860617941977865, "r2_greedy_val_sem": 0.052339276466450715, "mse_refit_ground_truth_assignment_val": 1.7800799160003207, "r2_refit_ground_truth_assignment_val": 0.9828068586905643, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 1.6464819639265917, "r2_ground_truth_val": 0.9840972324810938, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 103.95077555884649, "r2_baseline_sklearn_val": -0.004022548282242244}