{"time_milp": 12456.51956486702, "time_greedy": 0.46648435592651366, "time_refit_milp_assignment": 12459.238372564316, "mse_refit_ground_truth_assignment": 2.923443760358866, "r2_refit_ground_truth_assignment": 0.9754255282831593, "weight_mismatch_refit_ground_truth_assignment": 1.7074762043799887, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.642375484280844, "r2_milp": 0.9777881885452239, "weight_mismatch_milp": 2.382732084494824, "refit-weight_mismatch_milp": 1.137185525899413, "rand_score_milp": 0.9158841940532081, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 2.642323681293166, "r2_refit_milp_assignment": 0.9777886240011998, "weight_mismatch_refit_milp_assignment": 2.3933393307285096, "refit-weight_mismatch_refit_milp_assignment": 1.0970251954084844, "rand_score_refit_milp_assignment": 0.9158841940532081, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 8.068660024756998, "r2_greedy": 0.932174834262297, "weight_mismatch_greedy": 15.73871814197743, "refit-weight_mismatch_greedy": 15.342630520955122, "rand_score_greedy": 0.7576095461658843, "label_mismatch_greedy": 0.29930555555555555, "mse_greedy_sem": 1.9001744688465103, "r2_greedy_sem": 0.015972868838769503, "weight_mismatch_greedy_sem": 2.1799073782739247, "refit-weight_mismatch_greedy_sem": 2.280089833350252, "rand_score_greedy_sem": 0.020942627615793356, "label_mismatch_greedy_sem": 0.03185493115753559, "mse_ground_truth": 3.42137456427023, "r2_ground_truth": 0.9712196994127515, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.50486807702754, "r2_baseline_sklearn": 0.06268994669745498, "mse_milp_val": 3.4493195594700494, "r2_milp_val": 0.9708982613165362, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 3.453026534200097, "r2_refit_milp_assignment_val": 0.97086698575391, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 20.23597186538806, "label_mismatch_greedy_val": 0.303125, "mse_greedy_val_sem": 5.36459233844736, "label_mismatch_greedy_val_sem": 0.029051896685472915, "r2_greedy_val": 0.8292701052833369, "r2_greedy_val_sem": 0.04526080048112241, "mse_refit_ground_truth_assignment_val": 3.5526990331391635, "r2_refit_ground_truth_assignment_val": 0.9700260538054366, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 3.369945957959714, "r2_ground_truth_val": 0.9715679324704244, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 118.91387381916495, "r2_baseline_sklearn_val": -0.0032704775707725897}