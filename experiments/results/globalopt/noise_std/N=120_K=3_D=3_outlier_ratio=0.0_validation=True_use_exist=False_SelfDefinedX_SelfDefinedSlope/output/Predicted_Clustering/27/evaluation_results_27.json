{"time_milp": 5109.140767812729, "time_greedy": 0.46651517152786254, "time_refit_milp_assignment": 5111.8862545490265, "mse_refit_ground_truth_assignment": 3.280956402724153, "r2_refit_ground_truth_assignment": 0.9721980784081292, "weight_mismatch_refit_ground_truth_assignment": 2.889798099242026, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.2422231525109417, "r2_milp": 0.9810000180966051, "weight_mismatch_milp": 3.545852510271078, "refit-weight_mismatch_milp": 1.3557960459293386, "rand_score_milp": 0.8748043818466353, "label_mismatch_milp": 0.1111111111111111, "mse_refit_milp_assignment": 2.2421777068632966, "r2_refit_milp_assignment": 0.981000403190516, "weight_mismatch_refit_milp_assignment": 3.545801955703808, "refit-weight_mismatch_refit_milp_assignment": 1.3206806418117056, "rand_score_refit_milp_assignment": 0.8748043818466353, "label_mismatch_refit_milp_assignment": 0.1111111111111111, "mse_greedy": 7.98891573155977, "r2_greedy": 0.9323041267514334, "weight_mismatch_greedy": 20.154325399407547, "refit-weight_mismatch_greedy": 19.26757137370392, "rand_score_greedy": 0.7325899843505478, "label_mismatch_greedy": 0.3291666666666667, "mse_greedy_sem": 1.5506169501481823, "r2_greedy_sem": 0.013139501284214412, "weight_mismatch_greedy_sem": 3.2774729641258773, "refit-weight_mismatch_greedy_sem": 3.4189878969975624, "rand_score_greedy_sem": 0.022788924955945665, "label_mismatch_greedy_sem": 0.034289703821615884, "mse_ground_truth": 4.173470087487083, "r2_ground_truth": 0.965094153826566, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.98674042527176, "r2_baseline_sklearn": 0.06800263151624275, "mse_milp_val": 7.363553858873587, "r2_milp_val": 0.9395772362519951, "label_mismatch_milp_val": 0.14583333333333334, "mse_refit_milp_assignment_val": 7.384675210759823, "r2_refit_milp_assignment_val": 0.9394039217791849, "label_mismatch_refit_milp_assignment_val": 0.14583333333333334, "mse_greedy_val": 29.51447169948715, "label_mismatch_greedy_val": 0.3145833333333333, "mse_greedy_val_sem": 7.970538244169854, "label_mismatch_greedy_val_sem": 0.030186584729989224, "r2_greedy_val": 0.7578145030478407, "r2_greedy_val_sem": 0.06540346665510566, "mse_refit_ground_truth_assignment_val": 7.3423587392939496, "r2_refit_ground_truth_assignment_val": 0.9397511560368592, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 6.34828964906168, "r2_ground_truth_val": 0.9479081415005993, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 121.91546446971851, "r2_baseline_sklearn_val": -0.0003959294743245412}