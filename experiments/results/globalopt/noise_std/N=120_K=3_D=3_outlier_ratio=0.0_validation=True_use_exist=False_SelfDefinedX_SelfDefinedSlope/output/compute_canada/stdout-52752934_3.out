==================== Evaluating with noise_std = 0.9 in Dataset 1 with random state = 42 ====================
ODS is enabled
mse 0.6928283492647214
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 312 columns and 216 nonzeros
Model fingerprint: 0x5e363aa3
Model has 84 quadratic objective terms
Model has 216 general constraints
Variable types: 96 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e-02, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [4e-01, 2e+01]
  GenCon coe range [6e-03, 5e+00]
Presolve added 216 rows and 204 columns
Presolve time: 0.02s
Presolved: 288 rows, 516 columns, 1512 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 84 quadratic objective terms
Variable types: 300 continuous, 216 integer (216 binary)

Root relaxation: objective 0.000000e+00, 577 iterations, 0.01 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   72          -    0.00000      -     -    0s
H    0     0                    7717.6957167    0.00000   100%     -    0s
H    0     0                    7311.0366948    0.00000   100%     -    0s
     0     0    0.32397    0   71 7311.03669    0.32397   100%     -    0s
     0     2    0.32397    0   71 7311.03669    0.32397   100%     -    0s
H   31    48                    7302.4604327    0.32397   100%   2.4    0s
H   32    48                    6980.3535918    0.32397   100%   2.4    0s
H   33    48                    6737.0044506    0.32397   100%   2.5    0s
H   42    48                    6507.2496587    0.32397   100%   2.6    0s
H   79    96                    6335.9166692    0.32397   100%   2.4    0s
H  555   640                    5874.3179340    0.32397   100%   2.5    0s
H  625   640                    5639.0056569    0.32397   100%   2.5    0s
H  927   966                    4562.8098710    0.32397   100%   2.5    0s
H  947   966                    4462.3201543    0.32397   100%   2.5    0s
H  961   966                    3864.4697818    0.32397   100%   2.5    0s
H 2053  2071                    2875.1658588    0.32945   100%   2.4    0s
H 2054  2071                    2812.4147538    0.32945   100%   2.4    0s
H 2059  2071                    2764.7691637    0.32945   100%   2.4    0s
H 3011  3575                    1690.9517366    0.32945   100%   2.3    0s
H 3043  3351                     597.1757208    0.32945   100%   2.3    0s
H 3383  3085                     374.2495962    0.32945   100%   2.3    0s
* 4860  3578             139     373.9102271    0.35115   100%   2.3    0s
H 5163  3578                     373.0562258    0.38525   100%   2.3    0s
H 5205  3437                     371.9392771    0.38525   100%   2.4    1s
H 5247  3297                     346.2641936    0.38525   100%   2.4    1s
H 5935  3522                     282.0355419    0.38525   100%   2.4    1s
H 6389  3532                     272.8661656    0.38525   100%   2.4    1s
H 6390  3361                     253.3279486    0.38525   100%   2.4    1s
H 6391  3202                     243.9884149    0.38525   100%   2.4    1s
H 7785  3842                     228.5446563    0.38525   100%   2.4    1s
H17947  8418                     224.6016465    0.47036   100%   2.2    1s
H22372 10626                     223.1827050    0.48878   100%   2.2    1s
H24646 11636                     201.4183658    0.49582   100%   2.2    1s
 88768 45876  125.59937   89   57  201.41837    0.84641   100%   2.1    5s
 206677 103560  122.63805   82   57  201.41837    1.29774  99.4%   2.0   10s
 273855 136252    3.59218   61   68  201.41837    1.45900  99.3%   2.0   15s
 357906 176356     cutoff  105       201.41837    1.62634  99.2%   2.0   20s
 476177 233386  197.50576  112   34  201.41837    1.83703  99.1%   2.0   25s
 569125 276398     cutoff  119       201.41837    2.00058  99.0%   2.0   30s
 654570 316040    2.77310   78   67  201.41837    2.14573  98.9%   1.9   35s
H725434 346031                     199.6813598    2.26119  98.9%   1.9   37s
H727454 342823                     192.3660419    2.26865  98.8%   1.9   38s
 764619 360394     cutoff  102       192.36604    2.33515  98.8%   1.9   40s
 854395 402702   64.93826   95   50  192.36604    2.44979  98.7%   1.9   45s
 943548 442338     cutoff   94       192.36604    2.58233  98.7%   1.9   50s
 1047245 488780    4.43462   82   61  192.36604    2.72800  98.6%   1.9   55s
 1129161 524981  138.70695   81   58  192.36604    2.83591  98.5%   1.9   60s
 1180552 548842   35.26094  105   47  192.36604    2.90269  98.5%   1.9   65s
 1246957 577815     cutoff  105       192.36604    3.00041  98.4%   1.9   70s
 1330856 613509     cutoff   88       192.36604    3.10556  98.4%   1.9   75s
 1462105 670510   38.11093   97   49  192.36604    3.27518  98.3%   1.9   80s
H1511019 692960                     192.1710327    3.32277  98.3%   1.9   82s
 1530181 701190   99.07463   89   48  192.17103    3.34305  98.3%   1.9   85s
H1531043 696521                     187.9646156    3.34305  98.2%   1.9   86s
 1570646 714999     cutoff  116       187.96462    3.38444  98.2%   1.9   90s
H1586473 717193                     184.5696539    3.40350  98.2%   1.9   91s
H1628482 731275                     182.3070641    3.46209  98.1%   1.9   93s
 1655868 744386   72.32996   79   50  182.30706    3.49574  98.1%   1.9   95s
 1767225 793682   90.53275   90   58  182.30706    3.60938  98.0%   1.9  100s
 1852965 831168     cutoff  104       182.30706    3.69778  98.0%   1.9  105s
H1920561 821758                     162.3598975    3.77818  97.7%   1.9  109s
 1933343 828036  104.74142   76   63  162.35990    3.79084  97.7%   1.9  110s
 2022619 866242     cutoff   77       162.35990    3.87978  97.6%   1.9  115s
 2103500 902152   30.11222   78   64  162.35990    3.95622  97.6%   1.9  120s
 2175300 932119   14.72191   88   60  162.35990    4.02590  97.5%   1.9  125s
 2236049 955634   76.57296  113   40  162.35990    4.10176  97.5%   1.9  130s
 2323061 989898   92.19703  106   37  162.35990    4.20339  97.4%   1.9  135s
 2402757 1024460   97.89016   69   60  162.35990    4.28019  97.4%   1.9  140s
 2491629 1060985  146.70822   86   56  162.35990    4.37704  97.3%   1.9  145s
 2573951 1093890     cutoff   81       162.35990    4.46188  97.3%   1.9  150s
 2666805 1130742   25.71030   96   49  162.35990    4.56497  97.2%   1.9  155s
 2761027 1170848   85.44289   91   44  162.35990    4.65185  97.1%   1.9  160s
 2846650 1206209   70.36651   98   45  162.35990    4.72120  97.1%   1.9  165s
 2948351 1246392   10.20544   76   54  162.35990    4.82144  97.0%   1.9  170s
 3030328 1279070     cutoff  113       162.35990    4.90244  97.0%   1.9  175s
H3082483 1262104                     151.4830375    4.95318  96.7%   1.9  177s
H3084203 1257263                     150.0320871    4.95639  96.7%   1.9  177s
H3086994 1257391                     149.8401677    4.96211  96.7%   1.9  177s
H3087000 1240678                     145.6743234    4.96211  96.6%   1.9  178s
H3087004 1216993                     139.9817076    4.96211  96.5%   1.9  178s
H3087022 1054757                     108.2538382    4.96211  95.4%   1.9  178s
H3088986 1013583                     101.1497427    4.96302  95.1%   1.9  178s
H3089009 927439                      87.7309890    4.96302  94.3%   1.9  179s
H3089065 894108                      83.0244907    4.96302  94.0%   1.9  179s
H3091057 873354                      80.0744805    4.96831  93.8%   1.9  179s
H3091065 620460                      50.9573878    4.96831  90.3%   1.9  179s
H3091076 583716                      47.4004987    4.96831  89.5%   1.9  180s
H3093040 534401                      42.7667590    4.97189  88.4%   1.9  180s
 3255563 574575    5.76063   67   66   42.76676    5.35050  87.5%   1.9  185s
 3343082 593602   14.10475   79   57   42.76676    5.57919  87.0%   1.9  190s
 3439188 616245     cutoff   66        42.76676    5.80117  86.4%   1.9  195s
 3554954 642770     cutoff   87        42.76676    6.09309  85.8%   1.9  200s
 3654267 664422   26.07782   87   56   42.76676    6.34692  85.2%   1.9  205s
 3775768 691290   31.53865   84   58   42.76676    6.67558  84.4%   1.8  210s
 3976301 730372   20.44251   76   63   42.76676    7.22864  83.1%   1.8  215s
 4233772 777570   41.81807   95   50   42.76676    7.93923  81.4%   1.8  220s
 4481738 814072   14.23787   82   64   42.76676    8.65555  79.8%   1.8  225s
 4739247 844222   30.52172   80   62   42.76676    9.39369  78.0%   1.8  230s
 4991551 867991   37.98763   87   63   42.76676   10.15628  76.3%   1.8  235s
 5119696 881063   34.67460   84   63   42.76676   10.51728  75.4%   1.8  240s
 5205267 889737   11.45900   75   65   42.76676   10.75339  74.9%   1.8  245s
 5334846 900455   11.12277   54   68   42.76676   11.12058  74.0%   1.8  250s
 5463014 910201   34.56735   81   62   42.76676   11.48654  73.1%   1.8  255s
 5567000 916978   23.27470   85   64   42.76676   11.79079  72.4%   1.8  260s
 5701637 927020   17.60408   91   50   42.76676   12.17976  71.5%   1.8  265s
 5817751 934921   12.98055   76   66   42.76676   12.52671  70.7%   1.8  270s
 5947323 942281   38.36545   86   50   42.76676   12.93151  69.8%   1.8  275s
 6045082 947703     cutoff   88        42.76676   13.23276  69.1%   1.8  280s
 6156285 953231   17.23321   87   59   42.76676   13.56606  68.3%   1.8  285s
 6285738 960758     cutoff   89        42.76676   13.94542  67.4%   1.8  290s
 6405228 967943   26.45055   95   49   42.76676   14.29216  66.6%   1.8  295s
 6532972 973052   21.23074   97   56   42.76676   14.67981  65.7%   1.8  300s
 6667854 977545     cutoff   69        42.76676   15.08420  64.7%   1.7  305s
 6812739 985029   32.71944   94   48   42.76676   15.50060  63.8%   1.7  310s
 6954033 991807     cutoff   87        42.76676   15.89619  62.8%   1.7  315s
 7096890 996980   39.15960   75   64   42.76676   16.29312  61.9%   1.7  320s
 7236792 1000266   24.14641   71   64   42.76676   16.69623  61.0%   1.7  325s
 7374329 1005545     cutoff   82        42.76676   17.06951  60.1%   1.7  330s
 7485449 1007826   23.60404   90   62   42.76676   17.37747  59.4%   1.7  335s
 7613353 1010688   42.43964  105   44   42.76676   17.72380  58.6%   1.7  340s
 7737817 1011813     cutoff   87        42.76676   18.07567  57.7%   1.7  345s
 7874049 1014366     cutoff   96        42.76676   18.44823  56.9%   1.7  350s
 7988788 1015965     cutoff   88        42.76676   18.76882  56.1%   1.7  355s
 8178699 1018753   20.67732   74   62   42.76676   19.27578  54.9%   1.7  360s
 8419224 1021615     cutoff   91        42.76676   19.91413  53.4%   1.7  365s
 8575876 1024532     cutoff  104        42.76676   20.30391  52.5%   1.7  370s
 8692214 1025275     cutoff  102        42.76676   20.58005  51.9%   1.7  375s
 8803487 1026296     cutoff   95        42.76676   20.83647  51.3%   1.7  380s
 8929923 1029932   21.97677   98   50   42.76676   21.11259  50.6%   1.7  385s
 9060031 1029862     cutoff   88        42.76676   21.41439  49.9%   1.7  390s
 9209019 1030786     cutoff   75        42.76676   21.75396  49.1%   1.7  395s
 9354433 1029263   22.09085   77   65   42.76676   22.07864  48.4%   1.7  400s
 9572861 1025693     cutoff   76        42.76676   22.58116  47.2%   1.7  405s
 9769214 1018448     cutoff   95        42.76676   23.05406  46.1%   1.7  410s
 10016367 1010321     cutoff   92        42.76676   23.66401  44.7%   1.7  415s
 10256811 1002029   27.64914   91   56   42.76676   24.27125  43.2%   1.7  420s
 10469133 991362     cutoff   78        42.76676   24.83498  41.9%   1.7  425s
 10608260 983656   27.06453   83   60   42.76676   25.20997  41.1%   1.7  430s
 10749001 975747   42.07757   94   53   42.76676   25.58131  40.2%   1.7  435s
 10886832 966766   26.38003   87   64   42.76676   25.94121  39.3%   1.7  440s
 11022769 958398   32.20185   87   53   42.76676   26.29836  38.5%   1.7  445s
 11150414 948469     cutoff   89        42.76676   26.64648  37.7%   1.7  450s
 11281653 937223   37.67795   97   45   42.76676   27.00626  36.9%   1.7  455s
 11422008 926333     cutoff  100        42.76676   27.37405  36.0%   1.7  460s
 11555169 915027     cutoff   77        42.76676   27.72959  35.2%   1.7  465s
 11696450 902576   35.20173  103   43   42.76676   28.10352  34.3%   1.7  470s
 11831430 889730   29.16590   70   65   42.76676   28.46211  33.4%   1.7  475s
 11967340 875872   31.73237   96   50   42.76676   28.82951  32.6%   1.7  480s
 12041155 868830     cutoff   89        42.76676   29.02950  32.1%   1.7  485s
 12113594 861595   30.86805  103   44   42.76676   29.21821  31.7%   1.7  490s
 12182889 854239   39.86730  101   43   42.76676   29.39996  31.3%   1.7  495s
 12284485 843088   36.54768   78   55   42.76676   29.66467  30.6%   1.7  500s
 12538624 813911   30.37755   81   63   42.76676   30.34926  29.0%   1.7  505s
 12785561 782953     cutoff   88        42.76676   31.00893  27.5%   1.7  510s
 13036686 747947     cutoff   82        42.76676   31.68564  25.9%   1.6  515s
 13289979 709472   37.06825   91   56   42.76676   32.37991  24.3%   1.6  520s
 13536715 668253   40.91312   79   61   42.76676   33.07227  22.7%   1.6  525s
 13788355 621978     cutoff   95        42.76676   33.79423  21.0%   1.6  530s
 14021019 576968     cutoff   81        42.76676   34.48030  19.4%   1.6  535s
 14269915 524173     cutoff   84        42.76676   35.23148  17.6%   1.6  540s
 14515072 466240   37.29491   89   49   42.76676   36.02274  15.8%   1.6  545s
 14622873 438105   40.88086   88   57   42.76676   36.38927  14.9%   1.6  550s
 14713724 412416     cutoff   90        42.76676   36.70948  14.2%   1.6  555s
 14797234 387582     cutoff   91        42.76676   37.02880  13.4%   1.6  560s
 14879517 362269     cutoff   88        42.76676   37.34868  12.7%   1.6  565s
 14964084 335211     cutoff   69        42.76676   37.69158  11.9%   1.6  570s
 15045935 308119   38.04469   79   58   42.76676   38.02646  11.1%   1.6  575s
 15178503 261314     cutoff  103        42.76676   38.62802  9.68%   1.6  580s
 15305495 214204   39.62252   67   65   42.76676   39.22443  8.28%   1.6  585s
 15434749 162847   42.75072   76   62   42.76676   39.89592  6.71%   1.6  590s

Explored 15555501 nodes (25033956 simplex iterations) in 594.61 seconds (270.02 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 42.7668 47.4005 50.9574 ... 145.674

Optimal solution found (tolerance 5.00e-02)
Best objective 4.276675897748e+01, best bound 4.063303971683e+01, gap 4.9892%
Optimal solution found.
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
Cluster Assignments from Gurobi MIQP using MSE

Cluster 0 weights w_0^* (including bias) in original space:
[-10.28179405  -1.3597415   -1.68435827  -0.89242323]

Cluster 1 weights w_1^* (including bias) in original space:
[1.16680385 1.49012791 1.53133856 1.06026903]

Cluster 2 weights w_2^* (including bias) in original space:
[9.91038885 0.10337892 0.02897884 0.27087506]
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[0.80627685 0.00156823 0.00088171 0.00129184]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
107.18755843116125
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
-----------------------------------
Regression weights for cluster 0: y = -1.3597x_0 + -1.6844x_1 + -0.8924x_2 + -10.2818
Regression weights for cluster 0 after refit: y = -1.3499x_1 + -1.677x_2 + -0.8881x_3 + -10.305
-----------------------------------
Regression weights for cluster 1: y = 1.4901x_0 + 1.5313x_1 + 1.0603x_2 + 1.1668
Regression weights for cluster 1 after refit: y = 1.4903x_1 + 1.5317x_2 + 1.0599x_3 + 1.1673
-----------------------------------
Regression weights for cluster 2: y = 0.1034x_0 + 0.029x_1 + 0.2709x_2 + 9.9104
Regression weights for cluster 2 after refit: y = 0.0979x_1 + 0.0223x_2 + 0.2674x_3 + 9.9307
{'time_milp': 595.8016335964203, 'time_greedy': np.float64(0.4864043593406677), 'time_refit_milp_assignment': 598.6619622707367, 'mse_refit_ground_truth_assignment': np.float64(0.5919973614726703), 'r2_refit_ground_truth_assignment': 0.9948387593746341, 'weight_mismatch_refit_ground_truth_assignment': np.float64(0.7683642919953325), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(0.5639064502604536), 'r2_milp': 0.9950836657907562, 'weight_mismatch_milp': np.float64(0.7568441307928445), 'refit-weight_mismatch_milp': np.float64(0.16477136782168544), 'rand_score_milp': np.float64(0.9640062597809077), 'label_mismatch_milp': np.float64(0.027777777777777776), 'mse_refit_milp_assignment': np.float64(0.5638496937329315), 'r2_refit_milp_assignment': 0.9950841606140691, 'weight_mismatch_refit_milp_assignment': np.float64(0.7698601718615813), 'refit-weight_mismatch_refit_milp_assignment': np.float64(0.11804971141486567), 'rand_score_refit_milp_assignment': np.float64(0.9640062597809077), 'label_mismatch_refit_milp_assignment': np.float64(0.027777777777777776), 'mse_greedy': np.float64(6.6410919687698335), 'r2_greedy': np.float64(0.9421006310218354), 'weight_mismatch_greedy': np.float64(17.273565305835785), 'refit-weight_mismatch_greedy': np.float64(17.19132110507024), 'rand_score_greedy': np.float64(0.773356807511737), 'label_mismatch_greedy': np.float64(0.2826388888888889), 'mse_greedy_sem': np.float64(1.71067344303776), 'r2_greedy_sem': np.float64(0.014914251051689226), 'weight_mismatch_greedy_sem': np.float64(2.9351342688824618), 'refit-weight_mismatch_greedy_sem': np.float64(3.019292458366436), 'rand_score_greedy_sem': np.float64(0.0291913579358409), 'label_mismatch_greedy_sem': np.float64(0.038753877481073604), 'mse_ground_truth': np.float64(0.6928283492647214), 'r2_ground_truth': np.float64(0.9939189458807312), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(107.18755843116125), 'r2_baseline_sklearn': np.float64(0.06550127228188907), 'mse_milp_val': np.float64(1.0999054235298817), 'r2_milp_val': 0.9902335088844666, 'label_mismatch_milp_val': np.float64(0.041666666666666664), 'mse_refit_milp_assignment_val': np.float64(1.1015858634218259), 'r2_refit_milp_assignment_val': 0.9902185876003964, 'label_mismatch_refit_milp_assignment_val': np.float64(0.041666666666666664), 'mse_greedy_val': np.float64(15.832614981675892), 'label_mismatch_greedy_val': np.float64(0.2604166666666667), 'mse_greedy_val_sem': np.float64(4.306721142878381), 'label_mismatch_greedy_val_sem': np.float64(0.03703722739960825), 'r2_greedy_val': np.float64(0.8594160095529368), 'r2_greedy_val_sem': np.float64(0.038241064076232095), 'mse_refit_ground_truth_assignment_val': np.float64(1.0808548624154868), 'r2_refit_ground_truth_assignment_val': 0.9904026662791747, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.020833333333333332), 'mse_ground_truth_val': np.float64(1.0857220129642875), 'r2_ground_truth_val': 0.9903594489428693, 'label_mismatch_ground_truth_val': np.float64(0.020833333333333332), 'mse_baseline_sklearn_val': np.float64(112.89344533553135), 'r2_baseline_sklearn_val': -0.00242512427384578}
