==================== Evaluating with noise_std = 0.3 in Dataset 1 with random state = 7 ====================
ODS is enabled
mse 0.08964313758837524
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 312 columns and 216 nonzeros
Model fingerprint: 0x145612bd
Model has 84 quadratic objective terms
Model has 216 general constraints
Variable types: 96 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e-02, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [9e-01, 2e+01]
  GenCon coe range [6e-03, 4e+00]
Presolve added 216 rows and 204 columns
Presolve time: 0.02s
Presolved: 288 rows, 516 columns, 1512 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 84 quadratic objective terms
Variable types: 300 continuous, 216 integer (216 binary)

Root relaxation: objective 0.000000e+00, 577 iterations, 0.01 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   72          -    0.00000      -     -    0s
H    0     0                    8368.3365404    0.00000   100%     -    0s
H    0     0                    7849.7053882    0.00000   100%     -    0s
     0     0    0.18110    0   71 7849.70539    0.18110   100%     -    0s
     0     2    0.18110    0   71 7849.70539    0.18110   100%     -    0s
H   31    48                    7846.3121762    0.18110   100%   2.4    0s
H   32    48                    7840.4917555    0.18110   100%   2.4    0s
H   35    48                    7380.7757916    0.18110   100%   2.5    0s
H   42    48                    7347.8778924    0.18110   100%   2.6    0s
H   79    96                    6956.3749900    0.18110   100%   2.4    0s
H  534   634                    6943.2376712    0.18110   100%   2.5    0s
H  562   634                    6228.5363452    0.18110   100%   2.5    0s
H 1609  1626                    5389.0095368    0.26375   100%   2.5    0s
H 1611  1626                    5120.4591116    0.26375   100%   2.5    0s
H 1611  1626                    2253.1139134    0.26375   100%   2.5    0s
H 1623  1626                    2028.0795168    0.26375   100%   2.5    0s
H 1688  1922                    1083.2680238    0.26375   100%   2.5    0s
H 1927  2178                    1008.7853102    0.26375   100%   2.5    0s
H 1959  2136                     539.9905925    0.26375   100%   2.4    0s
H 2956  2614                     351.5346975    0.26375   100%   2.3    0s
H 5526  3557                     351.4321183    0.26375   100%   2.3    0s
H 5573  3405                     351.1577027    0.26375   100%   2.3    0s
H 5709  3319                     307.6844820    0.26375   100%   2.4    0s
H 6611  3675                     277.7268136    0.26375   100%   2.4    0s
H 6653  3526                     267.2148703    0.26375   100%   2.4    0s
H 6655  3368                     241.4913423    0.26375   100%   2.4    0s
H 7985  4048                     230.8305605    0.26375   100%   2.4    0s
H21187  9074                     230.7132383    0.48455   100%   2.1    1s
H21192  9030                     225.1532455    0.48455   100%   2.1    1s
H21194  9017                     224.2323945    0.48455   100%   2.1    1s
H108699 54891                     216.6278639    1.02060   100%   2.0    4s
H109884 55162                     213.3281426    1.02953   100%   2.0    4s
H110296 54020                     201.9585443    1.02953  99.5%   2.0    4s
H110394 53805                     199.9634473    1.02953  99.5%   2.0    4s
H112939 53641                     187.6739787    1.03252  99.4%   2.0    4s
H112940 49681                     147.1591204    1.03252  99.3%   2.0    4s
H113009 49703                     144.1174992    1.03252  99.3%   2.0    4s
H113054 49064                     138.0229343    1.03252  99.3%   2.0    4s
H113231 48322                     130.7932318    1.03252  99.2%   2.0    4s
H113318 43676                      86.8266101    1.03252  98.8%   2.0    4s
H113620 42791                      80.2613958    1.03252  98.7%   2.0    4s
H115985 39685                      59.1251564    1.04094  98.2%   2.0    4s
H122541 37071                      38.4088180    1.09273  97.2%   2.0    4s
 141234 44684    6.79960   84   62   38.40882    1.20912  96.9%   2.0    5s
H164422 52753                      38.3676244    1.32302  96.6%   2.0    5s
H164424 52145                      36.8275406    1.32302  96.4%   2.0    5s
H164434 46221                      25.4223960    1.32302  94.8%   2.0    5s
H164436 45525                      24.0686889    1.32302  94.5%   2.0    5s
H250137 63460                      17.0397258    1.79238  89.5%   1.9    7s
*334435 81359             133      14.3562165    2.21894  84.5%   1.9    8s
H375904 47353                       6.6097923    2.42289  63.3%   1.9    9s
 380824 48641    3.70512   77   68    6.60979    2.44258  63.0%   1.9   10s
 658505 50606     cutoff   74         6.60979    4.72730  28.5%   1.8   15s

Explored 778650 nodes (1354541 simplex iterations) in 17.11 seconds (13.97 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 6.60979 14.3562 17.0397 ... 80.2614

Optimal solution found (tolerance 5.00e-02)
Best objective 6.609792272209e+00, best bound 6.290000348395e+00, gap 4.8382%
Optimal solution found.
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Cluster Assignments from Gurobi MIQP using MSE

Cluster 0 weights w_0^* (including bias) in original space:
[-9.89882321 -1.44585265 -1.73081231 -1.03489852]

Cluster 1 weights w_1^* (including bias) in original space:
[10.03419725  0.02572129  0.09364051  0.123515  ]

Cluster 2 weights w_2^* (including bias) in original space:
[1.06294161 1.58611959 1.53349433 1.04623491]
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 4.22888721e-01  1.91540785e-04 -5.81802869e-04  3.40385420e-04]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
116.22670839344076
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
-----------------------------------
Regression weights for cluster 0: y = -1.4459x_0 + -1.7308x_1 + -1.0349x_2 + -9.8988
Regression weights for cluster 0 after refit: y = -1.4409x_1 + -1.7269x_2 + -1.0304x_3 + -9.9167
-----------------------------------
Regression weights for cluster 1: y = 0.0257x_0 + 0.0936x_1 + 0.1235x_2 + 10.0342
Regression weights for cluster 1 after refit: y = 0.0212x_1 + 0.0883x_2 + 0.1207x_3 + 10.0506
-----------------------------------
Regression weights for cluster 2: y = 1.5861x_0 + 1.5335x_1 + 1.0462x_2 + 1.0629
Regression weights for cluster 2 after refit: y = 1.5863x_1 + 1.534x_2 + 1.0459x_3 + 1.0632
{'time_milp': 17.461605548858643, 'time_greedy': np.float64(0.48084784746170045), 'time_refit_milp_assignment': 20.222636222839355, 'mse_refit_ground_truth_assignment': np.float64(0.062320905518811545), 'r2_refit_ground_truth_assignment': 0.9994679739863227, 'weight_mismatch_refit_ground_truth_assignment': np.float64(0.3312427499230328), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(0.06236578848865775), 'r2_milp': 0.9994675908258513, 'weight_mismatch_milp': np.float64(0.3347435439807904), 'refit-weight_mismatch_milp': np.float64(0.038173843214839666), 'rand_score_milp': 1.0, 'label_mismatch_milp': np.float64(0.0), 'mse_refit_milp_assignment': np.float64(0.062320905518811545), 'r2_refit_milp_assignment': 0.9994679739863227, 'weight_mismatch_refit_milp_assignment': np.float64(0.3312427499230328), 'refit-weight_mismatch_refit_milp_assignment': np.float64(0.0), 'rand_score_refit_milp_assignment': 1.0, 'label_mismatch_refit_milp_assignment': np.float64(0.0), 'mse_greedy': np.float64(5.543659924591376), 'r2_greedy': np.float64(0.9526744474216156), 'weight_mismatch_greedy': np.float64(12.540333766408486), 'refit-weight_mismatch_greedy': np.float64(12.373131146355519), 'rand_score_greedy': np.float64(0.8179186228482003), 'label_mismatch_greedy': np.float64(0.21388888888888888), 'mse_greedy_sem': np.float64(1.8381325939496052), 'r2_greedy_sem': np.float64(0.015691915071326553), 'weight_mismatch_greedy_sem': np.float64(3.4620337493005926), 'refit-weight_mismatch_greedy_sem': np.float64(3.4836259073650706), 'rand_score_greedy_sem': np.float64(0.0340315274789341), 'label_mismatch_greedy_sem': np.float64(0.04340197367676194), 'mse_ground_truth': np.float64(0.08964313758837524), 'r2_ground_truth': np.float64(0.999200816771906), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(116.22670839344076), 'r2_baseline_sklearn': np.float64(0.007786683543400841), 'mse_milp_val': np.float64(0.12354516175259649), 'r2_milp_val': 0.9988172551126905, 'label_mismatch_milp_val': np.float64(0.0), 'mse_refit_milp_assignment_val': np.float64(0.12342013080284649), 'r2_refit_milp_assignment_val': 0.9988184520815921, 'label_mismatch_refit_milp_assignment_val': np.float64(0.0), 'mse_greedy_val': np.float64(13.599715459466916), 'label_mismatch_greedy_val': np.float64(0.2125), 'mse_greedy_val_sem': np.float64(4.7172390268018285), 'label_mismatch_greedy_val_sem': np.float64(0.04257775824390034), 'r2_greedy_val': np.float64(0.8698047442702773), 'r2_greedy_val_sem': np.float64(0.045159925828092716), 'mse_refit_ground_truth_assignment_val': np.float64(0.12342013080284649), 'r2_refit_ground_truth_assignment_val': 0.9988184520815921, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.0), 'mse_ground_truth_val': np.float64(0.11720636304349293), 'r2_ground_truth_val': 0.9988779388469502, 'label_mismatch_ground_truth_val': np.float64(0.0), 'mse_baseline_sklearn_val': np.float64(104.8869182939203), 'r2_baseline_sklearn_val': -0.004122416434347631}
