==================== Evaluating with noise_std = 0.9 in Dataset 1 with random state = 7 ====================
ODS is enabled
mse 0.806788238295377
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 312 columns and 216 nonzeros
Model fingerprint: 0x5bf534cc
Model has 84 quadratic objective terms
Model has 216 general constraints
Variable types: 96 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e-02, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [7e-01, 2e+01]
  GenCon coe range [6e-03, 4e+00]
Presolve added 216 rows and 204 columns
Presolve time: 0.03s
Presolved: 288 rows, 516 columns, 1512 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 84 quadratic objective terms
Variable types: 300 continuous, 216 integer (216 binary)

Root relaxation: objective 0.000000e+00, 577 iterations, 0.01 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   72          -    0.00000      -     -    0s
H    0     0                    8481.4184602    0.00000   100%     -    0s
H    0     0                    7968.8256533    0.00000   100%     -    0s
     0     0    0.17564    0   71 7968.82565    0.17564   100%     -    0s
     0     2    0.17564    0   71 7968.82565    0.17564   100%     -    0s
H   32    48                    7662.6201765    0.17564   100%   2.4    0s
H   35    48                    7496.0611362    0.17564   100%   2.5    0s
H   42    48                    7240.7135171    0.17564   100%   2.6    0s
H   79    96                    6849.1572649    0.17564   100%   2.4    0s
H  534   640                    6625.6410707    0.17564   100%   2.5    0s
H  583   640                    6572.8817162    0.17564   100%   2.5    0s
H  976  1120                    6554.0913348    0.17564   100%   2.5    0s
H  979  1120                    6356.2096250    0.17564   100%   2.5    0s
H 1024  1120                    4366.4542987    0.17564   100%   2.5    0s
H 1479  1616                    4333.3878270    0.23723   100%   2.5    0s
H 1615  1792                    2330.5228191    0.23723   100%   2.5    0s
H 1640  1792                    1487.9410611    0.23723   100%   2.5    0s
H 1791  2026                     815.8358165    0.23723   100%   2.5    0s
H 1909  2022                     770.7122794    0.23723   100%   2.4    0s
H 1911  1880                     417.4946596    0.23723   100%   2.4    0s
H 2939  2413                     356.4455055    0.23723   100%   2.3    0s
H 2941  2260                     296.1498747    0.23723   100%   2.3    0s
H 2948  2256                     291.8545523    0.23723   100%   2.3    0s
H 4271  2741                     242.9096595    0.24329   100%   2.2    0s
H 4273  2605                     207.0122248    0.24329   100%   2.2    0s
H 4351  2524                     201.2680010    0.24329   100%   2.4    0s
H 4353  2399                     186.2839661    0.24329   100%   2.4    0s
H 4356  2280                     185.8859640    0.24329   100%   2.4    0s
H 4357  2168                     176.4429973    0.24329   100%   2.4    0s
H 4363  2060                     151.3052946    0.24329   100%   2.4    0s
H 4366  1958                     133.9491473    0.24329   100%   2.4    0s
H 4407  1881                     109.4195677    0.24329   100%   2.4    0s
H 5609  2186                     101.9318171    0.24329   100%   2.4    0s
H 5619  2096                      93.1126097    0.24329   100%   2.4    0s
H 5628  2144                      48.5788867    0.24329  99.5%   2.4    0s
H 5908  1922                      40.1291009    0.24329  99.4%   2.4    0s
H16591  5810                      39.5362223    0.38798  99.0%   2.1    1s
H145179 64357                      39.4531122    1.27059  96.8%   1.9    4s
 165785 74081   26.24173  101   49   39.45311    1.36002  96.6%   1.9    5s
 344174 144264    7.81887   84   64   39.45311    1.93570  95.1%   1.9   10s
 552116 216019   17.88472   84   59   39.45311    2.53559  93.6%   1.9   15s
 817697 302265   16.61218   87   61   39.45311    3.20562  91.9%   1.8   20s
 1041196 373411   10.98567   91   61   39.45311    3.65353  90.7%   1.8   25s
 1241034 435495   39.03366   85   60   39.45311    4.02168  89.8%   1.8   30s
 1493162 503280   22.24503   93   56   39.45311    4.51417  88.6%   1.8   35s
 1754098 573526     cutoff   80        39.45311    4.98729  87.4%   1.8   40s
 2011530 635896   14.31244   92   57   39.45311    5.46557  86.1%   1.8   45s
 2271166 696727     cutoff  102        39.45311    5.90097  85.0%   1.8   50s
 2520339 751926   12.50853   78   68   39.45311    6.33485  83.9%   1.8   55s
 2762656 806738   31.11526  106   45   39.45311    6.72393  83.0%   1.8   60s
 3014746 856949     cutoff   86        39.45311    7.15494  81.9%   1.7   65s
 3266676 907909   33.24704   87   61   39.45311    7.56182  80.8%   1.7   70s
 3518202 953288   18.68028   83   65   39.45311    7.97878  79.8%   1.7   75s
 3765051 996850     cutoff   87        39.45311    8.41484  78.7%   1.7   80s
 4016370 1040691   22.03119   89   57   39.45311    8.82593  77.6%   1.7   85s
 4264099 1078361    9.80646   81   56   39.45311    9.22806  76.6%   1.7   90s
 4512891 1114507     cutoff  105        39.45311    9.64819  75.5%   1.7   95s
 4748558 1144783   26.07441   87   64   39.45311   10.06107  74.5%   1.7  100s
 4987525 1178560   32.82594   94   54   39.45311   10.45304  73.5%   1.7  105s
 5226323 1204968     cutoff   90        39.45311   10.85241  72.5%   1.7  110s
 5451311 1230826   26.98669   96   56   39.45311   11.21072  71.6%   1.7  115s
 5672667 1250596   30.38715   94   55   39.45311   11.58046  70.6%   1.7  120s
 5899570 1277775   34.49496   84   61   39.45311   11.93334  69.8%   1.7  125s
 6124266 1301689   15.80412   94   54   39.45311   12.29368  68.8%   1.7  130s
 6351620 1322424   16.74294   93   59   39.45311   12.65774  67.9%   1.7  135s
 6586908 1345721     cutoff   86        39.45311   13.00784  67.0%   1.7  140s
 6835728 1363644   29.10532   97   52   39.45311   13.40203  66.0%   1.7  145s
 7073255 1379120     cutoff   89        39.45311   13.78932  65.0%   1.7  150s
 7316102 1393897   22.36272  100   50   39.45311   14.17644  64.1%   1.7  155s
 7571698 1406113   25.80260   93   56   39.45311   14.60011  63.0%   1.7  160s
 7806783 1418575   35.54183   87   58   39.45311   14.96534  62.1%   1.7  165s
 8040321 1429302     cutoff  105        39.45311   15.33778  61.1%   1.7  170s
 8274987 1438727   33.19829   90   60   39.45311   15.69963  60.2%   1.7  175s
 8502556 1446237   25.73051   88   62   39.45311   16.04842  59.3%   1.7  180s
 8735578 1454410     cutoff   92        39.45311   16.40164  58.4%   1.7  185s
 8952337 1460282     cutoff   97        39.45311   16.73467  57.6%   1.6  190s
 9171735 1467737   21.50757   98   50   39.45311   17.06843  56.7%   1.6  195s
 9391921 1474940   17.46659   91   62   39.45311   17.39169  55.9%   1.6  200s
 9615705 1479566     cutoff  101        39.45311   17.72636  55.1%   1.6  205s
 9828250 1483041   31.50793  103   44   39.45311   18.04469  54.3%   1.6  210s
 10048865 1486945     cutoff  101        39.45311   18.37386  53.4%   1.6  215s
 10292850 1489063   26.93361  104   47   39.45311   18.73443  52.5%   1.6  220s
 10530001 1492732   24.59770   92   56   39.45311   19.08087  51.6%   1.6  225s
 10777191 1493929   38.20497   91   54   39.45311   19.44060  50.7%   1.6  230s
 11022906 1496418   29.66785   97   50   39.45311   19.79008  49.8%   1.6  235s
 11269735 1497704   20.54320   71   64   39.45311   20.13737  49.0%   1.6  240s
 11502083 1495473   24.49146   84   56   39.45311   20.47028  48.1%   1.6  245s
 11722805 1494829     cutoff  101        39.45311   20.77610  47.3%   1.6  250s
 11965532 1491167     cutoff   98        39.45311   21.12159  46.5%   1.6  255s
 12215236 1487169     cutoff   90        39.45311   21.47131  45.6%   1.6  260s
 12461925 1482325     cutoff  102        39.45311   21.80650  44.7%   1.6  265s
 12697795 1475883   28.82909   87   57   39.45311   22.13169  43.9%   1.6  270s
 12951753 1468422     cutoff   88        39.45311   22.48433  43.0%   1.6  275s
 13191483 1462584     cutoff   78        39.45311   22.80983  42.2%   1.6  280s
 13425133 1453586   24.52822   91   58   39.45311   23.13322  41.4%   1.6  285s
 13666530 1443787   31.55078   83   59   39.45311   23.47273  40.5%   1.6  290s
 13913161 1435610   33.22128   98   51   39.45311   23.80301  39.7%   1.6  295s
 14155355 1423933     cutoff  109        39.45311   24.13725  38.8%   1.6  300s
 14388592 1413985     cutoff   89        39.45311   24.44660  38.0%   1.6  305s
 14627763 1401624     cutoff   89        39.45311   24.76652  37.2%   1.6  310s
 14868658 1389071     cutoff   83        39.45311   25.08815  36.4%   1.6  315s
 15116502 1377382   25.54177   85   64   39.45311   25.40554  35.6%   1.6  320s
 15349232 1363677   35.00544   97   49   39.45311   25.72003  34.8%   1.6  325s
 15599463 1346271     cutoff   87        39.45311   26.05238  34.0%   1.6  330s
 15824646 1328937   34.83769   92   57   39.45311   26.34918  33.2%   1.6  335s
 16044027 1310734   35.91825   87   60   39.45311   26.64391  32.5%   1.6  340s
 16268632 1293615   31.18864   97   52   39.45311   26.93976  31.7%   1.6  345s
 16486431 1274498     cutoff   91        39.45311   27.23295  31.0%   1.6  350s
 16711487 1254808     cutoff  101        39.45311   27.53681  30.2%   1.6  355s
 16926873 1234025   31.62151  106   45   39.45311   27.83112  29.5%   1.6  360s
 17145826 1211700     cutoff   84        39.45311   28.13335  28.7%   1.6  365s
 17358218 1187153     cutoff   87        39.45311   28.43146  27.9%   1.6  370s
 17576889 1161380   31.23888   95   49   39.45311   28.74490  27.1%   1.6  375s
 17816783 1130024   38.58931   97   51   39.45311   29.09635  26.3%   1.6  380s
 18055136 1097838   34.12314   91   55   39.45311   29.45028  25.4%   1.6  385s
 18306531 1061238   33.87001  101   45   39.45311   29.83607  24.4%   1.6  390s
 18554401 1022072   30.49636   85   62   39.45311   30.22919  23.4%   1.6  395s
 18804600 980405   36.44989   91   58   39.45311   30.64032  22.3%   1.6  400s
 19028019 941521   39.09900   88   55   39.45311   31.00698  21.4%   1.6  405s
 19263792 898913   39.33075   92   53   39.45311   31.41112  20.4%   1.6  410s
 19487035 856086   34.53032   92   55   39.45311   31.80030  19.4%   1.6  415s
 19713393 810315   36.33862   89   55   39.45311   32.20393  18.4%   1.6  420s
 19926446 766850   37.03955   93   57   39.45311   32.58369  17.4%   1.6  425s
 20144605 718359     cutoff  105        39.45311   32.98927  16.4%   1.6  430s
 20363265 667585     cutoff   84        39.45311   33.40343  15.3%   1.6  435s
 20568742 616955     cutoff   89        39.45311   33.81723  14.3%   1.6  440s
 20789654 558869   38.02474   93   54   39.45311   34.27628  13.1%   1.6  445s
 21004937 499163   38.76291   93   50   39.45311   34.74734  11.9%   1.6  450s
 21245590 427357     cutoff   94        39.45311   35.31322  10.5%   1.5  455s
 21482689 350741     cutoff   83        39.45311   35.91683  8.96%   1.5  460s
 21726933 266604     cutoff   89        39.45311   36.59822  7.24%   1.5  465s
 21962019 173803     cutoff   81        39.45311   37.37292  5.27%   1.5  470s

Explored 21991320 nodes (33905702 simplex iterations) in 470.60 seconds (381.32 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 39.4531 39.5362 48.5789 ... 186.284

Optimal solution found (tolerance 5.00e-02)
Best objective 3.945311217434e+01, best bound 3.748306884475e+01, gap 4.9934%
Optimal solution found.
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1]
Cluster Assignments from Gurobi MIQP using MSE

Cluster 0 weights w_0^* (including bias) in original space:
[-9.73278761 -1.65208822 -1.8592822  -0.97327228]

Cluster 1 weights w_1^* (including bias) in original space:
[10.09360602 -0.10000684  0.06549217  0.21741465]

Cluster 2 weights w_2^* (including bias) in original space:
[1.21485108 1.48151392 1.35887916 1.1302848 ]
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 4.02619555e-01  9.98391781e-05 -6.43511028e-04  3.85528592e-04]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
117.79724298157605
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1]
-----------------------------------
Regression weights for cluster 0: y = -1.6521x_0 + -1.8593x_1 + -0.9733x_2 + -9.7328
Regression weights for cluster 0 after refit: y = -1.6474x_1 + -1.8555x_2 + -0.9688x_3 + -9.7502
-----------------------------------
Regression weights for cluster 1: y = -0.1x_0 + 0.0655x_1 + 0.2174x_2 + 10.0936
Regression weights for cluster 1 after refit: y = -0.1046x_1 + 0.0603x_2 + 0.2145x_3 + 10.1101
-----------------------------------
Regression weights for cluster 2: y = 1.4815x_0 + 1.3589x_1 + 1.1303x_2 + 1.2149
Regression weights for cluster 2 after refit: y = 1.4817x_1 + 1.3592x_2 + 1.13x_3 + 1.2154
{'time_milp': 471.5936462879181, 'time_greedy': np.float64(0.48699629306793213), 'time_refit_milp_assignment': 474.4464511871338, 'mse_refit_ground_truth_assignment': np.float64(0.560888149669305), 'r2_refit_ground_truth_assignment': 0.9952816458487453, 'weight_mismatch_refit_ground_truth_assignment': np.float64(0.9937282497696122), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(0.5187101656954346), 'r2_milp': 0.9956364593100246, 'weight_mismatch_milp': np.float64(1.0658868722889676), 'refit-weight_mismatch_milp': np.float64(0.23174714960042847), 'rand_score_milp': np.float64(0.9640062597809077), 'label_mismatch_milp': np.float64(0.027777777777777776), 'mse_refit_milp_assignment': np.float64(0.518666102621791), 'r2_refit_milp_assignment': 0.9956368299814081, 'weight_mismatch_refit_milp_assignment': np.float64(1.0616430854606491), 'refit-weight_mismatch_refit_milp_assignment': np.float64(0.19856491793161887), 'rand_score_refit_milp_assignment': np.float64(0.9640062597809077), 'label_mismatch_refit_milp_assignment': np.float64(0.027777777777777776), 'mse_greedy': np.float64(5.769713611046529), 'r2_greedy': np.float64(0.9514634919916165), 'weight_mismatch_greedy': np.float64(14.723490857780357), 'refit-weight_mismatch_greedy': np.float64(14.415793550558394), 'rand_score_greedy': np.float64(0.8082942097026604), 'label_mismatch_greedy': np.float64(0.22777777777777777), 'mse_greedy_sem': np.float64(1.6704495312359187), 'r2_greedy_sem': np.float64(0.014052307014892955), 'weight_mismatch_greedy_sem': np.float64(3.2651063655744252), 'refit-weight_mismatch_greedy_sem': np.float64(3.3103804657685814), 'rand_score_greedy_sem': np.float64(0.029509560563579097), 'label_mismatch_greedy_sem': np.float64(0.040647876175230295), 'mse_ground_truth': np.float64(0.806788238295377), 'r2_ground_truth': np.float64(0.9929363031132942), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(117.79724298157605), 'r2_baseline_sklearn': np.float64(0.009055351309941284), 'mse_milp_val': np.float64(1.1173674443736237), 'r2_milp_val': 0.9895467020733705, 'label_mismatch_milp_val': np.float64(0.020833333333333332), 'mse_refit_milp_assignment_val': np.float64(1.116704841035923), 'r2_refit_milp_assignment_val': 0.9895529009206083, 'label_mismatch_refit_milp_assignment_val': np.float64(0.020833333333333332), 'mse_greedy_val': np.float64(17.361634959738296), 'label_mismatch_greedy_val': np.float64(0.22604166666666664), 'mse_greedy_val_sem': np.float64(5.998319447674206), 'label_mismatch_greedy_val_sem': np.float64(0.03270637774911548), 'r2_greedy_val': np.float64(0.8375768475792057), 'r2_greedy_val_sem': np.float64(0.056116025718633625), 'mse_refit_ground_truth_assignment_val': np.float64(1.2246382026681406), 'r2_refit_ground_truth_assignment_val': 0.9885431528819971, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.041666666666666664), 'mse_ground_truth_val': np.float64(1.1733574429276123), 'r2_ground_truth_val': 0.989022899327243, 'label_mismatch_ground_truth_val': np.float64(0.041666666666666664), 'mse_baseline_sklearn_val': np.float64(107.4592599475075), 'r2_baseline_sklearn_val': -0.005312679246820995}
