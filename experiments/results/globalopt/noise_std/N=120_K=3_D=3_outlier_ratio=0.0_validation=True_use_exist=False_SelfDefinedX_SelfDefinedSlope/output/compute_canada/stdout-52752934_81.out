==================== Evaluating with noise_std = 0.3 in Dataset 1 with random state = 8 ====================
ODS is enabled
mse 0.11309241078347845
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 312 columns and 216 nonzeros
Model fingerprint: 0x524d934a
Model has 84 quadratic objective terms
Model has 216 general constraints
Variable types: 96 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e-02, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [1e-01, 2e+01]
  GenCon coe range [3e-03, 4e+00]
Presolve added 216 rows and 204 columns
Presolve time: 0.02s
Presolved: 288 rows, 516 columns, 1512 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 84 quadratic objective terms
Variable types: 300 continuous, 216 integer (216 binary)

Root relaxation: objective 0.000000e+00, 577 iterations, 0.01 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   72          -    0.00000      -     -    0s
H    0     0                    7849.8749950    0.00000   100%     -    0s
H    0     0                    7276.7321781    0.00000   100%     -    0s
     0     0    0.16824    0   71 7276.73218    0.16824   100%     -    0s
     0     2    0.16824    0   71 7276.73218    0.16824   100%     -    0s
H   31    48                    7271.4617006    0.16824   100%   2.4    0s
H   35    48                    7087.2564986    0.16824   100%   2.5    0s
H   42    48                    6665.3487865    0.16824   100%   2.6    0s
H   79    96                    6156.0801144    0.16824   100%   2.4    0s
H  296   352                    6142.3753751    0.16824   100%   2.5    0s
H  541   640                    6084.5276927    0.16824   100%   2.5    0s
H  611   640                    6031.7314779    0.16824   100%   2.5    0s
H  618   640                    6026.1899112    0.16824   100%   2.5    0s
H 1630  1927                    5382.9540872    0.25906   100%   2.5    0s
H 1663  1927                    4077.7732618    0.25906   100%   2.5    0s
H 1723  1927                    4075.3086749    0.25906   100%   2.5    0s
H 1744  1927                    3977.5039796    0.25906   100%   2.5    0s
H 1900  1927                    3975.9041341    0.25906   100%   2.4    0s
H 1926  2140                    3970.4272118    0.25906   100%   2.4    0s
H 1952  2140                    2955.5335660    0.25906   100%   2.4    0s
H 1953  2140                    2765.0667772    0.25906   100%   2.4    0s
H 1954  2140                    1624.7651521    0.25906   100%   2.4    0s
H 3099  2808                     429.4074668    0.25906   100%   2.3    0s
H 3100  2786                     418.6232220    0.25906   100%   2.3    0s
H 3102  2748                     404.8151197    0.25906   100%   2.3    0s
H 3110  2748                     404.7025551    0.25906   100%   2.3    0s
* 4280  3150             139     371.1335869    0.25906   100%   2.2    0s
* 4483  3563             140     351.3803538    0.25906   100%   2.2    0s
H 5363  3090                     214.2866757    0.25906   100%   2.2    0s
H 5809  3231                     204.4482286    0.25906   100%   2.3    0s
H38348 19203                     202.3041706    0.48884   100%   2.1    1s
H112911 37941                      26.9376068    0.85116  96.8%   2.1    4s
H115067 25569                       8.5475720    0.88050  89.7%   2.1    4s
 132177 31915    1.61002   75   66    8.54757    1.02963  88.0%   2.0    5s
 390953 107781    7.03509   92   55    8.54757    2.68509  68.6%   1.9   10s
 660242 132077     cutoff   86         8.54757    4.12924  51.7%   1.8   15s
 917838 107299    5.65117  108   44    8.54757    5.47145  36.0%   1.8   20s
 1187787 29790    8.01672   81   63    8.54757    7.57303  11.4%   1.7   25s

Explored 1228428 nodes (2069807 simplex iterations) in 25.74 seconds (20.78 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 8.54757 26.9376 202.304 ... 418.623

Optimal solution found (tolerance 5.00e-02)
Best objective 8.547571973236e+00, best bound 8.134764346159e+00, gap 4.8295%
Optimal solution found.
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Cluster Assignments from Gurobi MIQP using MSE

Cluster 0 weights w_0^* (including bias) in original space:
[-10.00191895  -1.41140596  -1.65810306  -0.93268551]

Cluster 1 weights w_1^* (including bias) in original space:
[ 9.93011523 -0.02164528  0.27226283  0.14084124]

Cluster 2 weights w_2^* (including bias) in original space:
[0.97089436 1.74713232 1.52804712 0.9901663 ]
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 5.25800692e-01 -1.45468478e-05 -1.13824264e-04  1.51263312e-04]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
109.02599687548043
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
-----------------------------------
Regression weights for cluster 0: y = -1.4114x_0 + -1.6581x_1 + -0.9327x_2 + -10.0019
Regression weights for cluster 0 after refit: y = -1.4078x_1 + -1.6548x_2 + -0.9277x_3 + -10.0172
-----------------------------------
Regression weights for cluster 1: y = -0.0216x_0 + 0.2723x_1 + 0.1408x_2 + 9.9301
Regression weights for cluster 1 after refit: y = -0.0264x_1 + 0.2655x_2 + 0.1367x_3 + 9.9484
-----------------------------------
Regression weights for cluster 2: y = 1.7471x_0 + 1.528x_1 + 0.9902x_2 + 0.9709
Regression weights for cluster 2 after refit: y = 1.7477x_1 + 1.5289x_2 + 0.9899x_3 + 0.9705
{'time_milp': 26.0937020778656, 'time_greedy': np.float64(0.4755221247673035), 'time_refit_milp_assignment': 28.963372468948364, 'mse_refit_ground_truth_assignment': np.float64(0.08927461739384775), 'r2_refit_ground_truth_assignment': 0.9991815873258608, 'weight_mismatch_refit_ground_truth_assignment': np.float64(0.5040821052329985), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(0.08931881321227005), 'r2_milp': 0.9991811821668246, 'weight_mismatch_milp': np.float64(0.5080437285405912), 'refit-weight_mismatch_milp': np.float64(0.038400667479538166), 'rand_score_milp': 1.0, 'label_mismatch_milp': np.float64(0.0), 'mse_refit_milp_assignment': np.float64(0.08927461739384775), 'r2_refit_milp_assignment': 0.9991815873258608, 'weight_mismatch_refit_milp_assignment': np.float64(0.5040821052329985), 'refit-weight_mismatch_refit_milp_assignment': np.float64(0.0), 'rand_score_refit_milp_assignment': 1.0, 'label_mismatch_refit_milp_assignment': np.float64(0.0), 'mse_greedy': np.float64(3.600798234353501), 'r2_greedy': np.float64(0.9669901815539335), 'weight_mismatch_greedy': np.float64(9.168688563024244), 'refit-weight_mismatch_greedy': np.float64(8.902522755478277), 'rand_score_greedy': np.float64(0.8752151799687011), 'label_mismatch_greedy': np.float64(0.15208333333333335), 'mse_greedy_sem': np.float64(1.4165924182918823), 'r2_greedy_sem': np.float64(0.012986414538243344), 'weight_mismatch_greedy_sem': np.float64(3.217257563263129), 'refit-weight_mismatch_greedy_sem': np.float64(3.258011423251026), 'rand_score_greedy_sem': np.float64(0.03268407173233452), 'label_mismatch_greedy_sem': np.float64(0.041903263448737745), 'mse_ground_truth': np.float64(0.11309241078347845), 'r2_ground_truth': np.float64(0.998985946657813), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(109.02599687548043), 'r2_baseline_sklearn': np.float64(0.0005192936317961472), 'mse_milp_val': np.float64(0.5139261433444495), 'r2_milp_val': 0.9955343492947131, 'label_mismatch_milp_val': np.float64(0.0625), 'mse_refit_milp_assignment_val': np.float64(0.5213177881756933), 'r2_refit_milp_assignment_val': 0.995470121186489, 'label_mismatch_refit_milp_assignment_val': np.float64(0.0625), 'mse_greedy_val': np.float64(9.387527025215139), 'label_mismatch_greedy_val': np.float64(0.17604166666666665), 'mse_greedy_val_sem': np.float64(4.3349881765800236), 'label_mismatch_greedy_val_sem': np.float64(0.033335903135590865), 'r2_greedy_val': np.float64(0.918429102656186), 'r2_greedy_val_sem': np.float64(0.037667947542377594), 'mse_refit_ground_truth_assignment_val': np.float64(0.5213177881756933), 'r2_refit_ground_truth_assignment_val': 0.995470121186489, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.0625), 'mse_ground_truth_val': np.float64(0.433520151543715), 'r2_ground_truth_val': 0.99623301986955, 'label_mismatch_ground_truth_val': np.float64(0.0625), 'mse_baseline_sklearn_val': np.float64(115.25899823179016), 'r2_baseline_sklearn_val': -0.0015182792510481935}
