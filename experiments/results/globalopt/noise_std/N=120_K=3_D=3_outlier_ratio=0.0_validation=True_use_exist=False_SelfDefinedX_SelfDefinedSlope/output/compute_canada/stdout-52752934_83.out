==================== Evaluating with noise_std = 0.9 in Dataset 1 with random state = 8 ====================
ODS is enabled
mse 1.0178316970513068
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 312 columns and 216 nonzeros
Model fingerprint: 0xbb759aa5
Model has 84 quadratic objective terms
Model has 216 general constraints
Variable types: 96 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e-02, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [3e-01, 2e+01]
  GenCon coe range [3e-03, 4e+00]
Presolve added 216 rows and 204 columns
Presolve time: 0.02s
Presolved: 288 rows, 516 columns, 1512 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 84 quadratic objective terms
Variable types: 300 continuous, 216 integer (216 binary)

Root relaxation: objective 0.000000e+00, 577 iterations, 0.01 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   72          -    0.00000      -     -    0s
H    0     0                    7874.0502595    0.00000   100%     -    0s
H    0     0                    7275.7953790    0.00000   100%     -    0s
     0     0    0.15045    0   71 7275.79538    0.15045   100%     -    0s
     0     2    0.15045    0   71 7275.79538    0.15045   100%     -    0s
H   35    48                    7087.8264806    0.15045   100%   2.5    0s
H   42    48                    6657.0700588    0.15045   100%   2.6    0s
H   79    96                    6124.9596177    0.15045   100%   2.4    0s
H  443   514                    5751.2078162    0.15045   100%   2.5    0s
H 1601  1650                    5498.8826739    0.17515   100%   2.5    0s
H 1601  1650                    4237.4869548    0.17515   100%   2.5    0s
H 1691  1926                    4212.7920927    0.17515   100%   2.4    0s
H 1692  1926                    4060.4774072    0.17515   100%   2.4    0s
H 1840  1926                    3504.9765258    0.17515   100%   2.4    0s
H 1903  1926                    3003.3170490    0.17515   100%   2.4    0s
H 2019  2326                    2898.5686618    0.17515   100%   2.4    0s
H 2022  2326                    2768.7799126    0.17515   100%   2.4    0s
H 2094  2326                    2502.5334772    0.17515   100%   2.4    0s
H 2097  2326                    2227.7599673    0.17515   100%   2.4    0s
H 2422  2806                    2142.5172938    0.17515   100%   2.4    0s
H 2515  2806                    1253.3424786    0.17515   100%   2.3    0s
H 2722  2802                     914.2699776    0.17515   100%   2.3    0s
H 3177  3048                     621.4970273    0.17515   100%   2.3    0s
H 3180  3002                     559.8422624    0.17515   100%   2.3    0s
H 3213  2944                     492.9203362    0.17515   100%   2.3    0s
H 3854  3054                     470.9045312    0.27518   100%   2.3    0s
H 4639  3500                     470.1193689    0.27518   100%   2.3    0s
H 5011  3432                     467.2531401    0.27518   100%   2.4    0s
H 5014  3265                     465.5232099    0.27518   100%   2.4    0s
H 5023  3104                     462.6569811    0.27518   100%   2.4    0s
H 5106  2994                     430.5485792    0.27518   100%   2.4    0s
H 5353  3026                     408.8917437    0.27518   100%   2.4    0s
H 5385  2879                     403.0936460    0.27518   100%   2.4    0s
H 6480  3395                     399.9466689    0.27518   100%   2.4    0s
H 6488  3249                     393.4045719    0.27518   100%   2.4    0s
H 6957  3694                     393.0513043    0.27518   100%   2.4    0s
H 7827  3798                     372.4774155    0.27518   100%   2.4    1s
H 8680  3775                     336.3264572    0.27518   100%   2.3    1s
H 8690  3629                     324.6903686    0.27518   100%   2.3    1s
H 8787  3458                     308.8109079    0.27518   100%   2.3    1s
H23675 10898                     285.2248758    0.30774   100%   2.1    1s
H26299 11630                     239.2415805    0.32636   100%   2.1    1s
H26986 11556                     230.9664390    0.32636   100%   2.1    1s
H27588 12151                     228.3328870    0.33342   100%   2.1    1s
H29242 13106                     225.7007343    0.33342   100%   2.1    1s
H29421 13035                     221.6018933    0.33342   100%   2.1    1s
H29503 13030                     221.3026259    0.33342   100%   2.1    1s
H43850 21303                     219.8466669    0.53248   100%   2.1    2s
H49430 24052                     216.5247714    0.55752   100%   2.1    2s
H55834 28278                     214.9939343    0.59455   100%   2.1    2s
H62056 31582                     214.5947968    0.64724   100%   2.1    2s
H67594 34418                     212.6746479    0.65015   100%   2.1    2s
 124729 66045  110.61290  103   49  212.67465    0.93791   100%   2.1    5s
 254971 141011    8.73155   67   65  212.67465    1.34737  99.4%   2.0   10s
 390940 212509     cutoff  106       212.67465    1.63431  99.2%   2.0   15s
H476021 200501                     100.7634898    1.78569  98.2%   2.0   18s
H476024 197160                      95.8190162    1.78569  98.1%   2.0   18s
H477975 196949                      95.7146644    1.78731  98.1%   2.0   18s
H478041 195325                      93.0935006    1.78731  98.1%   2.0   18s
H478086 194389                      91.7632719    1.78731  98.1%   2.0   18s
*478302 188210             133      83.2360606    1.79409  97.8%   2.0   18s
H480383 165332                      58.8710824    1.79817  96.9%   2.0   18s
H480397 163783                      57.4280657    1.79817  96.9%   2.0   18s
 566855 200752    8.39294   75   59   57.42807    2.05626  96.4%   2.0   20s
 842834 307346     cutoff   75        57.42807    2.87824  95.0%   2.0   25s
 1118498 403916     cutoff   93        57.42807    3.63560  93.7%   1.9   30s
 1394627 496652    4.93582   69   64   57.42807    4.33996  92.4%   1.9   35s
 1673937 584039   39.04181   94   50   57.42807    4.97210  91.3%   1.9   40s
 1950259 669873   28.90347   70   63   57.42807    5.61357  90.2%   1.9   45s
 2229228 746902   19.45804   90   57   57.42807    6.24523  89.1%   1.8   50s
 2493519 818870   44.31639   87   58   57.42807    6.84409  88.1%   1.8   55s
 2749431 886374   48.85492  103   45   57.42807    7.41978  87.1%   1.8   60s
 3018488 959141     cutoff   95        57.42807    7.99642  86.1%   1.8   65s
 3291429 1022950     cutoff   86        57.42807    8.61432  85.0%   1.8   70s
 3560445 1080622   22.34409   78   64   57.42807    9.21661  84.0%   1.8   75s
 3834471 1139070   46.90302   70   62   57.42807    9.80311  82.9%   1.8   80s
 4112001 1196458   29.95817   83   60   57.42807   10.40311  81.9%   1.8   85s
 4386196 1247581   23.71448  103   48   57.42807   11.02208  80.8%   1.8   90s
 4658625 1298704   51.06580   97   47   57.42807   11.61512  79.8%   1.8   95s
 4901286 1336770   35.22251   94   55   57.42807   12.15643  78.8%   1.8  100s
 5145675 1376645   50.53213   91   57   57.42807   12.66712  77.9%   1.8  105s
 5388911 1411856     cutoff   96        57.42807   13.19231  77.0%   1.7  110s
 5622321 1441212   32.83571   86   61   57.42807   13.73320  76.1%   1.7  115s
 5857877 1474171     cutoff   79        57.42807   14.24144  75.2%   1.7  120s
 6088090 1505367   34.53156   93   53   57.42807   14.73067  74.3%   1.7  125s
 6330162 1535008   48.21506   91   54   57.42807   15.24518  73.5%   1.7  130s
 6565456 1565147   33.18270   84   56   57.42807   15.72831  72.6%   1.7  135s
 6806052 1594426   24.70441   81   61   57.42807   16.21833  71.8%   1.7  140s
 7032657 1620594   43.73270   99   47   57.42807   16.68331  70.9%   1.7  145s
 7268989 1650292   55.34942   90   57   57.42807   17.15072  70.1%   1.7  150s
 7506948 1678950   51.80442  102   47   57.42807   17.56680  69.4%   1.7  155s
 7741080 1706024   51.47151   78   61   57.42807   17.95324  68.7%   1.7  160s
 7978718 1731690     cutoff   96        57.42807   18.35048  68.0%   1.7  165s
 8212299 1752397   53.77992  101   49   57.42807   18.75742  67.3%   1.7  170s
 8456530 1773483   22.51440   82   62   57.42807   19.18116  66.6%   1.7  175s
 8697399 1794904   25.13330   95   48   57.42807   19.60268  65.9%   1.7  180s
 8930885 1815884   30.54628   78   62   57.42807   20.01433  65.1%   1.7  185s
 9158716 1833705   51.72217  102   42   57.42807   20.42024  64.4%   1.7  190s
 9397739 1854203   44.34133   89   56   57.42807   20.83854  63.7%   1.7  195s
 9651019 1871890   29.50224  101   43   57.42807   21.31242  62.9%   1.7  200s
 9879254 1887601   23.53176  100   50   57.42807   21.71171  62.2%   1.7  205s
 10122583 1904620   51.88288   80   61   57.42807   22.12614  61.5%   1.7  210s
 10364137 1919460     cutoff  101        57.42807   22.54567  60.7%   1.7  215s
 10597702 1932648   37.02933   86   67   57.42807   22.95847  60.0%   1.7  220s
 10846546 1945816   50.51389   81   62   57.42807   23.38269  59.3%   1.7  225s
 11083056 1958389   35.48337   77   61   57.42807   23.77252  58.6%   1.7  230s
 11319477 1970691     cutoff   85        57.42807   24.17266  57.9%   1.7  235s
 11563782 1982400     cutoff   90        57.42807   24.58523  57.2%   1.7  240s
 11785838 1990027   42.06186   86   61   57.42807   24.96980  56.5%   1.7  245s
 12024462 1999329     cutoff  102        57.42807   25.37705  55.8%   1.7  250s
 12243704 2006971   55.66403  102   44   57.42807   25.74967  55.2%   1.7  255s
 12478824 2017205   44.73312   88   61   57.42807   26.14056  54.5%   1.7  260s
 12713700 2027089   38.23552   77   62   57.42807   26.52851  53.8%   1.7  265s
 12939516 2034100     cutoff   88        57.42807   26.90691  53.1%   1.7  270s
 13171181 2041807   43.48469  100   44   57.42807   27.28454  52.5%   1.7  275s
 13394354 2048375     cutoff   83        57.42807   27.63884  51.9%   1.7  280s
 13639020 2053687     cutoff   99        57.42807   28.03590  51.2%   1.7  285s
 13884081 2058095     cutoff   91        57.42807   28.43465  50.5%   1.7  290s
 14124157 2061821     cutoff   85        57.42807   28.81975  49.8%   1.7  295s
 14363132 2066323     cutoff   76        57.42807   29.19915  49.2%   1.6  300s
 14588092 2070890     cutoff   99        57.42807   29.55226  48.5%   1.6  305s
 14833021 2075182     cutoff   93        57.42807   29.92812  47.9%   1.6  310s
 15057964 2074995     cutoff  103        57.42807   30.28505  47.3%   1.6  315s
 15288322 2075971     cutoff   96        57.42807   30.64509  46.6%   1.6  320s
 15522891 2074635   46.58386   88   55   57.42807   31.01321  46.0%   1.6  325s
 15763921 2073516     cutoff   90        57.42807   31.38642  45.3%   1.6  330s
 16003388 2071352     cutoff  101        57.42807   31.74853  44.7%   1.6  335s
 16232653 2071118     cutoff  102        57.42807   32.09198  44.1%   1.6  340s
 16482481 2068256   38.56350   82   57   57.42807   32.47105  43.5%   1.6  345s
 16715736 2064621   48.71569   91   52   57.42807   32.82396  42.8%   1.6  350s
 16958377 2061529   43.89925  105   47   57.42807   33.18253  42.2%   1.6  355s
 17200416 2056774   35.73055   92   52   57.42807   33.54395  41.6%   1.6  360s
 17435616 2052093   50.82975   77   56   57.42807   33.88944  41.0%   1.6  365s
 17676785 2045694   53.37966   70   64   57.42807   34.24217  40.4%   1.6  370s
 17917695 2038779     cutoff   89        57.42807   34.59808  39.8%   1.6  375s
 18163285 2029088   37.46611   96   53   57.42807   34.96212  39.1%   1.6  380s
 18392437 2019972   37.98513   92   60   57.42807   35.30777  38.5%   1.6  385s
 18639326 2010301     cutoff   85        57.42807   35.67151  37.9%   1.6  390s
 18873036 1999722     cutoff   93        57.42807   36.01643  37.3%   1.6  395s
 19116510 1986205   55.94057   88   58   57.42807   36.38138  36.6%   1.6  400s
 19347824 1973095     cutoff   91        57.42807   36.72900  36.0%   1.6  405s
 19584776 1958971     cutoff  101        57.42807   37.07989  35.4%   1.6  410s
 19813732 1944241     cutoff   82        57.42807   37.42103  34.8%   1.6  415s
 20062364 1928369     cutoff   92        57.42807   37.78558  34.2%   1.6  420s
 20290800 1911404   46.96943  103   46   57.42807   38.12654  33.6%   1.6  425s
 20529424 1894232   56.26220  110   39   57.42807   38.47806  33.0%   1.6  430s
 20765920 1875112   53.94813  106   43   57.42807   38.83617  32.4%   1.6  435s
 20998779 1854008     cutoff   79        57.42807   39.19171  31.8%   1.6  440s
 21239759 1835814   41.58206   72   59   57.42807   39.55231  31.1%   1.6  445s
 21461871 1814729   50.64445   88   55   57.42807   39.89295  30.5%   1.6  450s
 21699142 1790955     cutoff   85        57.42807   40.26557  29.9%   1.6  455s
 21941238 1765966     cutoff   94        57.42807   40.64353  29.2%   1.6  460s
 22174024 1741068     cutoff   80        57.42807   41.00629  28.6%   1.6  465s
 22401539 1715023   47.45699   77   55   57.42807   41.36905  28.0%   1.6  470s
 22641968 1685914   46.07208   97   50   57.42807   41.75398  27.3%   1.6  475s
 22872383 1657595     cutoff   83        57.42807   42.12760  26.6%   1.6  480s
 23111339 1625991     cutoff   90        57.42807   42.51860  26.0%   1.6  485s
 23347264 1593506     cutoff   97        57.42807   42.90816  25.3%   1.6  490s
 23580649 1560131   43.35178   89   63   57.42807   43.29696  24.6%   1.6  495s
 23804377 1526112     cutoff  105        57.42807   43.67532  23.9%   1.6  500s
 24040106 1489534     cutoff   97        57.42807   44.07149  23.3%   1.6  505s
 24273500 1451914   47.96777   99   48   57.42807   44.47596  22.6%   1.6  510s
 24509528 1410803     cutoff   77        57.42807   44.89245  21.8%   1.6  515s
 24745347 1369089   46.38136   81   58   57.42807   45.31230  21.1%   1.6  520s
 24964642 1327794     cutoff   88        57.42807   45.70768  20.4%   1.6  525s
 25214284 1279711   46.37321   78   66   57.42807   46.16477  19.6%   1.6  530s
 25449061 1233072   53.15256   85   52   57.42807   46.59730  18.9%   1.6  535s
 25686203 1183680   55.16725   77   61   57.42807   47.05345  18.1%   1.6  540s
 25920237 1132961   51.02512   82   59   57.42807   47.50966  17.3%   1.6  545s
 26142271 1082187     cutoff   81        57.42807   47.95232  16.5%   1.6  550s
 26372164 1025826     cutoff   83        57.42807   48.41964  15.7%   1.6  555s
 26605746 967082   53.87417   74   60   57.42807   48.90395  14.8%   1.6  560s
 26846325 904095     cutoff  106        57.42807   49.41133  14.0%   1.6  565s
 27083417 838685     cutoff   95        57.42807   49.92917  13.1%   1.6  570s
 27315837 770824     cutoff   92        57.42807   50.45543  12.1%   1.6  575s
 27539414 703029     cutoff  107        57.42807   50.97647  11.2%   1.6  580s
 27772823 630018     cutoff   82        57.42807   51.53618  10.3%   1.6  585s
 28007506 553040   55.62060   98   51   57.42807   52.12343  9.24%   1.6  590s
 28241782 471201     cutoff   92        57.42807   52.74889  8.15%   1.6  595s
 28464369 390501     cutoff   94        57.42807   53.38025  7.05%   1.6  600s
 28710574 295819   54.95407  100   46   57.42807   54.17858  5.66%   1.6  605s

Explored 28816373 nodes (44994586 simplex iterations) in 607.32 seconds (501.77 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 57.4281 58.8711 83.2361 ... 214.595

Optimal solution found (tolerance 5.00e-02)
Best objective 5.742806569240e+01, best bound 5.456088346150e+01, gap 4.9926%
Optimal solution found.
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]
Cluster Assignments from Gurobi MIQP using MSE

Cluster 0 weights w_0^* (including bias) in original space:
[-10.03619434  -1.55156871  -1.64242036  -0.66584858]

Cluster 1 weights w_1^* (including bias) in original space:
[ 9.93555362 -0.5282135   0.58355147  0.28532039]

Cluster 2 weights w_2^* (including bias) in original space:
[1.03474476 1.91929354 1.31831196 0.91686477]
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 5.75432521e-01 -1.81695640e-05 -9.60990597e-05  1.93121180e-04]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
109.36176835230543
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]
-----------------------------------
Regression weights for cluster 0: y = -1.5516x_0 + -1.6424x_1 + -0.6658x_2 + -10.0362
Regression weights for cluster 0 after refit: y = -1.5481x_1 + -1.639x_2 + -0.6606x_3 + -10.0516
-----------------------------------
Regression weights for cluster 1: y = -0.5282x_0 + 0.5836x_1 + 0.2853x_2 + 9.9356
Regression weights for cluster 1 after refit: y = -0.534x_1 + 0.5776x_2 + 0.2821x_3 + 9.9532
-----------------------------------
Regression weights for cluster 2: y = 1.9193x_0 + 1.3183x_1 + 0.9169x_2 + 1.0347
Regression weights for cluster 2 after refit: y = 1.9197x_1 + 1.3189x_2 + 0.9168x_3 + 1.0345
{'time_milp': 608.6905779838562, 'time_greedy': np.float64(0.4736467480659485), 'time_refit_milp_assignment': 611.4293942451477, 'mse_refit_ground_truth_assignment': np.float64(0.8034715565446301), 'r2_refit_ground_truth_assignment': 0.9926580328947358, 'weight_mismatch_refit_ground_truth_assignment': np.float64(1.5122463157059027), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(0.7680255501274519), 'r2_milp': 0.9929819316202203, 'weight_mismatch_milp': np.float64(1.667712050952734), 'refit-weight_mismatch_milp': np.float64(0.4892713843669551), 'rand_score_milp': np.float64(0.9640062597809077), 'label_mismatch_milp': np.float64(0.027777777777777776), 'mse_refit_milp_assignment': np.float64(0.7679816482649243), 'r2_refit_milp_assignment': 0.9929823327869174, 'weight_mismatch_refit_milp_assignment': np.float64(1.6712427468165585), 'refit-weight_mismatch_refit_milp_assignment': np.float64(0.4824817597595874), 'rand_score_refit_milp_assignment': np.float64(0.9640062597809077), 'label_mismatch_refit_milp_assignment': np.float64(0.027777777777777776), 'mse_greedy': np.float64(4.768443257717771), 'r2_greedy': np.float64(0.9564268912118749), 'weight_mismatch_greedy': np.float64(10.158319181200753), 'refit-weight_mismatch_greedy': np.float64(9.40993521602999), 'rand_score_greedy': np.float64(0.8326291079812206), 'label_mismatch_greedy': np.float64(0.19930555555555557), 'mse_greedy_sem': np.float64(1.4811894158427845), 'r2_greedy_sem': np.float64(0.013534821337734938), 'weight_mismatch_greedy_sem': np.float64(2.685285118588696), 'refit-weight_mismatch_greedy_sem': np.float64(2.786047152539081), 'rand_score_greedy_sem': np.float64(0.029412864029845786), 'label_mismatch_greedy_sem': np.float64(0.038897698981172256), 'mse_ground_truth': np.float64(1.0178316970513068), 'r2_ground_truth': np.float64(0.9909466109262499), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(109.36176835230543), 'r2_baseline_sklearn': np.float64(0.0006733912657668206), 'mse_milp_val': np.float64(1.7233572175779799), 'r2_milp_val': 0.9852481606262964, 'label_mismatch_milp_val': np.float64(0.08333333333333333), 'mse_refit_milp_assignment_val': np.float64(1.731918997001225), 'r2_refit_milp_assignment_val': 0.9851748722833362, 'label_mismatch_refit_milp_assignment_val': np.float64(0.08333333333333333), 'mse_greedy_val': np.float64(12.045508588649177), 'label_mismatch_greedy_val': np.float64(0.2385416666666667), 'mse_greedy_val_sem': np.float64(4.580267321810285), 'label_mismatch_greedy_val_sem': np.float64(0.03613104979796358), 'r2_greedy_val': np.float64(0.8968911343151177), 'r2_greedy_val_sem': np.float64(0.03920682672796574), 'mse_refit_ground_truth_assignment_val': np.float64(1.6316438634760155), 'r2_refit_ground_truth_assignment_val': 0.986033221700307, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.08333333333333333), 'mse_ground_truth_val': np.float64(1.1603458811183287), 'r2_ground_truth_val': 0.9900675055167883, 'label_mismatch_ground_truth_val': np.float64(0.08333333333333333), 'mse_baseline_sklearn_val': np.float64(116.96915633298488), 'r2_baseline_sklearn_val': -0.0012492989276287059}
