==================== Evaluating with noise_std = 0.9 in Dataset 1 with random state = 6 ====================
ODS is enabled
mse 0.8002855248618094
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 312 columns and 216 nonzeros
Model fingerprint: 0x135bf009
Model has 84 quadratic objective terms
Model has 216 general constraints
Variable types: 96 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e-02, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [2e-01, 2e+01]
  GenCon coe range [6e-03, 4e+00]
Presolve added 216 rows and 204 columns
Presolve time: 0.02s
Presolved: 288 rows, 516 columns, 1512 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 84 quadratic objective terms
Variable types: 300 continuous, 216 integer (216 binary)

Root relaxation: objective 0.000000e+00, 577 iterations, 0.01 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   72          -    0.00000      -     -    0s
H    0     0                    7606.8763970    0.00000   100%     -    0s
H    0     0                    6691.6764016    0.00000   100%     -    0s
     0     0    0.36954    0   71 6691.67640    0.36954   100%     -    0s
     0     2    0.36954    0   71 6691.67640    0.36954   100%     -    0s
H   35    48                    6325.8942744    0.36954   100%   2.5    0s
H   38    48                    6079.8840719    0.36954   100%   2.5    0s
H   42    48                    6015.7823163    0.36954   100%   2.6    0s
H   79    96                    5791.1562131    0.36954   100%   2.4    0s
H  357   417                    5317.3298674    0.36954   100%   2.5    0s
H  372   417                    5056.3243780    0.36954   100%   2.5    0s
H  412   417                    5048.2872826    0.36954   100%   2.5    0s
H 1104  1251                    4545.1590161    0.36954   100%   2.5    0s
H 1105  1251                    2800.0147120    0.36954   100%   2.5    0s
H 1134  1251                    2263.7630291    0.36954   100%   2.5    0s
H 2178  2341                    1479.9140411    0.37440   100%   2.4    0s
H 2190  2339                    1403.7904495    0.37440   100%   2.4    0s
H 2264  2335                    1325.9073897    0.37440   100%   2.4    0s
H 2856  3313                     980.3027201    0.37440   100%   2.3    0s
H 3180  3305                     925.2331262    0.37440   100%   2.3    0s
H 3360  3223                     731.4390627    0.37440   100%   2.3    0s
H 3440  3309                     720.3617675    0.37440   100%   2.3    0s
H 3779  3099                     547.3251107    0.37440   100%   2.3    0s
H 3782  2923                     450.7320358    0.37440   100%   2.3    0s
* 5273  3919             137     439.7179920    0.37440   100%   2.2    0s
H 5577  3710                     377.7234187    0.37440   100%   2.2    0s
H 5615  3547                     355.7191576    0.37440   100%   2.3    0s
H 5661  3399                     346.6989515    0.37440   100%   2.3    0s
H 5876  3370                     325.6182789    0.37440   100%   2.3    0s
H 6680  3638                     315.4628700    0.37440   100%   2.3    0s
H 7966  4268                     314.5517423    0.37440   100%   2.3    0s
H 7978  3969                     224.4566771    0.37440   100%   2.3    0s
H 8480  4072                     216.7508255    0.37809   100%   2.3    1s
H 8742  3850                     216.2125084    0.37809   100%   2.3    1s
H22383 11049                     214.7785997    0.65082   100%   2.2    1s
H22390 11035                     214.1180670    0.65082   100%   2.2    1s
H28473 15009                     213.5665603    0.71076   100%   2.2    1s
 129376 68819   85.91860  106   44  213.56656    1.62274  99.2%   2.0    5s
H135029 63868                     155.3248255    1.65421  98.9%   2.0    5s
H137121 48262                      64.1422272    1.65884  97.4%   2.0    5s
H139805 48747                      62.3233961    1.67084  97.3%   2.0    5s
H141909 48681                      58.9586540    1.68773  97.1%   2.0    5s
H143667 48662                      56.8104449    1.70456  97.0%   2.0    5s
 367800 144324     cutoff   73        56.81044    2.70837  95.2%   2.0   10s
 581253 219367    5.67754   75   61   56.81044    3.62976  93.6%   2.0   15s
 858762 309569   22.11063   73   67   56.81044    4.59643  91.9%   1.9   20s
 1094045 376506     cutoff   94        56.81044    5.25531  90.7%   1.9   25s
 1310645 433230   14.52287   83   61   56.81044    5.85950  89.7%   1.9   30s
 1575887 501477   54.53200   84   59   56.81044    6.52637  88.5%   1.9   35s
 1856690 567206   13.97055   92   57   56.81044    7.24073  87.3%   1.8   40s
 2139495 630630     cutoff   83        56.81044    7.90448  86.1%   1.8   45s
 2422445 691174   49.88924   91   61   56.81044    8.54487  85.0%   1.8   50s
 2691711 746157   25.02659   83   56   56.81044    9.10956  84.0%   1.8   55s
 2956457 798326   36.10720   77   67   56.81044    9.67614  83.0%   1.8   60s
 3211482 845548   37.85061   70   67   56.81044   10.17889  82.1%   1.8   65s
 3452810 888023   19.75082   81   59   56.81044   10.63785  81.3%   1.8   70s
 3707627 929783   22.29793   97   51   56.81044   11.10712  80.4%   1.8   75s
 3955804 968362     cutoff   92        56.81044   11.56850  79.6%   1.8   80s
 4203355 1005952   49.70204   96   53   56.81044   12.02789  78.8%   1.8   85s
 4444514 1041786   39.79908   88   55   56.81044   12.46753  78.1%   1.8   90s
 4675641 1073990   53.61840   95   53   56.81044   12.87301  77.3%   1.8   95s
 4915145 1103414     cutoff   92        56.81044   13.32337  76.5%   1.8  100s
 5154862 1130258     cutoff   91        56.81044   13.77358  75.8%   1.8  105s
 5407451 1157463   32.82290   87   53   56.81044   14.25866  74.9%   1.7  110s
 5659075 1185128     cutoff   98        56.81044   14.72049  74.1%   1.7  115s
 5892650 1208732   31.14869   85   60   56.81044   15.16429  73.3%   1.7  120s
 6135072 1230989     cutoff   94        56.81044   15.65530  72.4%   1.7  125s
 6378618 1252902   28.54873   99   51   56.81044   16.16601  71.5%   1.7  130s
 6624999 1274995     cutoff   93        56.81044   16.69725  70.6%   1.7  135s
 6855784 1295262     cutoff  102        56.81044   17.19779  69.7%   1.7  140s
 7099144 1314113     cutoff  103        56.81044   17.74477  68.8%   1.7  145s
 7348257 1333302     cutoff   94        56.81044   18.30253  67.8%   1.7  150s
 7585313 1350611   28.38795   86   61   56.81044   18.86003  66.8%   1.7  155s
 7823224 1369028   36.78953   97   50   56.81044   19.39435  65.9%   1.7  160s
 8067620 1384360     cutoff  103        56.81044   19.95311  64.9%   1.7  165s
 8321258 1401399     cutoff   99        56.81044   20.49822  63.9%   1.7  170s
 8566988 1418674   45.70397   95   51   56.81044   21.01326  63.0%   1.7  175s
 8810293 1433700   33.84326  103   50   56.81044   21.51634  62.1%   1.7  180s
 9053568 1446309     cutoff   94        56.81044   22.01558  61.2%   1.7  185s
 9291430 1461251   41.25314   98   50   56.81044   22.47906  60.4%   1.7  190s
 9537108 1472836     cutoff   82        56.81044   22.97444  59.6%   1.7  195s
 9789344 1486450   27.80546   88   60   56.81044   23.46064  58.7%   1.7  200s
 10041456 1498435   42.23005   95   51   56.81044   23.93675  57.9%   1.7  205s
 10278543 1507395   25.55740   87   56   56.81044   24.39592  57.1%   1.7  210s
 10523654 1515982   46.50717   89   55   56.81044   24.85014  56.3%   1.7  215s
 10759767 1524604     cutoff  105        56.81044   25.28495  55.5%   1.7  220s
 10994986 1532030     cutoff   80        56.81044   25.71100  54.7%   1.7  225s
 11235825 1540255   31.30050   98   51   56.81044   26.14983  54.0%   1.7  230s
 11484234 1545175   43.40198   97   44   56.81044   26.61334  53.2%   1.7  235s
 11728363 1549798   48.65102   91   54   56.81044   27.06824  52.4%   1.7  240s
 11981784 1551836     cutoff   83        56.81044   27.56104  51.5%   1.7  245s
 12210117 1555096   56.71008   77   57   56.81044   27.99725  50.7%   1.7  250s
 12454843 1556670   42.93197   85   62   56.81044   28.46672  49.9%   1.7  255s
 12695131 1557102     cutoff   94        56.81044   28.94218  49.1%   1.7  260s
 12936333 1558803   30.54644   94   49   56.81044   29.40795  48.2%   1.7  265s
 13174313 1558977   40.43496   87   57   56.81044   29.85482  47.4%   1.7  270s
 13417974 1559057   40.96850   90   54   56.81044   30.31193  46.6%   1.7  275s
 13655948 1557171     cutoff   98        56.81044   30.76496  45.8%   1.7  280s
 13901415 1557068     cutoff  100        56.81044   31.22096  45.0%   1.7  285s
 14139792 1555153     cutoff   94        56.81044   31.66043  44.3%   1.7  290s
 14380733 1554638   39.61888   89   50   56.81044   32.09036  43.5%   1.7  295s
 14626516 1552447     cutoff   97        56.81044   32.52404  42.7%   1.6  300s
 14881717 1550235   48.45401  101   44   56.81044   32.96705  42.0%   1.6  305s
 15129400 1547257     cutoff   98        56.81044   33.39578  41.2%   1.6  310s
 15363867 1543398   47.99192   88   60   56.81044   33.80557  40.5%   1.6  315s
 15612846 1535695     cutoff   93        56.81044   34.24095  39.7%   1.6  320s
 15862125 1528283   48.55107   85   63   56.81044   34.66977  39.0%   1.6  325s
 16103861 1521342     cutoff   96        56.81044   35.08464  38.2%   1.6  330s
 16349384 1513843     cutoff   92        56.81044   35.51494  37.5%   1.6  335s
 16592555 1503390     cutoff   97        56.81044   35.94182  36.7%   1.6  340s
 16834012 1492360   37.06547   99   48   56.81044   36.36497  36.0%   1.6  345s
 17085304 1477695     cutoff   80        56.81044   36.80908  35.2%   1.6  350s
 17322431 1463673     cutoff  100        56.81044   37.22633  34.5%   1.6  355s
 17569476 1448347   43.00566   82   60   56.81044   37.65433  33.7%   1.6  360s
 17811290 1430811   47.24676   79   55   56.81044   38.08585  33.0%   1.6  365s
 18055729 1413093     cutoff   78        56.81044   38.52073  32.2%   1.6  370s
 18311645 1393541   45.43173   92   58   56.81044   38.97134  31.4%   1.6  375s
 18546405 1374904   41.06856   94   55   56.81044   39.38558  30.7%   1.6  380s
 18789851 1353622     cutoff   97        56.81044   39.81988  29.9%   1.6  385s
 19035311 1332941   41.83519   75   61   56.81044   40.25533  29.1%   1.6  390s
 19282777 1309080   49.97856   74   63   56.81044   40.70941  28.3%   1.6  395s
 19522121 1285134   45.21216   69   67   56.81044   41.14340  27.6%   1.6  400s
 19769883 1258859   53.52132  103   47   56.81044   41.59395  26.8%   1.6  405s
 20016063 1231678   44.69065  100   50   56.81044   42.05288  26.0%   1.6  410s
 20254367 1204102   52.58932  100   50   56.81044   42.50152  25.2%   1.6  415s
 20500746 1170507   43.93076   82   62   56.81044   42.98236  24.3%   1.6  420s
 20744438 1136610     cutoff  109        56.81044   43.45920  23.5%   1.6  425s
 20986931 1100552   47.05134   91   55   56.81044   43.95298  22.6%   1.6  430s
 21232777 1063762     cutoff   93        56.81044   44.44801  21.8%   1.6  435s
 21476403 1026872     cutoff   98        56.81044   44.95235  20.9%   1.6  440s
 21710410 986666   46.29943  104   48   56.81044   45.44768  20.0%   1.6  445s
 21949559 943390   52.43951   84   58   56.81044   45.97135  19.1%   1.6  450s
 22192672 898017   53.45574   89   56   56.81044   46.50954  18.1%   1.6  455s
 22438274 848954   52.13114   93   55   56.81044   47.07626  17.1%   1.6  460s
 22682444 798887     cutoff   96        56.81044   47.65006  16.1%   1.6  465s
 22922438 745977     cutoff   91        56.81044   48.21913  15.1%   1.6  470s
 23174655 687267     cutoff   91        56.81044   48.86268  14.0%   1.6  475s
 23427266 622713     cutoff   82        56.81044   49.54461  12.8%   1.6  480s
 23675148 556043     cutoff   95        56.81044   50.24788  11.6%   1.6  485s
 23927435 482075     cutoff   91        56.81044   51.01743  10.2%   1.6  490s
 24176565 401247     cutoff   82        56.81044   51.83647  8.76%   1.6  495s
 24424211 313548   54.51721   91   52   56.81044   52.73308  7.18%   1.6  500s
 24672060 220454     cutoff  106        56.81044   53.73775  5.41%   1.6  505s

Explored 24723827 nodes (39015708 simplex iterations) in 506.03 seconds (431.45 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 56.8104 58.9587 62.3234 ... 314.552

Optimal solution found (tolerance 5.00e-02)
Best objective 5.681044494812e+01, best bound 5.397762695453e+01, gap 4.9864%
Optimal solution found.
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Cluster Assignments from Gurobi MIQP using MSE

Cluster 0 weights w_0^* (including bias) in original space:
[-10.14301341  -1.25737411  -1.58989108  -1.09662847]

Cluster 1 weights w_1^* (including bias) in original space:
[9.91134226 0.17594794 0.17465246 0.07325519]

Cluster 2 weights w_2^* (including bias) in original space:
[1.01207928 1.46742855 1.77460172 0.9470497 ]
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 5.97950641e-01  2.92772880e-04  1.03506395e-03 -1.05233657e-03]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
105.65015709775506
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
-----------------------------------
Regression weights for cluster 0: y = -1.2574x_0 + -1.5899x_1 + -1.0966x_2 + -10.143
Regression weights for cluster 0 after refit: y = -1.2534x_1 + -1.5884x_2 + -1.092x_3 + -10.1572
-----------------------------------
Regression weights for cluster 1: y = 0.1759x_0 + 0.1747x_1 + 0.0733x_2 + 9.9113
Regression weights for cluster 1 after refit: y = 0.1681x_1 + 0.1669x_2 + 0.0713x_3 + 9.9314
-----------------------------------
Regression weights for cluster 2: y = 1.4674x_0 + 1.7746x_1 + 0.947x_2 + 1.0121
Regression weights for cluster 2 after refit: y = 1.4676x_1 + 1.7754x_2 + 0.9469x_3 + 1.012
{'time_milp': 507.0591380596161, 'time_greedy': np.float64(0.4730446934700012), 'time_refit_milp_assignment': 509.78444743156433, 'mse_refit_ground_truth_assignment': np.float64(0.804291580740748), 'r2_refit_ground_truth_assignment': 0.9927460390376596, 'weight_mismatch_refit_ground_truth_assignment': np.float64(0.7357436262847247), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(0.7593509913935546), 'r2_milp': 0.993151361297093, 'weight_mismatch_milp': np.float64(0.598808379653585), 'refit-weight_mismatch_milp': np.float64(0.20230948300260526), 'rand_score_milp': np.float64(0.9816118935837246), 'label_mismatch_milp': np.float64(0.013888888888888888), 'mse_refit_milp_assignment': np.float64(0.7593052347257943), 'r2_refit_milp_assignment': 0.9931517739796196, 'weight_mismatch_refit_milp_assignment': np.float64(0.5920039227572618), 'refit-weight_mismatch_refit_milp_assignment': np.float64(0.20592040093595565), 'rand_score_refit_milp_assignment': np.float64(0.9816118935837246), 'label_mismatch_refit_milp_assignment': np.float64(0.013888888888888888), 'mse_greedy': np.float64(6.078926733784078), 'r2_greedy': np.float64(0.9451737426131144), 'weight_mismatch_greedy': np.float64(11.002472471360743), 'refit-weight_mismatch_greedy': np.float64(10.77455689031281), 'rand_score_greedy': np.float64(0.8182902973395931), 'label_mismatch_greedy': np.float64(0.22638888888888892), 'mse_greedy_sem': np.float64(1.666965441401284), 'r2_greedy_sem': np.float64(0.015034475713843393), 'weight_mismatch_greedy_sem': np.float64(2.7902262158461353), 'refit-weight_mismatch_greedy_sem': np.float64(2.821816877877115), 'rand_score_greedy_sem': np.float64(0.03656434892895884), 'label_mismatch_greedy_sem': np.float64(0.047229746562562375), 'mse_ground_truth': np.float64(0.8002855248618094), 'r2_ground_truth': np.float64(0.9928060796475773), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(105.65015709775506), 'r2_baseline_sklearn': np.float64(0.04713398274489633), 'mse_milp_val': np.float64(0.7579469450497195), 'r2_milp_val': 0.993216547734431, 'label_mismatch_milp_val': np.float64(0.0), 'mse_refit_milp_assignment_val': np.float64(0.7581684800006118), 'r2_refit_milp_assignment_val': 0.9932145650471541, 'label_mismatch_refit_milp_assignment_val': np.float64(0.0), 'mse_greedy_val': np.float64(14.101719887991266), 'label_mismatch_greedy_val': np.float64(0.2354166666666667), 'mse_greedy_val_sem': np.float64(4.541623015665052), 'label_mismatch_greedy_val_sem': np.float64(0.051567622242475845), 'r2_greedy_val': np.float64(0.8737928236964683), 'r2_greedy_val_sem': np.float64(0.040646490016464545), 'mse_refit_ground_truth_assignment_val': np.float64(1.0543862918136018), 'r2_refit_ground_truth_assignment_val': 0.9905634832006366, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.020833333333333332), 'mse_ground_truth_val': np.float64(0.9910157426450676), 'r2_ground_truth_val': 0.9911306351604607, 'label_mismatch_ground_truth_val': np.float64(0.020833333333333332), 'mse_baseline_sklearn_val': np.float64(111.8431886210077), 'r2_baseline_sklearn_val': -0.0009710259995352466}
