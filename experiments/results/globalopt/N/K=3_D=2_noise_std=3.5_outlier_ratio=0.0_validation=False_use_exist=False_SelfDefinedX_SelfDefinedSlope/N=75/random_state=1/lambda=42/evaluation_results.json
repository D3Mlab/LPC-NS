{"time_milp": 3038.3453829288483, "time_refit_milp_assignment": 3039.1463136672974, "mse_refit_ground_truth_assignment": 10.15877679161422, "r2_refit_ground_truth_assignment": 0.9083842469734694, "weight_mismatch_refit_ground_truth_assignment": 2.512213880612685, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.649781391377582, "r2_milp": 0.9400297159658272, "weight_mismatch_milp": 4.809946538725336, "refit-weight_mismatch_milp": 2.910058480087661, "rand_score_milp": 0.8266666666666667, "label_mismatch_milp": 0.14666666666666667, "mse_refit_milp_assignment": 6.649756730270228, "r2_refit_milp_assignment": 0.9400299383691704, "weight_mismatch_refit_milp_assignment": 4.81524366470818, "refit-weight_mismatch_refit_milp_assignment": 2.924858029323335, "rand_score_refit_milp_assignment": 0.8266666666666667, "label_mismatch_refit_milp_assignment": 0.14666666666666667, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": 11.2570486209453, "r2_ground_truth": 0.8984796095613107, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.53250492201481, "r2_baseline_sklearn": 0.012157260643503198, "random_state": 42}