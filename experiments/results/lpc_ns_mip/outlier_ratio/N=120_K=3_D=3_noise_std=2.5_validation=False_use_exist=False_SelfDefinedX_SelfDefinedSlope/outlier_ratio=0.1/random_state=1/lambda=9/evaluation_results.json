{"time_milp": 18035.330711364746, "time_refit_milp_assignment": 18038.461898565292, "mse_refit_ground_truth_assignment": 77.02734529991224, "r2_refit_ground_truth_assignment": 0.7031506364212111, "weight_mismatch_refit_ground_truth_assignment": 4.886895808252226, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 64.48663392559317, "r2_milp": 0.7514802546340322, "weight_mismatch_milp": 8.118240540247289, "refit-weight_mismatch_milp": 5.595114841249607, "rand_score_milp": 0.7563025210084033, "label_mismatch_milp": 0.24166666666666667, "mse_refit_milp_assignment": 64.4866277737603, "r2_refit_milp_assignment": 0.751480278342076, "weight_mismatch_refit_milp_assignment": 8.128064937294695, "refit-weight_mismatch_refit_milp_assignment": 5.603418687760578, "rand_score_refit_milp_assignment": 0.7563025210084033, "label_mismatch_refit_milp_assignment": 0.24166666666666667, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": 84.13053288838786, "r2_ground_truth": 0.6757762448098967, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 255.05166196284006, "r2_baseline_sklearn": 0.017090934204728514, "random_state": 9}