{"time_milp": 18045.352198123932, "time_refit_milp_assignment": 18048.51954817772, "mse_refit_ground_truth_assignment": 193.46427193641466, "r2_refit_ground_truth_assignment": 0.6099461413566909, "weight_mismatch_refit_ground_truth_assignment": 19.094080099176672, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 103.77429502629431, "r2_milp": 0.7907749901423716, "weight_mismatch_milp": 33.341453925170896, "refit-weight_mismatch_milp": 33.275497746573976, "rand_score_milp": 0.6369747899159663, "label_mismatch_milp": 0.44166666666666665, "mse_refit_milp_assignment": 103.77426713049213, "r2_refit_milp_assignment": 0.7907750463846182, "weight_mismatch_refit_milp_assignment": 33.35784464514012, "refit-weight_mismatch_refit_milp_assignment": 33.28729333319063, "rand_score_refit_milp_assignment": 0.6369747899159663, "label_mismatch_refit_milp_assignment": 0.44166666666666665, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": 251.07039099362797, "r2_ground_truth": 0.4938033063265781, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 482.72355622739974, "r2_baseline_sklearn": 0.02676607305242762, "random_state": 5}