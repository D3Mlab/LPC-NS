{"time_milp": 18055.90518283844, "time_refit_milp_assignment": 18058.766989707947, "mse_refit_ground_truth_assignment": 238.09468177138314, "r2_refit_ground_truth_assignment": 0.5857778577332018, "weight_mismatch_refit_ground_truth_assignment": 16.528112191549983, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 137.54895593164454, "r2_milp": 0.760700983454662, "weight_mismatch_milp": 30.99284853064115, "refit-weight_mismatch_milp": 19.8301278980794, "rand_score_milp": 0.6780112044817928, "label_mismatch_milp": 0.3416666666666667, "mse_refit_milp_assignment": 137.54881575841875, "r2_refit_milp_assignment": 0.760701227319218, "weight_mismatch_refit_milp_assignment": 31.020978764608813, "refit-weight_mismatch_refit_milp_assignment": 19.855754585638245, "rand_score_refit_milp_assignment": 0.6780112044817928, "label_mismatch_refit_milp_assignment": 0.3416666666666667, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": 291.1043216334688, "r2_ground_truth": 0.4935550225942452, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 541.3122045135372, "r2_baseline_sklearn": 0.05823614553044343, "random_state": 42}