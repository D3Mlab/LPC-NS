==================== Evaluating with noise_std = 2 in Dataset 1 with random state = 7 ====================
ODS is enabled
mse 3.9841394483722326
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
using MSE:
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 288 columns and 216 nonzeros
Model fingerprint: 0x97b61be4
Model has 72 quadratic objective terms
Model has 216 general constraints
Variable types: 72 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e+00, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [2e-01, 2e+01]
  GenCon coe range [5e-06, 1e+01]
Presolve added 216 rows and 216 columns
Presolve time: 0.01s
Presolved: 288 rows, 504 columns, 16200 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 72 quadratic objective terms
Variable types: 288 continuous, 216 integer (216 binary)
Found heuristic solution: objective 9261.2357666
Found heuristic solution: objective 8535.5899039

Root relaxation: objective 0.000000e+00, 673 iterations, 0.01 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   83 8535.58990    0.00000   100%     -    0s
H    0     0                    7997.9605276    0.00000   100%     -    0s
H    0     0                    7629.1551150    0.00000   100%     -    0s
H    0     0                    4998.6248755    0.00000   100%     -    0s
     0     0    0.00000    0   79 4998.62488    0.00000   100%     -    0s
H    0     0                    4647.1416762    0.00000   100%     -    0s
     0     2    0.00000    0   79 4647.14168    0.00000   100%     -    0s
H   35    48                    4623.5385033    0.00000   100%  45.9    0s
H   36    48                    4293.7979698    0.00000   100%  44.7    0s
H   40    48                    4291.9420715    0.00000   100%  45.1    0s
H   41    48                    4186.5579283    0.00000   100%  44.5    0s
H   88    96                    4165.2568995    0.00000   100%  38.6    0s
H   89    96                    3988.0784875    0.00000   100%  39.0    0s
H  146   159                    3777.1231872    0.00000   100%  39.1    0s
H  217   231                    3523.9902817    0.00000   100%  39.7    0s
H  915   931                    3158.3950536    0.00000   100%  29.7    1s
H  920   931                    2409.6274586    0.00000   100%  29.7    1s
H  930   947                    1947.9338520    0.00000   100%  29.6    1s
H 2106  1995                    1825.7870733    0.00000   100%  21.6    1s
H 4081  3221                    1765.5159689    0.00000   100%  25.2    2s
H 4088  3090                    1603.8401085    0.00000   100%  25.2    2s
H 4100  2975                    1553.0067483    0.00000   100%  25.2    4s
H 4104  2829                    1267.1857719    0.00000   100%  25.2    4s
  6461  3662     cutoff   34      1267.18577    0.00000   100%  27.1    5s
H 9561  4311                    1124.7106203    5.71158  99.5%  27.0    5s
H 9739  3220                     802.8268091    5.71158  99.3%  26.8    5s
*11098  3178             123     687.5322548   28.92558  95.8%  26.2    5s
*16407  5438             115     640.7823512   48.26636  92.5%  23.3    6s
*25381  9275             114     626.6144814   60.73351  90.3%  21.2    8s
*27117  9398             114     608.8788530   63.84300  89.5%  21.1    8s
*40463 13961             121     574.7064352   80.72500  86.0%  19.7    9s
 43431 15243  475.75937   60   55  574.70644   84.47537  85.3%  19.5   10s
H44685 14758                     561.5078775   86.34765  84.6%  19.4   10s
*44705 14326             120     551.2665643   86.34765  84.3%  19.4   10s
*77783 25546             119     537.4930849  114.82814  78.6%  17.5   12s
H90005 24851                     480.1341806  122.62460  74.5%  17.0   13s
 105965 29436     cutoff   32       480.13418  131.94081  72.5%  16.4   15s
*168607 38762             118     416.2275079  159.11584  61.8%  14.9   19s
 173192 40001  399.99849   38   61  416.22751  161.47936  61.2%  14.8   20s
H207007 45581                     400.8115984  174.70035  56.4%  14.2   22s
H207533 45079                     398.3068331  174.79211  56.1%  14.2   24s
 209324 45902     cutoff   36       398.30683  175.37308  56.0%  14.1   25s
 281409 64973     cutoff   77       398.30683  195.48634  50.9%  13.1   30s
 341583 80171  353.87903   29   73  398.30683  206.81826  48.1%  12.3   36s
H341762 77846                     389.7984108  206.91170  46.9%  12.3   36s
 389893 89917  372.81869   67   49  389.79841  213.61719  45.2%  11.8   40s
H411882 93334                     384.6340757  216.16759  43.8%  11.6   41s
 450936 103263  357.06337   53   59  384.63408  220.45763  42.7%  11.3   45s
 491879 112763  321.17149   77   46  384.63408  224.55476  41.6%  11.1   50s
 565949 130124     cutoff   68       384.63408  230.56211  40.1%  10.6   55s
 634197 145749  363.86238   73   51  384.63408  235.07282  38.9%  10.3   60s
 643857 147790     cutoff   62       384.63408  235.63710  38.7%  10.2   65s
 704162 161635     cutoff   63       384.63408  239.09201  37.8%  10.0   70s
 773806 177350  358.85453   87   31  384.63408  242.77956  36.9%   9.7   75s
 831420 190597  322.10686   57   63  384.63408  245.52413  36.2%   9.6   80s
 877042 201597     cutoff   62       384.63408  247.44762  35.7%   9.4   85s
 952689 218634  297.77612   37   70  384.63408  250.48639  34.9%   9.2   90s
 1010135 230938  317.93458   95   27  384.63408  252.64088  34.3%   9.1   95s
 1074879 245248     cutoff   55       384.63408  254.86285  33.7%   9.0  102s
 1114111 253501     cutoff   85       384.63408  256.13306  33.4%   8.9  105s
 1186633 268699  360.75922   82   42  384.63408  258.34488  32.8%   8.8  110s
 1252249 282751     cutoff   70       384.63408  260.18340  32.4%   8.7  116s
 1300037 292473     cutoff   67       384.63408  261.53883  32.0%   8.6  120s
 1374697 307416  351.28397   55   50  384.63408  263.52728  31.5%   8.5  125s
 1444147 321269     cutoff   60       384.63408  265.25683  31.0%   8.4  130s
 1484107 328915     cutoff   73       384.63408  266.23991  30.8%   8.4  135s
 1557873 343135     cutoff   69       384.63408  267.91496  30.3%   8.3  140s
 1616769 354218  343.14323   96   25  384.63408  269.27434  30.0%   8.2  145s
 1667431 363693  314.94441   64   52  384.63408  270.34384  29.7%   8.2  150s
 1744139 377958  313.11509   74   53  384.63408  271.93070  29.3%   8.1  155s
 1819089 392070     cutoff   90       384.63408  273.34537  28.9%   8.0  160s
 1873952 402476  315.52187   59   52  384.63408  274.32374  28.7%   8.0  165s
 1928798 412459     cutoff   76       384.63408  275.27378  28.4%   7.9  170s
 2001382 425260     cutoff   81       384.63408  276.50097  28.1%   7.9  175s
 2036140 431315  374.13405   86   33  384.63408  277.07902  28.0%   7.9  180s
 2106624 443389     cutoff   72       384.63408  278.21780  27.7%   7.8  185s
 2151474 451376     cutoff   90       384.63408  278.89011  27.5%   7.8  191s
 2204113 459137     cutoff   62       384.63408  279.82034  27.3%   7.8  195s
 2275763 468758     cutoff   81       384.63408  281.03280  26.9%   7.7  201s
 2322549 474567     cutoff   79       384.63408  281.88135  26.7%   7.7  205s
 2395703 483459  350.46777   75   45  384.63408  283.12694  26.4%   7.7  210s
 2429699 486772  317.05427   78   49  384.63408  283.75717  26.2%   7.6  215s
 2506807 494563  357.66995   92   23  384.63408  285.14181  25.9%   7.6  220s
 2556894 499275  322.90515   83   43  384.63408  286.01761  25.6%   7.6  225s
 2632197 505893     cutoff   78       384.63408  287.31582  25.3%   7.5  230s
 2675955 509231  359.21763   76   45  384.63408  288.05521  25.1%   7.5  235s
 2740076 514440  335.93886   42   61  384.63408  289.18727  24.8%   7.5  242s
 2773267 517275     cutoff   63       384.63408  289.73718  24.7%   7.5  245s
 2849620 523384     cutoff   62       384.63408  291.00795  24.3%   7.5  250s
 2904202 527515  372.91491   67   43  384.63408  291.87270  24.1%   7.4  255s
 2960554 531186  380.09090   63   43  384.63408  292.78726  23.9%   7.4  260s
 3034003 535973  358.54904   66   48  384.63408  293.94211  23.6%   7.4  266s
 3087714 538968     cutoff   95       384.63408  294.78697  23.4%   7.4  270s
 3122239 540939     cutoff   64       384.63408  295.31441  23.2%   7.4  275s
 3198259 545147  352.81553   78   52  384.63408  296.48226  22.9%   7.3  280s
 3256843 548132     cutoff   34       384.63408  297.39140  22.7%   7.3  285s
 3322416 551315     cutoff   83       384.63408  298.38713  22.4%   7.3  291s
 3366312 553145     cutoff   84       384.63408  299.07472  22.2%   7.3  295s
 3441124 556850  348.16502   76   48  384.63408  300.14546  22.0%   7.3  300s
 3509645 559628     cutoff   88       384.63408  301.12811  21.7%   7.3  308s
 3531143 560221     cutoff   90       384.63408  301.46839  21.6%   7.2  310s
 3606732 562551     cutoff   77       384.63408  302.56898  21.3%   7.2  315s
 3681514 564950  326.36858   66   50  384.63408  303.65365  21.1%   7.2  320s
 3720727 565895     cutoff   55       384.63408  304.22727  20.9%   7.2  325s
 3786146 567279     cutoff   89       384.63408  305.15839  20.7%   7.2  330s
 3834488 568075     cutoff   59       384.63408  305.86649  20.5%   7.2  335s
 3909120 568869  330.79056   81   41  384.63408  306.91296  20.2%   7.2  340s
 3980390 569570  326.21965   72   46  384.63408  307.93022  19.9%   7.1  345s
 4002320 569722     cutoff   69       384.63408  308.23983  19.9%   7.1  350s
 4077839 569381     cutoff   72       384.63408  309.34038  19.6%   7.1  355s
 4151184 568997     cutoff   88       384.63408  310.38639  19.3%   7.1  360s
 4223598 568129  342.78076   83   43  384.63408  311.39488  19.0%   7.1  365s
 4266879 567702  341.20673   58   52  384.63408  311.97517  18.9%   7.1  371s
 4322598 566894  362.33974   75   39  384.63408  312.73420  18.7%   7.1  375s
 4394311 565357     cutoff   83       384.63408  313.71253  18.4%   7.1  380s
 4469008 563591  349.02367   67   48  384.63408  314.72573  18.2%   7.1  385s
 4528050 561860  363.90284   51   68  384.63408  315.51135  18.0%   7.0  390s
 4579572 559823  362.65519   78   41  384.63408  316.23061  17.8%   7.0  395s
 4648559 557043     cutoff   82       384.63408  317.17269  17.5%   7.0  400s
H4688140 551259                     382.2965999  317.69792  16.9%   7.0  402s
 4694679 550808     cutoff   90       382.29660  317.80006  16.9%   7.0  405s
 4768819 546091  331.84285   84   39  382.29660  318.88974  16.6%   7.0  410s
 4817465 542743     cutoff   57       382.29660  319.58151  16.4%   7.0  416s
 4870280 538869     cutoff   58       382.29660  320.33209  16.2%   7.0  420s
 4926457 534377  328.80533   70   45  382.29660  321.15275  16.0%   7.0  425s
 4992994 528459  366.14558   87   38  382.29660  322.13099  15.7%   7.0  430s
 5018611 526053     cutoff   83       382.29660  322.51825  15.6%   7.0  435s
 5093106 518502     cutoff   75       382.29660  323.61998  15.3%   7.0  440s
 5140449 513335     cutoff   80       382.29660  324.32564  15.2%   7.0  445s
 5213388 505445  365.57133   79   41  382.29660  325.36996  14.9%   6.9  450s
 5285798 496538  381.30715   77   28  382.29660  326.43869  14.6%   6.9  455s
 5327401 491359     cutoff   77       382.29660  327.04046  14.5%   6.9  460s
 5397072 482070  357.94337   71   44  382.29660  328.06824  14.2%   6.9  465s
 5446090 475397     cutoff   46       382.29660  328.79936  14.0%   6.9  470s
 5519982 464427     cutoff   66       382.29660  329.91611  13.7%   6.9  475s
 5569081 456709  340.33252   61   53  382.29660  330.68813  13.5%   6.9  480s
 5637285 445858     cutoff   69       382.29660  331.71473  13.2%   6.9  485s
 5711503 432708     cutoff   71       382.29660  332.95096  12.9%   6.9  490s
 5763408 422992     cutoff   75       382.29660  333.78162  12.7%   6.9  495s
 5820806 411734  354.75888   50   56  382.29660  334.72697  12.4%   6.9  501s
 5865981 402377     cutoff   71       382.29660  335.48972  12.2%   6.9  505s
 5939699 386253     cutoff   62       382.29660  336.78869  11.9%   6.9  510s
 5999580 372643     cutoff   91       382.29660  337.86434  11.6%   6.9  516s
 6047867 361075  353.80601   73   41  382.29660  338.74485  11.4%   6.8  520s
 6119634 343066     cutoff   76       382.29660  340.11923  11.0%   6.8  525s
 6168798 329831     cutoff   71       382.29660  341.06847  10.8%   6.8  530s
 6241706 309482     cutoff   91       382.29660  342.56915  10.4%   6.8  535s
 6295665 293744     cutoff   74       382.29660  343.70735  10.1%   6.8  540s
 6355533 274464  371.82510   86   33  382.29660  345.07219  9.74%   6.8  545s
 6407919 257113  346.78998   78   40  382.29660  346.32943  9.41%   6.8  550s
 6470033 234819     cutoff   86       382.29660  347.93465  8.99%   6.8  555s
 6524256 214638     cutoff   80       382.29660  349.42260  8.60%   6.8  560s
 6585677 189727     cutoff   80       382.29660  351.30832  8.11%   6.8  565s
 6640853 166108  358.06806   85   36  382.29660  353.21156  7.61%   6.8  571s
 6693165 141664     cutoff   66       382.29660  355.27281  7.07%   6.7  575s
 6749475 113520  365.08162   86   28  382.29660  357.94993  6.37%   6.7  580s
 6818201 75401  365.82344   77   36  382.29660  362.31622  5.23%   6.7  585s

Explored 6830009 nodes (45825978 simplex iterations) in 585.80 seconds (597.08 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 382.297 384.634 389.798 ... 561.508

Optimal solution found (tolerance 5.00e-02)
Best objective 3.822965999172e+02, best bound 3.632954105812e+02, gap 4.9703%

Gurobi MIQP converged to an optimal solution.
Cluster Assignments from Gurobi MIQP using MSE
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 3.65459419e-01 -6.82804340e-05 -7.56642652e-04  4.68291074e-04]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
122.00793004011209
Cluster assignments:  [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 1 1 2 1 1 2 2 1 1
 1 2 1 1 2 1 1 1 2 1 2 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 1 2 1]
-----------------------------------
Regression weights for cluster 0: y = -2.0212x_0 + -2.12x_1 + -0.8198x_2 + -9.4752
Regression weights for cluster 0 after refit: y = -2.0167x_1 + -2.117x_2 + -0.8146x_3 + -9.4928
-----------------------------------
Regression weights for cluster 1: y = 1.4066x_0 + -3.0497x_1 + 3.7033x_2 + 3.4193
Regression weights for cluster 1 after refit: y = 1.4063x_1 + -3.0525x_2 + 3.7036x_3 + 3.4234
-----------------------------------
Regression weights for cluster 2: y = -0.9915x_0 + 1.7908x_1 + -0.3232x_2 + 8.2008
Regression weights for cluster 2 after refit: y = -0.9963x_1 + 1.7846x_2 + -0.3267x_3 + 8.2192
{'time_milp': 586.6460573673248, 'time_greedy': np.float64(0.4890092134475708), 'time_refit_milp_assignment': 589.3638305664062, 'mse_refit_ground_truth_assignment': np.float64(2.7698180230582965), 'r2_refit_ground_truth_assignment': 0.9775782935986489, 'weight_mismatch_refit_ground_truth_assignment': np.float64(2.2082849994883453), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(4.599012942421114), 'r2_milp': 0.9627709412414311, 'weight_mismatch_milp': np.float64(9.60024593536538), 'refit-weight_mismatch_milp': np.float64(8.405511289020614), 'rand_score_milp': np.float64(0.7758215962441315), 'label_mismatch_milp': np.float64(0.25), 'mse_refit_milp_assignment': np.float64(4.5989689641882245), 'r2_refit_milp_assignment': 0.9627712972456949, 'weight_mismatch_refit_milp_assignment': np.float64(9.578618019052229), 'refit-weight_mismatch_refit_milp_assignment': np.float64(8.407308408486537), 'rand_score_refit_milp_assignment': np.float64(0.7758215962441315), 'label_mismatch_refit_milp_assignment': np.float64(0.25), 'mse_greedy': np.float64(7.5698735968928705), 'r2_greedy': np.float64(0.938721792597239), 'weight_mismatch_greedy': np.float64(15.679104227542624), 'refit-weight_mismatch_greedy': np.float64(15.202819936331474), 'rand_score_greedy': np.float64(0.7776212832550861), 'label_mismatch_greedy': np.float64(0.25625000000000003), 'mse_greedy_sem': np.float64(1.5888801715480398), 'r2_greedy_sem': np.float64(0.012862001913772937), 'weight_mismatch_greedy_sem': np.float64(2.6239088014343834), 'refit-weight_mismatch_greedy_sem': np.float64(2.6801725065068758), 'rand_score_greedy_sem': np.float64(0.023745148296521176), 'label_mismatch_greedy_sem': np.float64(0.03429525498221287), 'mse_ground_truth': np.float64(3.9841394483722326), 'r2_ground_truth': np.float64(0.9667520353708405), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(122.00793004011209), 'r2_baseline_sklearn': np.float64(0.012344506670716404), 'mse_milp_val': np.float64(12.956384754608989), 'r2_milp_val': 0.8861080628118579, 'label_mismatch_milp_val': np.float64(0.2916666666666667), 'mse_refit_milp_assignment_val': np.float64(12.961841386839433), 'r2_refit_milp_assignment_val': 0.8860600967760371, 'label_mismatch_refit_milp_assignment_val': np.float64(0.2916666666666667), 'mse_greedy_val': np.float64(19.432822458525266), 'label_mismatch_greedy_val': np.float64(0.2625), 'mse_greedy_val_sem': np.float64(4.4579918184868585), 'label_mismatch_greedy_val_sem': np.float64(0.03285011593524541), 'r2_greedy_val': np.float64(0.8291775185167023), 'r2_greedy_val_sem': np.float64(0.0391875769200001), 'mse_refit_ground_truth_assignment_val': np.float64(5.794194340283853), 'r2_refit_ground_truth_assignment_val': 0.9490666547529977, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.10416666666666667), 'mse_ground_truth_val': np.float64(5.593102784141138), 'r2_ground_truth_val': 0.9508343320267931, 'label_mismatch_ground_truth_val': np.float64(0.10416666666666667), 'mse_baseline_sklearn_val': np.float64(114.62882359380815), 'r2_baseline_sklearn_val': -0.0076343844337005695}
