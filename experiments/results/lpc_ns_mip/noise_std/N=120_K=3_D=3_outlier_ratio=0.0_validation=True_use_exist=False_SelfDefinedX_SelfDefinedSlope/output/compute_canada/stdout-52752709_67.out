==================== Evaluating with noise_std = 2 in Dataset 1 with random state = 6 ====================
ODS is enabled
mse 3.952027283268194
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
using MSE:
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 288 columns and 216 nonzeros
Model fingerprint: 0x01ca1da6
Model has 72 quadratic objective terms
Model has 216 general constraints
Variable types: 72 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e+00, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [2e-01, 2e+01]
  GenCon coe range [7e-05, 1e+01]
Presolve added 216 rows and 216 columns
Presolve time: 0.04s
Presolved: 288 rows, 504 columns, 16200 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 72 quadratic objective terms
Variable types: 288 continuous, 216 integer (216 binary)
Found heuristic solution: objective 9668.0780524
Found heuristic solution: objective 6511.1517003

Root relaxation: objective 0.000000e+00, 665 iterations, 0.02 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   82 6511.15170    0.00000   100%     -    0s
H    0     0                    4223.0502164    0.00000   100%     -    0s
     0     0    0.00000    0   81 4223.05022    0.00000   100%     -    0s
     0     2    0.00000    0   81 4223.05022    0.00000   100%     -    0s
H   33    48                    3257.3928934    0.00000   100%  44.3    0s
H   81    96                    3156.1417362    0.00000   100%  36.7    0s
H  155   160                    3003.1061457    0.00000   100%  35.7    0s
H  197   222                    2318.6176460    0.00000   100%  34.5    0s
H  222   238                    2181.5484433    0.00000   100%  34.9    0s
H  224   238                    2086.3985755    0.00000   100%  35.0    0s
H  227   238                    2073.5755118    0.00000   100%  35.0    0s
H  236   238                    1972.5625264    0.00000   100%  34.8    0s
H 1296  1309                    1883.4139523    0.00000   100%  25.2    1s
H 1301  1309                    1866.4580361    0.00000   100%  25.1    1s
H 1303  1309                    1670.1299020    0.00000   100%  25.1    1s
H 1304  1309                    1645.8942051    0.00000   100%  25.1    1s
H 1311  1307                    1533.4989454    0.00000   100%  25.0    1s
H 1750  1612                    1244.4389630    0.00000   100%  22.1    2s
H 1753  1430                    1019.1699742    0.00000   100%  22.1    2s
H 1760  1275                     854.5525689    0.00000   100%  22.0    2s
H 2898  1858                     846.1669914    0.00000   100%  24.0    3s
H 2955  1806                     807.9096628    0.00000   100%  24.3    4s
H 4090  2249                     761.7033183    0.00000   100%  25.3    4s
  4096  2252   18.83773   21   77  761.70332    0.00000   100%  25.3    6s
H 4098  2161                     727.5858005    0.00000   100%  25.2    6s
 40296 15357     cutoff   44       727.58580   98.55587  86.5%  25.9   10s
H92039 31301                     686.7753756  162.66373  76.3%  22.8   14s
H92042 25535                     599.3723931  162.66373  72.9%  22.8   14s
 100948 28868  421.91124   40   62  599.37239  167.58146  72.0%  22.2   15s
*122948 33955             115     574.7933847  179.78014  68.7%  20.9   16s
 163915 47152  459.02428   31   68  574.79338  196.55958  65.8%  19.0   20s
H199558 55654                     547.9018654  204.57980  62.7%  17.7   22s
 227913 66016  355.19586   69   45  547.90187  211.55226  61.4%  16.9   25s
*238461 64242             116     519.5696364  213.21389  59.0%  16.6   25s
 288275 81731     cutoff   38       519.56964  222.42299  57.2%  15.4   32s
H288279 69363                     476.9713413  222.42299  53.4%  15.4   32s
 308083 76478  471.67166   82   24  476.97134  226.13374  52.6%  15.1   35s
 373730 98214     cutoff   46       476.97134  234.98969  50.7%  14.1   40s
H388767 99758                     467.9685084  236.61416  49.4%  13.9   41s
 428652 113052     cutoff   80       467.96851  240.67708  48.6%  13.4   45s
 493928 131348  393.68764   87   37  467.96851  246.59522  47.3%  12.7   50s
 547282 145975     cutoff   53       467.96851  251.09693  46.3%  12.3   55s
 622069 165557  336.33076   54   70  467.96851  256.76995  45.1%  11.8   60s
 679479 179354  364.20782   79   40  467.96851  261.02171  44.2%  11.4   65s
 752389 196888  411.52630   71   41  467.96851  265.95471  43.2%  11.1   70s
 815834 212700  381.69804   71   49  467.96851  270.09731  42.3%  10.8   75s
 871529 225764  424.87085   79   40  467.96851  273.56528  41.5%  10.6   80s
 939882 241198     cutoff   80       467.96851  277.78695  40.6%  10.3   85s
 1009919 257246  388.18833   65   57  467.96851  281.81143  39.8%  10.1   90s
 1056019 267385  298.45468   62   54  467.96851  284.33555  39.2%  10.0   95s
 1113046 279332     cutoff   67       467.96851  287.37551  38.6%   9.9  100s
 1188516 294999  367.46919   76   49  467.96851  291.37877  37.7%   9.7  105s
 1249804 306935  394.05024   78   34  467.96851  294.55012  37.1%   9.6  110s
 1307542 318394     cutoff   90       467.96851  297.36789  36.5%   9.5  115s
 1368102 329639     cutoff   78       467.96851  300.35293  35.8%   9.4  120s
 1430201 341354  367.22071   76   37  467.96851  303.04917  35.2%   9.3  125s
H1482129 349201                     465.8978285  305.33131  34.5%   9.2  129s
 1484565 349882     cutoff   71       465.89783  305.43365  34.4%   9.2  130s
 1555979 362729  421.38682   72   41  465.89783  308.42770  33.8%   9.1  135s
 1619650 374082     cutoff   90       465.89783  310.87450  33.3%   9.0  140s
 1689506 386243  441.03030   83   36  465.89783  313.54682  32.7%   8.9  145s
 1753562 397532  347.87525   58   50  465.89783  315.96835  32.2%   8.8  150s
 1804574 405558  318.15425   65   52  465.89783  317.67323  31.8%   8.8  155s
 1875933 416745     cutoff   72       465.89783  320.16751  31.3%   8.7  160s
 1936581 425748  368.97685   65   54  465.89783  322.29035  30.8%   8.7  165s
 1973112 430744     cutoff   78       465.89783  323.51751  30.6%   8.6  170s
 2048956 441314     cutoff   55       465.89783  326.05484  30.0%   8.6  175s
 2124161 451571     cutoff   92       465.89783  328.46733  29.5%   8.5  180s
 2183341 459197     cutoff   57       465.89783  330.30074  29.1%   8.5  186s
 2237070 466076     cutoff   82       465.89783  331.95240  28.7%   8.4  190s
 2312629 474875  411.01541   64   52  465.89783  334.20424  28.3%   8.4  195s
 2372033 481994  371.09581   61   58  465.89783  335.91721  27.9%   8.3  200s
 2419262 487379     cutoff   75       465.89783  337.19407  27.6%   8.3  205s
 2493073 495556  398.60665   44   61  465.89783  339.24492  27.2%   8.2  210s
 2555783 502291     cutoff   30       465.89783  340.88956  26.8%   8.2  215s
 2585579 505508  442.24450   77   45  465.89783  341.67697  26.7%   8.2  220s
 2657129 512470     cutoff   62       465.89783  343.48164  26.3%   8.1  225s
 2732262 519922     cutoff   71       465.89783  345.36069  25.9%   8.1  230s
 2807122 526239     cutoff   88       465.89783  347.17958  25.5%   8.0  235s
 2860991 530822  428.07221   85   34  465.89783  348.46444  25.2%   8.0  240s
 2920179 535747     cutoff   65       465.89783  349.82007  24.9%   8.0  245s
 2987118 540590     cutoff   77       465.89783  351.41737  24.6%   8.0  250s
 3042808 544821     cutoff   57       465.89783  352.67183  24.3%   7.9  256s
 3089527 548264     cutoff   73       465.89783  353.71062  24.1%   7.9  260s
 3164455 553035     cutoff   90       465.89783  355.39371  23.7%   7.9  265s
 3239396 557782  411.78595   73   46  465.89783  357.02351  23.4%   7.8  270s
 3302088 561496  391.71426   77   43  465.89783  358.36656  23.1%   7.8  276s
 3357340 564539  413.44027   64   51  465.89783  359.51301  22.8%   7.8  280s
 3414460 567489     cutoff   56       465.89783  360.67246  22.6%   7.8  285s
 3472991 570355  438.30721   69   47  465.89783  361.86226  22.3%   7.7  290s
 3532380 572971     cutoff   85       465.89783  363.04692  22.1%   7.7  295s
 3596611 575713  442.62346   82   32  465.89783  364.33485  21.8%   7.7  300s
 3659447 578135  424.35412   78   39  465.89783  365.59798  21.5%   7.7  305s
 3714278 580109     cutoff   70       465.89783  366.65303  21.3%   7.6  310s
 3789742 582777     cutoff   71       465.89783  368.10561  21.0%   7.6  315s
 3841888 583947  457.00690   94   17  465.89783  369.11275  20.8%   7.6  320s
 3899857 585333  440.81307   90   24  465.89783  370.20855  20.5%   7.6  325s
 3972168 586917     cutoff   88       465.89783  371.53672  20.3%   7.6  330s
 4028495 587711  444.40111   77   33  465.89783  372.56821  20.0%   7.5  335s
 4092560 588934  405.21699   59   54  465.89783  373.72357  19.8%   7.5  340s
 4143755 589505  397.24912   44   67  465.89783  374.65876  19.6%   7.5  345s
 4206495 590047     cutoff   81       465.89783  375.78773  19.3%   7.5  350s
 4271325 590348     cutoff   82       465.89783  376.93667  19.1%   7.5  355s
 4332474 590571     cutoff   59       465.89783  377.99490  18.9%   7.4  360s
 4402968 590354  455.80718   59   54  465.89783  379.19412  18.6%   7.4  365s
 4454374 590142     cutoff   48       465.89783  380.07273  18.4%   7.4  370s
 4519655 589183  437.41250   61   42  465.89783  381.20897  18.2%   7.4  375s
 4576992 588431  426.59063   88   34  465.89783  382.15514  18.0%   7.4  380s
 4642920 586912     cutoff   82       465.89783  383.29698  17.7%   7.4  386s
 4695041 585228  396.73010   90   30  465.89783  384.19536  17.5%   7.3  390s
 4762783 582923  443.15442   77   43  465.89783  385.35348  17.3%   7.3  395s
 4832583 579800     cutoff   66       465.89783  386.59045  17.0%   7.3  400s
 4881173 577366  388.31778   76   47  465.89783  387.45372  16.8%   7.3  405s
 4922075 575244  419.27871   65   51  465.89783  388.14175  16.7%   7.3  410s
 4993656 571234  441.81758   92   28  465.89783  389.36987  16.4%   7.3  415s
 5052680 567346  465.36907   56   55  465.89783  390.37506  16.2%   7.2  420s
 5119049 562868     cutoff   85       465.89783  391.52586  16.0%   7.2  425s
 5160492 560034     cutoff   81       465.89783  392.24170  15.8%   7.2  430s
 5234714 553850     cutoff   67       465.89783  393.51145  15.5%   7.2  435s
 5307887 548126     cutoff   65       465.89783  394.76772  15.3%   7.2  440s
 5342277 545242  424.98640   73   45  465.89783  395.37411  15.1%   7.2  445s
 5409691 539281  459.66628   72   47  465.89783  396.53310  14.9%   7.1  450s
 5432632 537380     cutoff   72       465.89783  396.92351  14.8%   7.1  455s
 5493601 531198  459.88039   74   39  465.89783  397.99576  14.6%   7.1  460s
 5539433 526745     cutoff   62       465.89783  398.78718  14.4%   7.1  465s
 5607346 519731  413.81366   79   37  465.89783  399.95162  14.2%   7.1  470s
 5649835 515524  432.35258   84   32  465.89783  400.66686  14.0%   7.1  475s
 5722885 507222  431.73935   90   32  465.89783  401.95865  13.7%   7.1  480s
 5793109 498639     cutoff   69       465.89783  403.19024  13.5%   7.1  485s
 5854236 491110     cutoff   65       465.89783  404.25454  13.2%   7.0  490s
 5926838 481846  433.38765   84   33  465.89783  405.51928  13.0%   7.0  495s
 5984242 474090     cutoff   70       465.89783  406.54094  12.7%   7.0  500s
 6046112 465202  442.22667   70   50  465.89783  407.64826  12.5%   7.0  505s
 6108678 455745     cutoff   84       465.89783  408.78373  12.3%   7.0  510s
 6160112 447676     cutoff   73       465.89783  409.74312  12.1%   7.0  515s
 6206268 439803  435.20152   80   43  465.89783  410.62386  11.9%   7.0  520s
 6276506 427792     cutoff   70       465.89783  411.96076  11.6%   6.9  525s
 6329410 418273  456.90610   92   27  465.89783  413.01640  11.4%   6.9  530s
 6403534 404389     cutoff   48       465.89783  414.49117  11.0%   6.9  535s
 6442417 396854     cutoff   69       465.89783  415.28386  10.9%   6.9  540s
 6517879 381892     cutoff   77       465.89783  416.81659  10.5%   6.9  545s
 6590763 366727  448.79680   79   34  465.89783  418.31077  10.2%   6.9  550s
 6645192 354544     cutoff   73       465.89783  419.52954  10.0%   6.9  555s
 6702543 340936     cutoff   78       465.89783  420.85617  9.67%   6.9  560s
 6770080 324925  453.96711   94   23  465.89783  422.42760  9.33%   6.8  565s
 6833928 308585     cutoff   73       465.89783  424.02793  8.99%   6.8  570s
 6883933 295413  454.50076   68   45  465.89783  425.32197  8.71%   6.8  575s
 6942029 278856     cutoff   71       465.89783  426.87457  8.38%   6.8  580s
 7016177 256123     cutoff   69       465.89783  429.00619  7.92%   6.8  585s
 7078848 235851  434.84718   74   43  465.89783  430.89311  7.51%   6.8  590s
 7122982 220996  446.00321   83   35  465.89783  432.33039  7.20%   6.8  595s
 7201009 192662  442.33336   70   49  465.89783  435.05242  6.62%   6.7  600s
 7265388 167165     cutoff   79       465.89783  437.59616  6.07%   6.7  605s
 7333941 137521     cutoff   76       465.89783  440.71332  5.41%   6.7  610s

Explored 7372238 nodes (49225808 simplex iterations) in 612.81 seconds (652.05 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 465.898 467.969 476.971 ... 761.703

Optimal solution found (tolerance 5.00e-02)
Best objective 4.658978285456e+02, best bound 4.426228899313e+02, gap 4.9957%

Gurobi MIQP converged to an optimal solution.
Cluster Assignments from Gurobi MIQP using MSE
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 6.17658156e-01  2.90008937e-04  1.10811278e-03 -1.08224676e-03]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
109.77090328587008
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 1 2
 1 1 2 1 1 1 1 2 1 1 1 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 1 2 2]
-----------------------------------
Regression weights for cluster 0: y = -1.1524x_0 + -1.197x_1 + -1.2161x_2 + -10.6348
Regression weights for cluster 0 after refit: y = -1.1482x_1 + -1.1947x_2 + -1.2115x_3 + -10.6503
-----------------------------------
Regression weights for cluster 1: y = 1.2812x_0 + 3.3598x_1 + -0.146x_2 + 0.5993
Regression weights for cluster 1 after refit: y = 1.2816x_1 + 3.3611x_2 + -0.1463x_3 + 0.5983
-----------------------------------
Regression weights for cluster 2: y = -0.3241x_0 + 0.6256x_1 + -0.0433x_2 + 10.5423
Regression weights for cluster 2 after refit: y = -0.3322x_1 + 0.6177x_2 + -0.0465x_3 + 10.5651
{'time_milp': 613.690217256546, 'time_greedy': np.float64(0.4784006953239441), 'time_refit_milp_assignment': 616.3684847354889, 'mse_refit_ground_truth_assignment': np.float64(3.9718102752629525), 'r2_refit_ground_truth_assignment': 0.9656195904690807, 'weight_mismatch_refit_ground_truth_assignment': np.float64(1.6349858361791783), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(3.6216264996915806), 'r2_milp': 0.9686508182420211, 'weight_mismatch_milp': np.float64(3.908717970548519), 'refit-weight_mismatch_milp': np.float64(3.2922755585152927), 'rand_score_milp': np.float64(0.8438967136150235), 'label_mismatch_milp': np.float64(0.1388888888888889), 'mse_refit_milp_assignment': np.float64(3.6215716180200577), 'r2_refit_milp_assignment': 0.9686512933035705, 'weight_mismatch_refit_milp_assignment': np.float64(3.9376382035439095), 'refit-weight_mismatch_refit_milp_assignment': np.float64(3.325089725948285), 'rand_score_refit_milp_assignment': np.float64(0.8438967136150235), 'label_mismatch_refit_milp_assignment': np.float64(0.1388888888888889), 'mse_greedy': np.float64(7.757882683352058), 'r2_greedy': np.float64(0.9328469475474096), 'weight_mismatch_greedy': np.float64(13.908225711848058), 'refit-weight_mismatch_greedy': np.float64(13.338792889424724), 'rand_score_greedy': np.float64(0.7536189358372457), 'label_mismatch_greedy': np.float64(0.3104166666666666), 'mse_greedy_sem': np.float64(1.3932387144188385), 'r2_greedy_sem': np.float64(0.012060021566080456), 'weight_mismatch_greedy_sem': np.float64(2.6174516371060723), 'refit-weight_mismatch_greedy_sem': np.float64(2.6420508007623518), 'rand_score_greedy_sem': np.float64(0.020666289122536593), 'label_mismatch_greedy_sem': np.float64(0.03204242220849813), 'mse_ground_truth': np.float64(3.952027283268194), 'r2_ground_truth': np.float64(0.9650896016367458), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(109.77090328587008), 'r2_baseline_sklearn': np.float64(0.04981145926027608), 'mse_milp_val': np.float64(4.813534038709043), 'r2_milp_val': 0.9560853671203949, 'label_mismatch_milp_val': np.float64(0.10416666666666667), 'mse_refit_milp_assignment_val': np.float64(4.814270812442907), 'r2_refit_milp_assignment_val': 0.9560786454170107, 'label_mismatch_refit_milp_assignment_val': np.float64(0.10416666666666667), 'mse_greedy_val': np.float64(15.98735389542179), 'label_mismatch_greedy_val': np.float64(0.3104166666666667), 'mse_greedy_val_sem': np.float64(4.135763384376441), 'label_mismatch_greedy_val_sem': np.float64(0.03426267533413921), 'r2_greedy_val': np.float64(0.8541448400722093), 'r2_greedy_val_sem': np.float64(0.03773122392846192), 'mse_refit_ground_truth_assignment_val': np.float64(4.360924784916186), 'r2_refit_ground_truth_assignment_val': 0.9602145929778183, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.16666666666666666), 'mse_ground_truth_val': np.float64(4.263602431868547), 'r2_ground_truth_val': 0.9611024802080108, 'label_mismatch_ground_truth_val': np.float64(0.16666666666666666), 'mse_baseline_sklearn_val': np.float64(109.80230206049835), 'r2_baseline_sklearn_val': -0.0017437802549540304}
