==================== Evaluating with noise_std = 1.4 in Dataset 1 with random state = 42 ====================
ODS is enabled
mse 1.6764735364924122
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
using MSE:
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8160 CPU @ 2.10GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 288 columns and 216 nonzeros
Model fingerprint: 0xce9e3e31
Model has 72 quadratic objective terms
Model has 216 general constraints
Variable types: 72 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e+00, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [4e-01, 2e+01]
  GenCon coe range [3e-04, 9e+00]
Presolve added 216 rows and 216 columns
Presolve time: 0.02s
Presolved: 288 rows, 504 columns, 16200 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 72 quadratic objective terms
Variable types: 288 continuous, 216 integer (216 binary)
Found heuristic solution: objective 10168.649714
Found heuristic solution: objective 7809.8801818

Root relaxation: objective 0.000000e+00, 687 iterations, 0.01 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   74 7809.88018    0.00000   100%     -    0s
H    0     0                    5676.3063513    0.00000   100%     -    0s
     0     0    0.00000    0   76 5676.30635    0.00000   100%     -    0s
     0     2    0.00000    0   76 5676.30635    0.00000   100%     -    0s
H   31    48                    4223.6729873    5.66862   100%  37.0    0s
H   35    48                    3981.9752373    5.66862   100%  33.3    0s
H   41    48                    2792.1785305    5.66862   100%  29.5    0s
H   89    96                    2500.9044214    8.88702   100%  24.8    0s
H  188   237                    2232.1296840    9.37955   100%  30.3    0s
H  218   237                    1874.5360378    9.37955  99.5%  32.9    0s
H  320   327                    1704.3034451    9.37955  99.4%  35.7    0s
H 1474  1357                    1437.0117150   11.67028  99.2%  26.9    1s
H 1477   916                     754.6381461   11.67028  98.5%  26.9    1s
  3813  2210  388.92580   23   79  754.63815   15.44906  98.0%  33.5    5s
H 5478  2310                     750.8628743   15.44906  97.9%  33.4    5s
H 5479  2204                     711.2028086   15.44906  97.8%  33.4    5s
*37078 10909             120     616.4334602  110.96209  82.0%  30.3    9s
 44246 14137  440.75480   23   76  616.43346  121.42806  80.3%  28.7   10s
 78582 27846     cutoff   61       616.43346  141.89041  77.0%  22.9   16s
H79123 26364                     586.1042793  141.89041  75.8%  22.9   16s
*101826 34572             124     582.7470793  150.57851  74.2%  21.0   18s
*111816 37103             120     574.6974422  154.17312  73.2%  20.3   19s
 114867 38829  250.97779   57   63  574.69744  155.04331  73.0%  20.1   20s
 177754 59479  549.77411   56   58  574.69744  168.22823  70.7%  17.5   25s
*182619 60821             122     572.1814999  168.90727  70.5%  17.3   25s
*218793 70631             124     558.3215813  175.58152  68.6%  16.4   28s
H220281 69501                     547.7594430  175.76166  67.9%  16.4   28s
H225550 64805                     516.7933793  176.45914  65.9%  16.3   29s
 232995 67031  392.72616   58   59  516.79338  177.69276  65.6%  16.2   30s
 258078 74631  401.14352   85   33  516.79338  181.63120  64.9%  15.7   35s
 273049 79000     cutoff   52       516.79338  183.52522  64.5%  15.5   43s
H273052 59561                     455.0178502  183.52522  59.7%  15.5   43s
 291846 64185  360.60588   51   61  455.01785  186.79024  58.9%  15.2   45s
 355798 79890     cutoff   52       455.01785  196.52990  56.8%  14.5   50s
H359914 79879                     453.0120913  197.09583  56.5%  14.4   50s
 418901 94187  270.44307   53   53  453.01209  204.68535  54.8%  13.9   55s
 482222 108848     cutoff   96       453.01209  212.29224  53.1%  13.4   60s
 543474 123509     cutoff   78       453.01209  218.48054  51.8%  13.1   65s
 601970 136953     cutoff   67       453.01209  224.24537  50.5%  12.8   70s
H626507 142145                     452.3577552  226.47327  49.9%  12.7   72s
 655576 148806  359.13013   38   72  452.35776  228.98748  49.4%  12.6   75s
 680400 154446     cutoff   54       452.35776  231.07454  48.9%  12.5   80s
 745677 170014  451.09624   93   42  452.35776  235.91337  47.8%  12.2   85s
 808764 185334     cutoff   78       452.35776  240.55268  46.8%  12.0   90s
 865840 198515     cutoff   66       452.35776  244.34029  46.0%  11.8   95s
 927213 212128     cutoff   80       452.35776  248.14770  45.1%  11.6  100s
 978775 224018  360.78892   62   55  452.35776  251.34449  44.4%  11.5  105s
 1026999 234487  315.84615   65   51  452.35776  254.07079  43.8%  11.4  110s
 1091880 247967  379.05279   75   52  452.35776  257.81918  43.0%  11.3  115s
 1147463 259964     cutoff   47       452.35776  260.69104  42.4%  11.1  120s
 1202620 271590     cutoff   48       452.35776  263.46561  41.8%  11.0  125s
 1262512 284499  320.42258   74   44  452.35776  266.21496  41.1%  10.9  130s
 1320940 296767  382.91829   61   48  452.35776  268.80441  40.6%  10.8  135s
 1369915 306831  363.03029   40   74  452.35776  270.91537  40.1%  10.7  140s
 1433053 319113  363.17549   63   61  452.35776  273.66485  39.5%  10.7  145s
 1490262 330130  366.03900   75   51  452.35776  276.14432  39.0%  10.6  150s
H1504980 325301                     442.5862961  276.72906  37.5%  10.6  151s
 1545156 332145  357.97581   49   62  442.58630  278.46020  37.1%  10.5  155s
 1604852 342764  303.08999   58   62  442.58630  280.91792  36.5%  10.5  160s
H1620494 335100                     432.2511056  281.43102  34.9%  10.4  162s
 1650868 339812  294.40955   51   63  432.25111  282.73233  34.6%  10.4  165s
 1717483 349337     cutoff   66       432.25111  285.55218  33.9%  10.4  170s
 1777428 357993     cutoff   52       432.25111  288.06114  33.4%  10.3  175s
 1816683 363617  405.73402   51   52  432.25111  289.75993  33.0%  10.3  180s
 1882288 372818  355.96853   81   54  432.25111  292.56098  32.3%  10.2  185s
 1939965 379625  351.14167   80   51  432.25111  294.94469  31.8%  10.2  190s
 2002491 387956     cutoff   77       432.25111  297.42569  31.2%  10.1  195s
 2056432 394923     cutoff   30       432.25111  299.59142  30.7%  10.1  200s
 2116548 402170  411.76207   65   53  432.25111  301.98107  30.1%  10.0  205s
 2165516 407575  337.21996   65   62  432.25111  303.97777  29.7%  10.0  210s
 2229912 414442  364.37605   58   54  432.25111  306.38732  29.1%  10.0  215s
 2289207 420263  313.03823   62   57  432.25111  308.57909  28.6%   9.9  220s
 2308791 422258  326.98193   68   59  432.25111  309.28077  28.4%   9.9  225s
 2376110 428501  360.20097   67   54  432.25111  311.66295  27.9%   9.9  230s
 2442771 434662     cutoff   57       432.25111  314.02734  27.4%   9.8  235s
 2486984 438715     cutoff   39       432.25111  315.54209  27.0%   9.8  240s
 2552795 443817  415.15977   76   47  432.25111  317.76600  26.5%   9.7  245s
 2615934 448317     cutoff   68       432.25111  319.90402  26.0%   9.7  250s
 2673487 451456  371.74243   72   52  432.25111  321.87490  25.5%   9.7  255s
 2732590 454649     cutoff   53       432.25111  323.87223  25.1%   9.6  260s
 2744118 455237     cutoff   67       432.25111  324.24051  25.0%   9.6  265s
 2803093 457087     cutoff   75       432.25111  326.20549  24.5%   9.6  270s
 2870098 458742  398.61876   53   61  432.25111  328.40514  24.0%   9.6  275s
 2937889 460159  348.98211   67   58  432.25111  330.59016  23.5%   9.5  280s
 3003753 461082  344.52715   78   47  432.25111  332.73886  23.0%   9.5  285s
 3067903 461225  377.54889   80   45  432.25111  334.82586  22.5%   9.5  290s
 3127590 460817  352.82686   63   55  432.25111  336.67635  22.1%   9.4  295s
 3177534 459697     cutoff   84       432.25111  338.32794  21.7%   9.4  300s
 3236468 458412  432.20670   63   50  432.25111  340.15504  21.3%   9.4  305s
 3285234 457424  409.91551   79   46  432.25111  341.67704  21.0%   9.3  313s
 3300904 456993     cutoff   68       432.25111  342.15031  20.8%   9.3  315s
 3366733 454491     cutoff   78       432.25111  344.19586  20.4%   9.3  320s
 3431646 451260  386.79253   73   52  432.25111  346.23498  19.9%   9.3  325s
 3498817 447395  383.25822   70   48  432.25111  348.30449  19.4%   9.3  330s
 3554327 443874  431.21679   70   52  432.25111  349.98681  19.0%   9.2  335s
 3609486 439872     cutoff   45       432.25111  351.68338  18.6%   9.2  340s
 3657732 435617     cutoff   55       432.25111  353.15822  18.3%   9.2  351s
 3711580 430719  370.62298   78   32  432.25111  354.75836  17.9%   9.2  355s
 3777817 424297  386.82086   73   47  432.25111  356.76015  17.5%   9.1  360s
 3844058 417307  388.21555   61   47  432.25111  358.78314  17.0%   9.1  365s
 3910290 409639     cutoff   73       432.25111  360.76634  16.5%   9.1  370s
 3959605 403314  399.46763   61   51  432.25111  362.26055  16.2%   9.0  375s
 3983538 400353  399.37151   90   25  432.25111  363.00305  16.0%   9.0  380s
 4043591 392035  388.69073   57   55  432.25111  364.83793  15.6%   9.0  385s
 4110995 382374  419.77871   65   52  432.25111  366.89474  15.1%   9.0  390s
 4177760 371657  419.26780   64   50  432.25111  368.94497  14.6%   8.9  395s
 4212117 365623     cutoff   70       432.25111  370.02504  14.4%   8.9  403s
 4228054 362583     cutoff   62       432.25111  370.54778  14.3%   8.9  405s
 4296431 349721     cutoff   72       432.25111  372.73107  13.8%   8.9  410s
 4361897 336073     cutoff   54       432.25111  374.84941  13.3%   8.9  415s
 4427430 321995     cutoff   53       432.25111  377.01908  12.8%   8.8  420s
 4495389 306232  407.64159   68   56  432.25111  379.25790  12.3%   8.8  425s
 4497101 305905     cutoff   84       432.25111  379.31446  12.2%   8.8  432s
 4536116 295627  421.08923   73   51  432.25111  380.69290  11.9%   8.8  435s
 4602060 278240  384.56653   54   54  432.25111  383.03136  11.4%   8.7  440s
 4670362 258602     cutoff   61       432.25111  385.57233  10.8%   8.7  445s
 4735856 238115  421.24537   77   49  432.25111  388.12707  10.2%   8.7  450s
 4778963 224528     cutoff   43       432.25111  389.88779  9.80%   8.6  459s
 4790234 220162     cutoff   34       432.25111  390.37559  9.69%   8.6  460s
 4859344 195280     cutoff   54       432.25111  393.43558  8.98%   8.6  465s
 4898573 180973     cutoff   73       432.25111  395.29747  8.55%   8.6  474s
 4908718 175956     cutoff   75       432.25111  395.84472  8.42%   8.6  475s
 4975670 147897  401.01415   61   62  432.25111  399.53306  7.57%   8.5  480s
 5035746 120656     cutoff   89       432.25111  403.27720  6.70%   8.5  485s
 5076131 101249  421.21172   78   43  432.25111  406.25335  6.01%   8.5  493s
 5090077 93847     cutoff   55       432.25111  407.37777  5.75%   8.5  495s

Explored 5126981 nodes (43262218 simplex iterations) in 497.65 seconds (459.93 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 432.251 442.586 452.358 ... 574.697

Optimal solution found (tolerance 5.00e-02)
Best objective 4.322511055501e+02, best bound 4.107495918774e+02, gap 4.9743%

Gurobi MIQP converged to an optimal solution.
Cluster Assignments from Gurobi MIQP using MSE
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[0.78488427 0.0015453  0.0008607  0.00134169]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
108.92426059720827
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 1 1 1 2 1
 1 1 1 1 1 1 2 1 1 1 1 2 2 2 2 2 1 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2]
-----------------------------------
Regression weights for cluster 0: y = -1.3667x_0 + -1.6925x_1 + -0.7964x_2 + -10.4507
Regression weights for cluster 0 after refit: y = -1.3567x_1 + -1.685x_2 + -0.7919x_3 + -10.4744
-----------------------------------
Regression weights for cluster 1: y = 1.7968x_0 + 1.9806x_1 + 0.7837x_2 + 0.9334
Regression weights for cluster 1 after refit: y = 1.7972x_1 + 1.9812x_2 + 0.7832x_3 + 0.9332
-----------------------------------
Regression weights for cluster 2: y = 0.8195x_0 + 0.2434x_1 + 0.2969x_2 + 8.9829
Regression weights for cluster 2 after refit: y = 0.819x_1 + 0.238x_2 + 0.294x_3 + 8.9961
{'time_milp': 498.38432598114014, 'time_greedy': np.float64(0.5341519355773926), 'time_refit_milp_assignment': 501.4722709655762, 'mse_refit_ground_truth_assignment': np.float64(1.432487442575844), 'r2_refit_ground_truth_assignment': 0.9876937078820484, 'weight_mismatch_refit_ground_truth_assignment': np.float64(1.1952333430792685), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(1.7919664405106286), 'r2_milp': 0.9846054758826815, 'weight_mismatch_milp': np.float64(2.3076688842043405), 'refit-weight_mismatch_milp': np.float64(2.0027793990800236), 'rand_score_milp': np.float64(0.8877151799687011), 'label_mismatch_milp': np.float64(0.09722222222222222), 'mse_refit_milp_assignment': np.float64(1.7919198687137852), 'r2_refit_milp_assignment': 0.9846058759742421, 'weight_mismatch_refit_milp_assignment': np.float64(2.318378171811826), 'refit-weight_mismatch_refit_milp_assignment': np.float64(1.9646205024313983), 'rand_score_refit_milp_assignment': np.float64(0.8877151799687011), 'label_mismatch_refit_milp_assignment': np.float64(0.09722222222222222), 'mse_greedy': np.float64(6.091829056802583), 'r2_greedy': np.float64(0.9476659789974606), 'weight_mismatch_greedy': np.float64(15.05558574825054), 'refit-weight_mismatch_greedy': np.float64(14.84758411056732), 'rand_score_greedy': np.float64(0.7739241001564945), 'label_mismatch_greedy': np.float64(0.2861111111111111), 'mse_greedy_sem': np.float64(1.4416797512935862), 'r2_greedy_sem': np.float64(0.012385261910605076), 'weight_mismatch_greedy_sem': np.float64(2.455711255574505), 'refit-weight_mismatch_greedy_sem': np.float64(2.526523258394221), 'rand_score_greedy_sem': np.float64(0.023363845721322062), 'label_mismatch_greedy_sem': np.float64(0.033333333333333326), 'mse_ground_truth': np.float64(1.6764735364924122), 'r2_ground_truth': np.float64(0.9855384269656834), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(108.92426059720827), 'r2_baseline_sklearn': np.float64(0.06424745530000764), 'mse_milp_val': np.float64(2.966675163994831), 'r2_milp_val': 0.9742077739655157, 'label_mismatch_milp_val': np.float64(0.08333333333333333), 'mse_refit_milp_assignment_val': np.float64(2.968920783539552), 'r2_refit_milp_assignment_val': 0.9741882505854073, 'label_mismatch_refit_milp_assignment_val': np.float64(0.08333333333333333), 'mse_greedy_val': np.float64(12.826511774970669), 'label_mismatch_greedy_val': np.float64(0.25729166666666664), 'mse_greedy_val_sem': np.float64(3.3026865602014195), 'label_mismatch_greedy_val_sem': np.float64(0.031605254104156544), 'r2_greedy_val': np.float64(0.8884865134716871), 'r2_greedy_val_sem': np.float64(0.02871350369450728), 'mse_refit_ground_truth_assignment_val': np.float64(1.9248322213443867), 'r2_refit_ground_truth_assignment_val': 0.9832655397079195, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.041666666666666664), 'mse_ground_truth_val': np.float64(1.906764348658135), 'r2_ground_truth_val': 0.983422621501687, 'label_mismatch_ground_truth_val': np.float64(0.041666666666666664), 'mse_baseline_sklearn_val': np.float64(115.34475785432848), 'r2_baseline_sklearn_val': -0.0028054647094102325}
