==================== Evaluating with noise_std = 2.9 in Dataset 1 with random state = 2 ====================
ODS is enabled
mse 9.4429562644153
Splitting data into training and validation set
Not whitening the data...
Set parameter TokenServer to value "license1.computecanada.ca"
Set parameter Threads to value 16
Read parameters from file gurobi.env
Set parameter MIPGap to value 0.05
Set parameter TimeLimit to value 36000
using MSE:
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "AlmaLinux 9.3 (Shamrock Pampas Cat)")

CPU model: Intel(R) Xeon(R) Platinum 8160 CPU @ 2.10GHz, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 48 physical cores, 48 logical processors, using up to 16 threads

Optimize a model with 72 rows, 288 columns and 216 nonzeros
Model fingerprint: 0xa69205af
Model has 72 quadratic objective terms
Model has 216 general constraints
Variable types: 72 continuous, 216 integer (216 binary)
Coefficient statistics:
  Matrix range     [1e+00, 1e+00]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e+00, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+00]
  GenCon rhs range [4e-01, 2e+01]
  GenCon coe range [3e-05, 9e+00]
Presolve added 216 rows and 216 columns
Presolve time: 0.04s
Presolved: 288 rows, 504 columns, 16200 nonzeros
Presolved model has 216 SOS constraint(s)
Presolved model has 72 quadratic objective terms
Variable types: 288 continuous, 216 integer (216 binary)
Found heuristic solution: objective 8816.6629334
Found heuristic solution: objective 6976.6524475

Root relaxation: objective 0.000000e+00, 681 iterations, 0.02 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0   86 6976.65245    0.00000   100%     -    0s
H    0     0                    6612.5462877    0.00000   100%     -    0s
H    0     0                    4144.5323954    0.00000   100%     -    0s
     0     0    0.00000    0   85 4144.53240    0.00000   100%     -    0s
H    0     0                    2971.6968237    0.00000   100%     -    0s
     0     2    0.00000    0   85 2971.69682    0.00000   100%     -    0s
H  127   157                    2266.2809198    0.00000   100%  30.4    0s
H  188   220                    2100.1957201    0.00000   100%  31.8    0s
H  190   220                    1856.5968094    0.00000   100%  31.7    0s
H  507   524                    1228.3570367    0.00000   100%  28.9    1s
H  512   524                     790.1088727    0.00000   100%  28.8    1s
H 1101  1045                     634.1106804    0.00000   100%  25.0    2s
H 3319  2255                     606.8422208    0.00000   100%  30.5    3s
H 3320  2155                     551.2280271    0.00000   100%  30.5    3s
  4389  2379  314.63040   20   74  551.22803    0.00000   100%  31.4    5s
 48225 13833  345.80621   33   71  551.22803  149.45161  72.9%  23.0   10s
 111205 33588  307.21536   70   48  551.22803  194.21328  64.8%  17.5   15s
*124596 37438             118     534.4985899  199.56611  62.7%  16.9   16s
*141878 33229             116     466.8764303  205.58267  56.0%  16.2   17s
 172232 42082  274.99431   26   75  466.87643  214.99396  54.0%  15.1   20s
H182511 42533                     456.1038058  217.56611  52.3%  14.8   20s
H182729 42294                     454.8962232  217.56611  52.2%  14.8   20s
 233100 56329     cutoff   57       454.89622  229.93300  49.5%  13.7   25s
 289824 72290  373.42736   59   52  454.89622  240.23787  47.2%  12.8   31s
 330856 83960     cutoff   80       454.89622  246.51942  45.8%  12.3   35s
 394139 100655  359.33882   78   42  454.89622  254.01035  44.2%  11.8   40s
H451565 114241                     450.8923424  259.32301  42.5%  11.4   44s
 454031 114769  357.32393   57   61  450.89234  259.53590  42.4%  11.4   45s
 516115 132085  415.39255   73   44  450.89234  264.52074  41.3%  11.0   50s
H544917 137433                     445.4819134  266.57098  40.2%  10.9   54s
 546392 137965  366.97520   53   63  445.48191  266.59786  40.2%  10.9   55s
 609316 154027     cutoff   46       445.48191  270.62629  39.3%  10.6   60s
 677324 168932  412.73768   52   53  445.48191  275.46055  38.2%  10.3   65s
 712889 176749     cutoff   62       445.48191  277.93894  37.6%  10.2   70s
 770771 189726     cutoff   75       445.48191  281.45564  36.8%  10.0   75s
 835927 203636  300.56342   78   44  445.48191  285.35227  35.9%   9.8   80s
 882963 214149  378.39687   62   51  445.48191  287.85989  35.4%   9.7   86s
 931017 224606  291.96242   68   47  445.48191  290.37507  34.8%   9.6   90s
 998529 239356  426.15351   78   40  445.48191  293.36945  34.1%   9.4   95s
 1001869 239813  294.76861   89   35  445.48191  293.53290  34.1%   9.4  100s
 1068511 254470  400.62664   65   49  445.48191  296.26040  33.5%   9.3  105s
 1135080 268866  423.86462   67   53  445.48191  298.59838  33.0%   9.1  110s
 1205350 283244     cutoff   51       445.48191  301.06708  32.4%   9.0  115s
 1277005 296354  409.77813   99   25  445.48191  303.43246  31.9%   8.9  120s
 1295179 299407  308.09348   50   59  445.48191  303.96671  31.8%   8.8  125s
 1364467 310321  389.07254   70   44  445.48191  306.13887  31.3%   8.7  130s
 1437749 321847  427.35728   75   40  445.48191  308.30507  30.8%   8.6  135s
 1509545 332813     cutoff   96       445.48191  310.35175  30.3%   8.5  140s
 1556958 339676  391.40076   47   61  445.48191  311.69387  30.0%   8.5  145s
 1614026 347712     cutoff   59       445.48191  313.21877  29.7%   8.4  150s
 1687179 357838  431.02949   65   57  445.48191  315.10955  29.3%   8.3  155s
 1736124 364210  426.33706   56   48  445.48191  316.32258  29.0%   8.2  160s
 1794200 371398  356.16970   57   52  445.48191  317.84474  28.7%   8.2  165s
 1868197 380116  363.76131   60   53  445.48191  319.77771  28.2%   8.1  170s
 1930583 387766  417.34618  105   20  445.48191  321.32626  27.9%   8.0  175s
 1997509 395644  432.48732   63   48  445.48191  322.96440  27.5%   8.0  180s
 2040734 400436     cutoff   69       445.48191  324.00559  27.3%   7.9  186s
 2086170 405414  410.12998   89   25  445.48191  325.15444  27.0%   7.9  190s
 2160593 412991     cutoff  104       445.48191  326.92208  26.6%   7.8  195s
 2206850 417538     cutoff   73       445.48191  328.10319  26.3%   7.8  200s
 2276756 423994  424.82529   63   56  445.48191  329.80137  26.0%   7.7  205s
 2350644 430173  398.07230   40   62  445.48191  331.62291  25.6%   7.7  210s
 2360691 431184  423.25986   80   36  445.48191  331.88979  25.5%   7.7  215s
 2433794 437516     cutoff   87       445.48191  333.70760  25.1%   7.6  220s
 2495023 442525  348.54783   58   54  445.48191  335.16372  24.8%   7.6  226s
 2550202 446791  345.24491   36   66  445.48191  336.51236  24.5%   7.6  230s
 2606661 450881  388.37704   62   48  445.48191  337.87352  24.2%   7.5  235s
 2636616 452909  393.87006   85   32  445.48191  338.58491  24.0%   7.5  240s
 2710483 457134  361.87971   68   45  445.48191  340.33560  23.6%   7.5  245s
 2770931 460421     cutoff   74       445.48191  341.76414  23.3%   7.5  251s
 2824985 463589  382.34338   64   48  445.48191  343.04310  23.0%   7.4  255s
 2859600 465414     cutoff   94       445.48191  343.85880  22.8%   7.4  260s
 2934337 469075  393.79037   60   54  445.48191  345.61349  22.4%   7.4  265s
 2981539 471296     cutoff   37       445.48191  346.72048  22.2%   7.3  270s
 3042214 473864     cutoff   54       445.48191  348.09053  21.9%   7.3  279s
 3052793 474618     cutoff   89       445.48191  348.31927  21.8%   7.3  280s
 3126062 477300     cutoff  101       445.48191  350.02904  21.4%   7.3  285s
 3198264 479850  398.44067   53   68  445.48191  351.67045  21.1%   7.2  290s
 3271966 482301     cutoff   72       445.48191  353.30248  20.7%   7.2  295s
 3303268 483263  410.36760   73   56  445.48191  353.99128  20.5%   7.2  300s
 3375966 485212  407.42259   81   40  445.48191  355.65586  20.2%   7.2  305s
 3428943 485037     cutoff   85       445.48191  356.89668  19.9%   7.2  310s
 3481823 484386     cutoff   59       445.48191  358.14263  19.6%   7.1  315s
 3546740 483697     cutoff  100       445.48191  359.64233  19.3%   7.1  323s
 3567835 483153  433.14074   86   35  445.48191  360.12974  19.2%   7.1  325s
 3641779 481611  389.95173   69   40  445.48191  361.84119  18.8%   7.1  330s
 3715013 479726     cutoff   97       445.48191  363.53753  18.4%   7.0  335s
 3741005 478964  382.61970   54   53  445.48191  364.15993  18.3%   7.0  340s
 3810389 476500     cutoff   70       445.48191  365.77210  17.9%   7.0  345s
 3879486 473407     cutoff   54       445.48191  367.41369  17.5%   7.0  350s
 3934793 470826     cutoff   71       445.48191  368.67318  17.2%   7.0  355s
 3976518 468635     cutoff   64       445.48191  369.65939  17.0%   6.9  361s
 4017121 466045     cutoff   95       445.48191  370.66575  16.8%   6.9  365s
 4092084 460850  389.44404   57   54  445.48191  372.42697  16.4%   6.9  370s
 4156730 456547  374.00813   54   53  445.48191  373.91747  16.1%   6.9  378s
 4181805 454624  423.79686   94   20  445.48191  374.53005  15.9%   6.9  380s
 4253386 449293     cutoff   64       445.48191  376.20174  15.6%   6.8  385s
 4325983 443172  402.61970   73   40  445.48191  377.90752  15.2%   6.8  390s
 4374664 438658  383.91777   82   47  445.48191  379.03841  14.9%   6.8  395s
 4449496 431288     cutoff   71       445.48191  380.83072  14.5%   6.8  400s
 4518613 424504     cutoff   56       445.48191  382.43181  14.2%   6.8  407s
 4555112 420467     cutoff  105       445.48191  383.28748  14.0%   6.7  410s
 4631016 411655     cutoff   98       445.48191  385.05717  13.6%   6.7  415s
 4697066 403684     cutoff   57       445.48191  386.59815  13.2%   6.7  424s
 4710970 401699     cutoff   48       445.48191  386.94795  13.1%   6.7  425s
 4784170 392341  421.51199   93   27  445.48191  388.61108  12.8%   6.7  430s
 4855874 382185     cutoff   91       445.48191  390.30779  12.4%   6.6  435s
 4933040 370885     cutoff   68       445.48191  392.13191  12.0%   6.6  440s
 4958792 366717     cutoff   95       445.48191  392.73906  11.8%   6.6  445s
 5035427 354237     cutoff   96       445.48191  394.60011  11.4%   6.6  450s
 5107775 341196     cutoff   95       445.48191  396.37438  11.0%   6.5  455s
 5186953 326354     cutoff   82       445.48191  398.27610  10.6%   6.5  460s
 5206914 322451  434.08947   90   16  445.48191  398.78285  10.5%   6.5  466s
 5259419 311377     cutoff   91       445.48191  400.11919  10.2%   6.5  470s
 5336205 294883     cutoff   59       445.48191  402.07711  9.74%   6.4  475s
 5410081 277698  437.37258   86   27  445.48191  404.06399  9.30%   6.4  480s
 5450057 267657     cutoff   72       445.48191  405.19839  9.04%   6.4  489s
 5463078 264085     cutoff   91       445.48191  405.57196  8.96%   6.4  490s
 5542978 243220     cutoff   69       445.48191  407.87405  8.44%   6.4  495s
 5615741 223307  445.26147   48   56  445.48191  410.02555  7.96%   6.3  500s
 5694300 200445  416.78973   82   39  445.48191  412.49522  7.40%   6.3  505s
 5772062 175768  421.35793   86   33  445.48191  415.16450  6.81%   6.3  510s
 5846864 150341     cutoff   65       445.48191  417.96646  6.18%   6.2  515s
 5872529 141831  433.60800   67   47  445.48191  419.01354  5.94%   6.2  520s
 5940053 116508  423.82359   65   52  445.48191  422.05028  5.26%   6.2  530s

Explored 5964988 nodes (36896433 simplex iterations) in 532.27 seconds (487.06 work units)
Thread count was 16 (of 48 available processors)

Solution count 10: 445.482 450.892 454.896 ... 790.109

Optimal solution found (tolerance 5.00e-02)
Best objective 4.454819134099e+02, best bound 4.232603644500e+02, gap 4.9882%

Gurobi MIQP converged to an optimal solution.
Cluster Assignments from Gurobi MIQP using MSE
############################################################################

Ridge Regression using scikit-learn:
Optimal weights w* in X Space (including bias):
[ 3.46802161e-01 -1.22582674e-04  6.60020338e-04 -1.06923779e-04]

Mean Squared Error on training data (scikit-learn) with lambda = 0.1:
118.75994908104339
Cluster assignments:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 1 2 1 1 2 1 2 2 2 2 1
 2 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 1 1 2 1 1 1 2 1]
-----------------------------------
Regression weights for cluster 0: y = -0.9528x_0 + -0.9725x_1 + -1.0889x_2 + -11.5629
Regression weights for cluster 0 after refit: y = -0.9469x_1 + -0.9686x_2 + -1.0829x_3 + -11.5819
-----------------------------------
Regression weights for cluster 1: y = -0.4034x_0 + 0.293x_1 + -0.7723x_2 + 11.4529
Regression weights for cluster 1 after refit: y = -0.4073x_1 + 0.2872x_2 + -0.7751x_3 + 11.4696
-----------------------------------
Regression weights for cluster 2: y = 0.6828x_0 + 2.4939x_1 + -0.2444x_2 + 1.8835
Regression weights for cluster 2 after refit: y = 0.6825x_1 + 2.494x_2 + -0.2456x_3 + 1.8856
{'time_milp': 533.0702381134033, 'time_greedy': np.float64(0.5323353171348572), 'time_refit_milp_assignment': 536.1652104854584, 'mse_refit_ground_truth_assignment': np.float64(6.8743715874323605), 'r2_refit_ground_truth_assignment': 0.9425046213038966, 'weight_mismatch_refit_ground_truth_assignment': np.float64(4.328369204907481), 'refit-weight_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'rand_score_refit_ground_truth_assignment': 1.0, 'label_mismatch_refit_ground_truth_assignment': np.float64(0.0), 'mse_milp': np.float64(4.800142257472197), 'r2_milp': 0.9598529126075921, 'weight_mismatch_milp': np.float64(5.566500174515555), 'refit-weight_mismatch_milp': np.float64(1.8830009116870026), 'rand_score_milp': np.float64(0.8137715179968701), 'label_mismatch_milp': np.float64(0.19444444444444445), 'mse_refit_milp_assignment': np.float64(4.800086488566392), 'r2_refit_milp_assignment': 0.9598533790435881, 'weight_mismatch_refit_milp_assignment': np.float64(5.603589571903566), 'refit-weight_mismatch_refit_milp_assignment': np.float64(1.8742962583595313), 'rand_score_refit_milp_assignment': np.float64(0.8137715179968701), 'label_mismatch_refit_milp_assignment': np.float64(0.19444444444444445), 'mse_greedy': np.float64(9.985870151495883), 'r2_greedy': np.float64(0.916480891574146), 'weight_mismatch_greedy': np.float64(15.984525976838674), 'refit-weight_mismatch_greedy': np.float64(14.541298405274773), 'rand_score_greedy': np.float64(0.7405907668231613), 'label_mismatch_greedy': np.float64(0.31875000000000003), 'mse_greedy_sem': np.float64(1.8558243518232773), 'r2_greedy_sem': np.float64(0.01552161132758666), 'weight_mismatch_greedy_sem': np.float64(2.7286198554789256), 'refit-weight_mismatch_greedy_sem': np.float64(2.9714734499201163), 'rand_score_greedy_sem': np.float64(0.018948427733542602), 'label_mismatch_greedy_sem': np.float64(0.02868537387134864), 'mse_ground_truth': np.float64(9.4429562644153), 'r2_ground_truth': np.float64(0.9242688874376752), 'weight_mismatch_ground_truth': 0, 'rand_score_ground_truth': 1, 'label_mismatch_ground_truth': 0, 'mse_baseline_sklearn': np.float64(118.75994908104339), 'r2_baseline_sklearn': np.float64(0.00672400967854514), 'mse_milp_val': np.float64(10.392425076472412), 'r2_milp_val': 0.9214792313610322, 'label_mismatch_milp_val': np.float64(0.10416666666666667), 'mse_refit_milp_assignment_val': np.float64(10.38814779648648), 'r2_refit_milp_assignment_val': 0.921511548679628, 'label_mismatch_refit_milp_assignment_val': np.float64(0.10416666666666667), 'mse_greedy_val': np.float64(35.37055989375721), 'label_mismatch_greedy_val': np.float64(0.25520833333333337), 'mse_greedy_val_sem': np.float64(7.8612854345580985), 'label_mismatch_greedy_val_sem': np.float64(0.03498756436346661), 'r2_greedy_val': np.float64(0.7327550086133319), 'r2_greedy_val_sem': np.float64(0.05939654799237202), 'mse_refit_ground_truth_assignment_val': np.float64(14.749966894332943), 'r2_refit_ground_truth_assignment_val': 0.8885554883080782, 'label_mismatch_refit_ground_truth_assignment_val': np.float64(0.25), 'mse_ground_truth_val': np.float64(16.176709969861335), 'r2_ground_truth_val': 0.8777756210377874, 'label_mismatch_ground_truth_val': np.float64(0.25), 'mse_baseline_sklearn_val': np.float64(132.39725165250834), 'r2_baseline_sklearn_val': -0.0003376390922789074}
