{"time_milp": 948.2351381778717, "time_greedy": 0.47465436458587645, "time_refit_milp_assignment": 950.9928805828094, "mse_refit_ground_truth_assignment": 0.3051995868865047, "r2_refit_ground_truth_assignment": 0.9973323032462322, "weight_mismatch_refit_ground_truth_assignment": 0.7748233967843747, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.9827464653632, "r2_milp": 0.9651875026269926, "weight_mismatch_milp": 7.637901598062768, "refit-weight_mismatch_milp": 7.8806203193918725, "rand_score_milp": 0.7562597809076682, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 3.982693557082806, "r2_refit_milp_assignment": 0.9651879650891122, "weight_mismatch_refit_milp_assignment": 7.66310238817317, "refit-weight_mismatch_refit_milp_assignment": 7.874597050016927, "rand_score_refit_milp_assignment": 0.7562597809076682, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 4.244855658792644, "r2_greedy": 0.9628964515427576, "weight_mismatch_greedy": 9.54156111727453, "refit-weight_mismatch_greedy": 9.216098007854942, "rand_score_greedy": 0.8462832550860719, "label_mismatch_greedy": 0.2013888888888889, "mse_greedy_sem": 1.4464703760684718, "r2_greedy_sem": 0.012643347148743144, "weight_mismatch_greedy_sem": 2.7068975346370125, "refit-weight_mismatch_greedy_sem": 2.772018387502542, "rand_score_greedy_sem": 0.0322480345697542, "label_mismatch_greedy_sem": 0.04589310297402863, "mse_ground_truth": 0.3803030573427974, "r2_ground_truth": 0.9965760585273404, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.08726573953972, "r2_baseline_sklearn": 0.029005441254059017, "mse_milp_val": 14.1349749338653, "r2_milp_val": 0.866231408850714, "label_mismatch_milp_val": 0.2708333333333333, "mse_refit_milp_assignment_val": 14.169589611198864, "r2_refit_milp_assignment_val": 0.8659038273274597, "label_mismatch_refit_milp_assignment_val": 0.2708333333333333, "mse_greedy_val": 6.922308359810441, "label_mismatch_greedy_val": 0.20104166666666665, "mse_greedy_val_sem": 2.9006880436777376, "label_mismatch_greedy_val_sem": 0.04396810193280009, "r2_greedy_val": 0.9344896300753787, "r2_greedy_val_sem": 0.027451124234872806, "mse_refit_ground_truth_assignment_val": 0.38569782915324075, "r2_refit_ground_truth_assignment_val": 0.9963498870386, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 0.37095950016151785, "r2_ground_truth_val": 0.9964893655671676, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 106.34431872819236, "r2_baseline_sklearn_val": -0.006406432240545268}