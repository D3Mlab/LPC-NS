{"time_milp": 1074.1248989105225, "time_greedy": 0.41515896320343015, "time_refit_milp_assignment": 1076.5981736183167, "mse_refit_ground_truth_assignment": 0.6866990704946357, "r2_refit_ground_truth_assignment": 0.9939846209144597, "weight_mismatch_refit_ground_truth_assignment": 1.1622350951670897, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.218205273083058, "r2_milp": 0.9630491653935946, "weight_mismatch_milp": 19.198925466137727, "refit-weight_mismatch_milp": 19.058917677871413, "rand_score_milp": 0.7562597809076682, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 4.218152301199087, "r2_refit_milp_assignment": 0.9630496294192161, "weight_mismatch_refit_milp_assignment": 19.22978764635494, "refit-weight_mismatch_refit_milp_assignment": 19.058140863688966, "rand_score_refit_milp_assignment": 0.7562597809076682, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 4.869987632559148, "r2_greedy": 0.9573396513692165, "weight_mismatch_greedy": 12.314254160038017, "refit-weight_mismatch_greedy": 11.725993618479892, "rand_score_greedy": 0.8421165884194053, "label_mismatch_greedy": 0.20763888888888887, "mse_greedy_sem": 1.4177062401769798, "r2_greedy_sem": 0.012418890359728797, "weight_mismatch_greedy_sem": 3.608573168464832, "refit-weight_mismatch_greedy_sem": 3.7066122182387553, "rand_score_greedy_sem": 0.03254125504274634, "label_mismatch_greedy_sem": 0.0474803210663534, "mse_ground_truth": 0.8556818790212939, "r2_ground_truth": 0.9923040528609511, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.8737888343771, "r2_baseline_sklearn": 0.02876252619868347, "mse_milp_val": 14.287740979308788, "r2_milp_val": 0.8655866383306882, "label_mismatch_milp_val": 0.25, "mse_refit_milp_assignment_val": 14.322460040454857, "r2_refit_milp_assignment_val": 0.8652600152676438, "label_mismatch_refit_milp_assignment_val": 0.25, "mse_greedy_val": 9.344191859477798, "label_mismatch_greedy_val": 0.2010416666666667, "mse_greedy_val_sem": 3.6398124075296825, "label_mismatch_greedy_val_sem": 0.043049291541127396, "r2_greedy_val": 0.9120935743632028, "r2_greedy_val_sem": 0.03424190165892861, "mse_refit_ground_truth_assignment_val": 0.8532561273894804, "r2_refit_ground_truth_assignment_val": 0.991972907080731, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 0.8204213039419278, "r2_ground_truth_val": 0.9922818039879325, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 107.02164561949185, "r2_baseline_sklearn_val": -0.006816905480715452}