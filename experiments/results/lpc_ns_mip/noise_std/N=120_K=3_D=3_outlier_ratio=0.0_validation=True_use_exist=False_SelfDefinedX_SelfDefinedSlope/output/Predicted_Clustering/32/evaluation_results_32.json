{"time_milp": 6906.768190145493, "time_greedy": 0.5631778955459594, "time_refit_milp_assignment": 6909.809595108032, "mse_refit_ground_truth_assignment": 0.3005062865495554, "r2_refit_ground_truth_assignment": 0.9972826670646654, "weight_mismatch_refit_ground_truth_assignment": 1.0933248437008063, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.166691463487817, "r2_milp": 0.9623226253429952, "weight_mismatch_milp": 7.815097686870379, "refit-weight_mismatch_milp": 8.36189053275979, "rand_score_milp": 0.8110328638497653, "label_mismatch_milp": 0.16666666666666666, "mse_refit_milp_assignment": 4.166640390712128, "r2_refit_milp_assignment": 0.9623230871693919, "weight_mismatch_refit_milp_assignment": 7.80291628478062, "refit-weight_mismatch_refit_milp_assignment": 8.391002001050966, "rand_score_refit_milp_assignment": 0.8110328638497653, "label_mismatch_refit_milp_assignment": 0.16666666666666666, "mse_greedy": 2.478771345492246, "r2_greedy": 0.9775856701914325, "weight_mismatch_greedy": 8.901427777051959, "refit-weight_mismatch_greedy": 8.528652154145743, "rand_score_greedy": 0.851349765258216, "label_mismatch_greedy": 0.16250000000000003, "mse_greedy_sem": 0.6751930745766495, "r2_greedy_sem": 0.006105444249847271, "weight_mismatch_greedy_sem": 2.3111793246011683, "refit-weight_mismatch_greedy_sem": 2.412529250520821, "rand_score_greedy_sem": 0.025194164484378802, "label_mismatch_greedy_sem": 0.030513993530339328, "mse_ground_truth": 0.33444675478477953, "r2_ground_truth": 0.9969996849088374, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 102.88011505141839, "r2_baseline_sklearn": 0.06970490291514198, "mse_milp_val": 7.398299631937404, "r2_milp_val": 0.9343133955278737, "label_mismatch_milp_val": 0.1875, "mse_refit_milp_assignment_val": 7.40463811594887, "r2_refit_milp_assignment_val": 0.9342571186111593, "label_mismatch_refit_milp_assignment_val": 0.1875, "mse_greedy_val": 5.759033756859418, "label_mismatch_greedy_val": 0.16875, "mse_greedy_val_sem": 1.8976531810119457, "label_mismatch_greedy_val_sem": 0.03297158421272893, "r2_greedy_val": 0.9488677951220821, "r2_greedy_val_sem": 0.0168485192716859, "mse_refit_ground_truth_assignment_val": 0.7868967865141002, "r2_refit_ground_truth_assignment_val": 0.9930134516648925, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 0.8385099042465719, "r2_ground_truth_val": 0.9925551990097241, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 112.9111850501833, "r2_baseline_sklearn_val": -0.0024941840491823353}