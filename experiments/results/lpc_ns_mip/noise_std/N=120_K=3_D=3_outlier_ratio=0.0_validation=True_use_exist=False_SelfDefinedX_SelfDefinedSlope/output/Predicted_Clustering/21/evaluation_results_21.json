{"time_milp": 23154.75282883644, "time_greedy": 0.4873032093048096, "time_refit_milp_assignment": 23157.52032136917, "mse_refit_ground_truth_assignment": 0.07382151906129344, "r2_refit_ground_truth_assignment": 0.9993407141388344, "weight_mismatch_refit_ground_truth_assignment": 0.43346971489703756, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.212911464443844, "r2_milp": 0.9623752938415674, "weight_mismatch_milp": 9.419127052166399, "refit-weight_mismatch_milp": 9.314489332606232, "rand_score_milp": 0.7914710485133021, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 4.212856262791661, "r2_refit_milp_assignment": 0.9623757868369603, "weight_mismatch_refit_milp_assignment": 9.416308044254539, "refit-weight_mismatch_refit_milp_assignment": 9.294209187909154, "rand_score_refit_milp_assignment": 0.7914710485133021, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 4.334445756366231, "r2_greedy": 0.9612898943357042, "weight_mismatch_greedy": 10.10375067052349, "refit-weight_mismatch_greedy": 9.820701274125346, "rand_score_greedy": 0.850547730829421, "label_mismatch_greedy": 0.18333333333333335, "mse_greedy_sem": 1.6214495555443238, "r2_greedy_sem": 0.014480855720078584, "weight_mismatch_greedy_sem": 2.889855843309837, "refit-weight_mismatch_greedy_sem": 2.9132995403989836, "rand_score_greedy_sem": 0.037262243699089904, "label_mismatch_greedy_sem": 0.0482978629004818, "mse_ground_truth": 0.09390307696845931, "r2_ground_truth": 0.9991623742428336, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 102.64524957281598, "r2_baseline_sklearn": 0.0832949169877677, "mse_milp_val": 6.343828526119688, "r2_milp_val": 0.9435109345438839, "label_mismatch_milp_val": 0.1875, "mse_refit_milp_assignment_val": 6.354084277201082, "r2_refit_milp_assignment_val": 0.9434196114900288, "label_mismatch_refit_milp_assignment_val": 0.1875, "mse_greedy_val": 15.489367694404894, "label_mismatch_greedy_val": 0.15625000000000003, "mse_greedy_val_sem": 6.546609800903028, "label_mismatch_greedy_val_sem": 0.04397394646647327, "r2_greedy_val": 0.8620738404323982, "r2_greedy_val_sem": 0.05829474552097706, "mse_refit_ground_truth_assignment_val": 0.14097364764104608, "r2_refit_ground_truth_assignment_val": 0.998744690280263, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.10251270002080028, "r2_ground_truth_val": 0.999087168482295, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 112.31966730566194, "r2_baseline_sklearn_val": -0.00015834480943111018}