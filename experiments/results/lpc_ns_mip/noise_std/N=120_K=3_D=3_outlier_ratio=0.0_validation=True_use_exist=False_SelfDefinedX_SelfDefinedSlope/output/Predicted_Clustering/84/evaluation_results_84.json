{"time_milp": 46.25495171546936, "time_greedy": 0.470116651058197, "time_refit_milp_assignment": 49.00260591506958, "mse_refit_ground_truth_assignment": 1.2002476338506205, "r2_refit_ground_truth_assignment": 0.9890648950494658, "weight_mismatch_refit_ground_truth_assignment": 1.8483010525302035, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.1815144366045909, "r2_milp": 0.9892355677274758, "weight_mismatch_milp": 2.283309885693374, "refit-weight_mismatch_milp": 0.683011569734348, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 1.1814708357407493, "r2_refit_milp_assignment": 0.9892359649621868, "weight_mismatch_refit_milp_assignment": 2.2842393983130176, "refit-weight_mismatch_refit_milp_assignment": 0.6672093591660432, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 4.970080217915209, "r2_greedy": 0.9547190535830368, "weight_mismatch_greedy": 10.263509499766194, "refit-weight_mismatch_greedy": 9.418589873330788, "rand_score_greedy": 0.8300273865414711, "label_mismatch_greedy": 0.19027777777777777, "mse_greedy_sem": 1.4783641274678547, "r2_greedy_sem": 0.013468942935635804, "weight_mismatch_greedy_sem": 2.69004423692215, "refit-weight_mismatch_greedy_sem": 2.796855148500969, "rand_score_greedy_sem": 0.02724380175883068, "label_mismatch_greedy_sem": 0.03642882055271072, "mse_ground_truth": 1.5204646338667667, "r2_ground_truth": 0.9865357571208291, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.6796389801541, "r2_baseline_sklearn": 0.0007409059937749651, "mse_milp_val": 2.2469454283450476, "r2_milp_val": 0.9808920079823625, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 2.256098139269231, "r2_refit_milp_assignment_val": 0.9808141734586251, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 13.39169308265069, "label_mismatch_greedy_val": 0.240625, "mse_greedy_val_sem": 4.7529227494131066, "label_mismatch_greedy_val_sem": 0.03257340310609686, "r2_greedy_val": 0.8861172321775472, "r2_greedy_val_sem": 0.04041878757292496, "mse_refit_ground_truth_assignment_val": 2.3244537748445246, "r2_refit_ground_truth_assignment_val": 0.9802328781042937, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 1.6010751244924715, "r2_ground_truth_val": 0.9863844798754311, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 117.72884729884582, "r2_baseline_sklearn_val": -0.0011644457644395256}