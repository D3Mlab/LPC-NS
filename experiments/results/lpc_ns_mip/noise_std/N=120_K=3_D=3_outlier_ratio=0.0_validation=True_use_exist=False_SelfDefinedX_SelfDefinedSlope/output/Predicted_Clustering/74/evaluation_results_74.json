{"time_milp": 374.4815893173218, "time_greedy": 0.4716342568397522, "time_refit_milp_assignment": 377.2228190898895, "mse_refit_ground_truth_assignment": 0.8378699519751347, "r2_refit_ground_truth_assignment": 0.9929931378984134, "weight_mismatch_refit_ground_truth_assignment": 1.2145567497184728, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.1055268684171926, "r2_milp": 0.9740293843114005, "weight_mismatch_milp": 7.444080236544887, "refit-weight_mismatch_milp": 6.806552493682446, "rand_score_milp": 0.8039906103286385, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 3.1054790976610733, "r2_refit_milp_assignment": 0.9740297838043049, "weight_mismatch_refit_milp_assignment": 7.420553122854582, "refit-weight_mismatch_refit_milp_assignment": 6.805975771708874, "rand_score_refit_milp_assignment": 0.8039906103286385, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 6.328041224573753, "r2_greedy": 0.9470804363741407, "weight_mismatch_greedy": 14.662304996661613, "refit-weight_mismatch_greedy": 14.294568180259057, "rand_score_greedy": 0.8016236306729265, "label_mismatch_greedy": 0.22777777777777777, "mse_greedy_sem": 1.8036294957430032, "r2_greedy_sem": 0.015083227569187915, "weight_mismatch_greedy_sem": 3.1428633767268015, "refit-weight_mismatch_greedy_sem": 3.1919546357092474, "rand_score_greedy_sem": 0.028877506323069707, "label_mismatch_greedy_sem": 0.03887322157251185, "mse_ground_truth": 1.2052021831326, "r2_ground_truth": 0.9895252573764585, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 118.43466883368855, "r2_baseline_sklearn": 0.009565397818006027, "mse_milp_val": 9.061826794332402, "r2_milp_val": 0.9160232961102971, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 9.064642661026612, "r2_refit_milp_assignment_val": 0.9159972012390377, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 17.67041269211248, "label_mismatch_greedy_val": 0.215625, "mse_greedy_val_sem": 6.0783729024495115, "label_mismatch_greedy_val_sem": 0.033226081567723706, "r2_greedy_val": 0.8362468133707359, "r2_greedy_val_sem": 0.05632878810699029, "mse_refit_ground_truth_assignment_val": 1.7747801465212802, "r2_refit_ground_truth_assignment_val": 0.9835529645162765, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 1.6973311228685357, "r2_ground_truth_val": 0.9842706910711364, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 108.52664119301117, "r2_baseline_sklearn_val": -0.0057254258390355695}