{"time_milp": 400.9509484767914, "time_greedy": 0.4848882079124451, "time_refit_milp_assignment": 403.69480991363525, "mse_refit_ground_truth_assignment": 0.357462924773666, "r2_refit_ground_truth_assignment": 0.99675154068014, "weight_mismatch_refit_ground_truth_assignment": 0.49049575085896346, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.0515075043851376, "r2_milp": 0.9813568395195051, "weight_mismatch_milp": 3.4804517964211326, "refit-weight_mismatch_milp": 3.0514198834065316, "rand_score_milp": 0.912754303599374, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 2.0514700742230336, "r2_refit_milp_assignment": 0.981357179667673, "weight_mismatch_refit_milp_assignment": 3.4827446901403434, "refit-weight_mismatch_refit_milp_assignment": 3.0515697891050872, "rand_score_refit_milp_assignment": 0.912754303599374, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 6.410727559693987, "r2_greedy": 0.9417422444535845, "weight_mismatch_greedy": 13.299816073330865, "refit-weight_mismatch_greedy": 13.136478861694238, "rand_score_greedy": 0.7968505477308294, "label_mismatch_greedy": 0.25833333333333336, "mse_greedy_sem": 1.7629808471482538, "r2_greedy_sem": 0.01602116238286659, "weight_mismatch_greedy_sem": 2.975982689526744, "refit-weight_mismatch_greedy_sem": 2.9985943183028314, "rand_score_greedy_sem": 0.036285058297240894, "label_mismatch_greedy_sem": 0.04737248195718296, "mse_ground_truth": 0.3556824554941374, "r2_ground_truth": 0.9967992192488507, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 104.95372161311866, "r2_baseline_sklearn": 0.04622865337994819, "mse_milp_val": 1.5616247948359032, "r2_milp_val": 0.9861430781762767, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.5635973576987479, "r2_refit_milp_assignment_val": 0.9861255748365031, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 14.172084315973436, "label_mismatch_greedy_val": 0.2520833333333333, "mse_greedy_val_sem": 4.596401572920048, "label_mismatch_greedy_val_sem": 0.04452632032578468, "r2_greedy_val": 0.8742454236798312, "r2_greedy_val_sem": 0.04078571080390982, "mse_refit_ground_truth_assignment_val": 0.3489489494309548, "r2_refit_ground_truth_assignment_val": 0.9969036363096148, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.33292609510969745, "r2_ground_truth_val": 0.9970458135089374, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 112.78653661298917, "r2_baseline_sklearn_val": -0.0008000806486496703}