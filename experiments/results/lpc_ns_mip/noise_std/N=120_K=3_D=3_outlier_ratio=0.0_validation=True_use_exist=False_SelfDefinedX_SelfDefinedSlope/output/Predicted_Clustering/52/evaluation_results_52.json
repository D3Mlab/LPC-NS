{"time_milp": 239.7460436820984, "time_greedy": 0.5354137778282165, "time_refit_milp_assignment": 242.83075523376465, "mse_refit_ground_truth_assignment": 0.34103789289072545, "r2_refit_ground_truth_assignment": 0.9971055314040287, "weight_mismatch_refit_ground_truth_assignment": 1.055639110158656, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.1959661655000273, "r2_milp": 0.9728750854592259, "weight_mismatch_milp": 4.325674139710802, "refit-weight_mismatch_milp": 4.163981297167791, "rand_score_milp": 0.8227699530516432, "label_mismatch_milp": 0.16666666666666666, "mse_refit_milp_assignment": 3.1959239710643303, "r2_refit_milp_assignment": 0.9728754435732994, "weight_mismatch_refit_milp_assignment": 4.318603337499356, "refit-weight_mismatch_refit_milp_assignment": 4.148472105026741, "rand_score_refit_milp_assignment": 0.8227699530516432, "label_mismatch_refit_milp_assignment": 0.16666666666666666, "mse_greedy": 7.826757110229512, "r2_greedy": 0.9335724764429237, "weight_mismatch_greedy": 14.766663832058345, "refit-weight_mismatch_greedy": 14.507940825522656, "rand_score_greedy": 0.7869131455399061, "label_mismatch_greedy": 0.26111111111111107, "mse_greedy_sem": 1.9393439619002275, "r2_greedy_sem": 0.016459667126507187, "weight_mismatch_greedy_sem": 2.8278046699471746, "refit-weight_mismatch_greedy_sem": 2.8935359369859635, "rand_score_greedy_sem": 0.033841628386676384, "label_mismatch_greedy_sem": 0.04395056366855408, "mse_ground_truth": 0.35177303712441155, "r2_ground_truth": 0.9968574845712448, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.18441708675033, "r2_baseline_sklearn": 0.06483900566090262, "mse_milp_val": 3.722663463145901, "r2_milp_val": 0.9638359611690357, "label_mismatch_milp_val": 0.0, "mse_refit_milp_assignment_val": 3.732550999079962, "r2_refit_milp_assignment_val": 0.9637399081046096, "label_mismatch_refit_milp_assignment_val": 0.0, "mse_greedy_val": 18.27794792592849, "label_mismatch_greedy_val": 0.209375, "mse_greedy_val_sem": 4.8402555657781745, "label_mismatch_greedy_val_sem": 0.04045595734436552, "r2_greedy_val": 0.8224377720179336, "r2_greedy_val_sem": 0.04702095474530746, "mse_refit_ground_truth_assignment_val": 0.36250525075611195, "r2_refit_ground_truth_assignment_val": 0.9964784208686718, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.2692891714893371, "r2_ground_truth_val": 0.9973839740951849, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 103.24258686142501, "r2_baseline_sklearn_val": -0.0029563395211065213}