{"time_milp": 77.81024956703186, "time_greedy": 0.4748310923576355, "time_refit_milp_assignment": 80.52270245552063, "mse_refit_ground_truth_assignment": 0.8034715565446301, "r2_refit_ground_truth_assignment": 0.9926580328947358, "weight_mismatch_refit_ground_truth_assignment": 1.5122463157059027, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.8145168385278276, "r2_milp": 0.9925571032522008, "weight_mismatch_milp": 1.953517987511324, "refit-weight_mismatch_milp": 0.6782949046552942, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 0.8144727048307676, "r2_refit_milp_assignment": 0.9925575065373569, "weight_mismatch_refit_milp_assignment": 1.9556984584347292, "refit-weight_mismatch_refit_milp_assignment": 0.6662310694169482, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 4.768443257717771, "r2_greedy": 0.9564268912118749, "weight_mismatch_greedy": 10.158319181200753, "refit-weight_mismatch_greedy": 9.40993521602999, "rand_score_greedy": 0.8326291079812206, "label_mismatch_greedy": 0.19930555555555557, "mse_greedy_sem": 1.4811894158427845, "r2_greedy_sem": 0.013534821337734938, "weight_mismatch_greedy_sem": 2.685285118588696, "refit-weight_mismatch_greedy_sem": 2.786047152539081, "rand_score_greedy_sem": 0.029412864029845786, "label_mismatch_greedy_sem": 0.038897698981172256, "mse_ground_truth": 1.0178316970513068, "r2_ground_truth": 0.9909466109262499, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.36176835230543, "r2_baseline_sklearn": 0.0006733912657668206, "mse_milp_val": 1.8134890673365358, "r2_milp_val": 0.9844766371391568, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 1.8232953109940997, "r2_refit_milp_assignment_val": 0.9843926962534133, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 12.045508588649177, "label_mismatch_greedy_val": 0.2385416666666667, "mse_greedy_val_sem": 4.580267321810285, "label_mismatch_greedy_val_sem": 0.03613104979796358, "r2_greedy_val": 0.8968911343151177, "r2_greedy_val_sem": 0.03920682672796574, "mse_refit_ground_truth_assignment_val": 1.6316438634760155, "r2_refit_ground_truth_assignment_val": 0.986033221700307, "label_mismatch_refit_ground_truth_assignment_val": 0.08333333333333333, "mse_ground_truth_val": 1.1603458811183287, "r2_ground_truth_val": 0.9900675055167883, "label_mismatch_ground_truth_val": 0.08333333333333333, "mse_baseline_sklearn_val": 116.96915633298488, "r2_baseline_sklearn_val": -0.0012492989276287059}