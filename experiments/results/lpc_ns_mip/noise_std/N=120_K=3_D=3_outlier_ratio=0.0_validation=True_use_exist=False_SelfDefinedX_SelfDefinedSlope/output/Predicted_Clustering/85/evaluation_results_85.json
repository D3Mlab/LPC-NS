{"time_milp": 47.77532410621643, "time_greedy": 0.4660806775093079, "time_refit_milp_assignment": 50.46339154243469, "mse_refit_ground_truth_assignment": 1.9442027787993519, "r2_refit_ground_truth_assignment": 0.9823965014485864, "weight_mismatch_refit_ground_truth_assignment": 2.352383157766655, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.8776941936240545, "r2_milp": 0.9829986936661661, "weight_mismatch_milp": 2.8000080888069565, "refit-weight_mismatch_milp": 0.7343164962750655, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 1.8776513566629471, "r2_refit_milp_assignment": 0.9829990815271398, "weight_mismatch_refit_milp_assignment": 2.7998766746933654, "refit-weight_mismatch_refit_milp_assignment": 0.7141653408128814, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 6.419447165731327, "r2_greedy": 0.9418760583437628, "weight_mismatch_greedy": 13.129503739141843, "refit-weight_mismatch_greedy": 12.234715429510402, "rand_score_greedy": 0.7942292644757434, "label_mismatch_greedy": 0.23888888888888887, "mse_greedy_sem": 1.4861289149833197, "r2_greedy_sem": 0.01345593602035621, "weight_mismatch_greedy_sem": 2.8505905712125967, "refit-weight_mismatch_greedy_sem": 2.9796350367831277, "rand_score_greedy_sem": 0.02541235154316509, "label_mismatch_greedy_sem": 0.0342674901866289, "mse_ground_truth": 2.4629013903957544, "r2_ground_truth": 0.9783699911490027, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 110.3495200490274, "r2_baseline_sklearn": 0.0008564757160426373, "mse_milp_val": 3.1545183119521467, "r2_milp_val": 0.9734741064540473, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 3.1628144210795583, "r2_refit_milp_assignment_val": 0.9734043456583259, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 16.039091204872395, "label_mismatch_greedy_val": 0.28541666666666665, "mse_greedy_val_sem": 5.062728509917925, "label_mismatch_greedy_val_sem": 0.029115713638888437, "r2_greedy_val": 0.8651295748506893, "r2_greedy_val_sem": 0.04257176032147881, "mse_refit_ground_truth_assignment_val": 3.4840202488895073, "r2_refit_ground_truth_assignment_val": 0.9707033717687328, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 2.272274643159038, "r2_ground_truth_val": 0.9808927673479555, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 119.0461696215085, "r2_baseline_sklearn_val": -0.001042222664855652}