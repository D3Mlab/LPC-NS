{"time_milp": 1508.8458235263824, "time_greedy": 0.5394968509674072, "time_refit_milp_assignment": 1511.9878723621368, "mse_refit_ground_truth_assignment": 2.3704910009681996, "r2_refit_ground_truth_assignment": 0.9796586314111567, "weight_mismatch_refit_ground_truth_assignment": 2.456328384357615, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.775029791753618, "r2_milp": 0.9590250960762576, "weight_mismatch_milp": 14.060746694148515, "refit-weight_mismatch_milp": 14.130885839955267, "rand_score_milp": 0.7265258215962441, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 4.774994757586109, "r2_refit_milp_assignment": 0.9590253967071878, "weight_mismatch_refit_milp_assignment": 14.06555776758913, "refit-weight_mismatch_refit_milp_assignment": 14.114861722536475, "rand_score_refit_milp_assignment": 0.7265258215962441, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 6.769102982632167, "r2_greedy": 0.9419137981416845, "weight_mismatch_greedy": 16.47166754019926, "refit-weight_mismatch_greedy": 15.658025800652727, "rand_score_greedy": 0.7416666666666666, "label_mismatch_greedy": 0.31805555555555554, "mse_greedy_sem": 1.3439007801822556, "r2_greedy_sem": 0.011532117652147116, "weight_mismatch_greedy_sem": 2.3782152314233627, "refit-weight_mismatch_greedy_sem": 2.468210146806964, "rand_score_greedy_sem": 0.022212676717895667, "label_mismatch_greedy_sem": 0.03343217557791662, "mse_ground_truth": 3.0153321382094176, "r2_ground_truth": 0.9744054535331084, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 108.2879659837833, "r2_baseline_sklearn": 0.07077249864581758, "mse_milp_val": 10.381140503773475, "r2_milp_val": 0.9132777337366749, "label_mismatch_milp_val": 0.3125, "mse_refit_milp_assignment_val": 10.394829082989139, "r2_refit_milp_assignment_val": 0.9131633816950012, "label_mismatch_refit_milp_assignment_val": 0.3125, "mse_greedy_val": 27.881838650143372, "label_mismatch_greedy_val": 0.2875, "mse_greedy_val_sem": 8.309519925860192, "label_mismatch_greedy_val_sem": 0.027522585090403104, "r2_greedy_val": 0.767079904712793, "r2_greedy_val_sem": 0.06941630346578129, "mse_refit_ground_truth_assignment_val": 5.7648923176317295, "r2_refit_ground_truth_assignment_val": 0.9518410788903849, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 4.350580707763831, "r2_ground_truth_val": 0.9636559953695225, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 119.74695679412775, "r2_baseline_sklearn_val": -0.0003455273096879541}