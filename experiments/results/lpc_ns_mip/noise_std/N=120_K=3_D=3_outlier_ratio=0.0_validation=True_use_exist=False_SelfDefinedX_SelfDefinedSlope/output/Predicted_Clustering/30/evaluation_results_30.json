{"time_milp": 1910.2644517421722, "time_greedy": 0.5272595405578613, "time_refit_milp_assignment": 1913.3092241287231, "mse_refit_ground_truth_assignment": 6.8982108367275305, "r2_refit_ground_truth_assignment": 0.9441425166669652, "weight_mismatch_refit_ground_truth_assignment": 4.190207243895252, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 7.155427744591786, "r2_milp": 0.9420597317994013, "weight_mismatch_milp": 14.167157198713504, "refit-weight_mismatch_milp": 16.41476421245455, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 7.155402252140778, "r2_refit_milp_assignment": 0.9420599382216448, "weight_mismatch_refit_milp_assignment": 14.148490753911851, "refit-weight_mismatch_refit_milp_assignment": 16.396993048244234, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 11.018379588242146, "r2_greedy": 0.910779915433948, "weight_mismatch_greedy": 21.674928332176307, "refit-weight_mismatch_greedy": 20.985126400270197, "rand_score_greedy": 0.7113849765258217, "label_mismatch_greedy": 0.35208333333333336, "mse_greedy_sem": 1.947155732925784, "r2_greedy_sem": 0.015766873682614438, "weight_mismatch_greedy_sem": 2.7324197688493412, "refit-weight_mismatch_greedy_sem": 2.8071416148694985, "rand_score_greedy_sem": 0.01990341108837589, "label_mismatch_greedy_sem": 0.030013719924239783, "mse_ground_truth": 8.77472085894159, "r2_ground_truth": 0.9303270075988742, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 116.11990806118966, "r2_baseline_sklearn": 0.059732156253080704, "mse_milp_val": 33.43619745189775, "r2_milp_val": 0.741944808444913, "label_mismatch_milp_val": 0.3125, "mse_refit_milp_assignment_val": 33.45617743097776, "r2_refit_milp_assignment_val": 0.7417906061814477, "label_mismatch_refit_milp_assignment_val": 0.3125, "mse_greedy_val": 42.422714167967534, "label_mismatch_greedy_val": 0.315625, "mse_greedy_val_sem": 10.09502277349146, "label_mismatch_greedy_val_sem": 0.024005959527506022, "r2_greedy_val": 0.6725883184937282, "r2_greedy_val_sem": 0.07791176132734697, "mse_refit_ground_truth_assignment_val": 12.484137165644155, "r2_refit_ground_truth_assignment_val": 0.903649438237857, "label_mismatch_refit_ground_truth_assignment_val": 0.16666666666666666, "mse_ground_truth_val": 9.876416476676178, "r2_ground_truth_val": 0.9237754068944872, "label_mismatch_ground_truth_val": 0.16666666666666666, "mse_baseline_sklearn_val": 129.6427547391103, "r2_baseline_sklearn_val": -0.000561919639921804}