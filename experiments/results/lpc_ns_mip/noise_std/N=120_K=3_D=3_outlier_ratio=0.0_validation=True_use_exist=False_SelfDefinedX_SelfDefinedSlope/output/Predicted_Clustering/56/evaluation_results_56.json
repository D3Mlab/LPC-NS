{"time_milp": 361.0501437187195, "time_greedy": 0.4763999700546265, "time_refit_milp_assignment": 363.77188539505005, "mse_refit_ground_truth_assignment": 2.737776417928324, "r2_refit_ground_truth_assignment": 0.9775011926668062, "weight_mismatch_refit_ground_truth_assignment": 2.9909774787860224, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.9986744571225423, "r2_milp": 0.9671392427775238, "weight_mismatch_milp": 4.85698205233668, "refit-weight_mismatch_milp": 4.548494115935333, "rand_score_milp": 0.8227699530516432, "label_mismatch_milp": 0.16666666666666666, "mse_refit_milp_assignment": 3.9986311629695686, "r2_refit_milp_assignment": 0.9671395985650892, "weight_mismatch_refit_milp_assignment": 4.857272107929646, "refit-weight_mismatch_refit_milp_assignment": 4.52195745161864, "rand_score_refit_milp_assignment": 0.8227699530516432, "label_mismatch_refit_milp_assignment": 0.16666666666666666, "mse_greedy": 9.141616328610565, "r2_greedy": 0.9248749959476159, "weight_mismatch_greedy": 15.327851275667086, "refit-weight_mismatch_greedy": 14.929841011203402, "rand_score_greedy": 0.7333724569640063, "label_mismatch_greedy": 0.3319444444444445, "mse_greedy_sem": 1.9305576976715075, "r2_greedy_sem": 0.015865154437407568, "weight_mismatch_greedy_sem": 2.476715908186776, "refit-weight_mismatch_greedy_sem": 2.6122348738673367, "rand_score_greedy_sem": 0.024240429878092228, "label_mismatch_greedy_sem": 0.03653735171267122, "mse_ground_truth": 2.823955770248749, "r2_ground_truth": 0.9753841821603813, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.34510818564951, "r2_baseline_sklearn": 0.06853980678282978, "mse_milp_val": 7.41180389555527, "r2_milp_val": 0.9287358380536673, "label_mismatch_milp_val": 0.041666666666666664, "mse_refit_milp_assignment_val": 7.420803404625572, "r2_refit_milp_assignment_val": 0.9286493081776936, "label_mismatch_refit_milp_assignment_val": 0.041666666666666664, "mse_greedy_val": 24.21497815155244, "label_mismatch_greedy_val": 0.275, "mse_greedy_val_sem": 6.252534509996676, "label_mismatch_greedy_val_sem": 0.04051590727961128, "r2_greedy_val": 0.7671740714087176, "r2_greedy_val_sem": 0.06011783881149962, "mse_refit_ground_truth_assignment_val": 3.491321156902192, "r2_refit_ground_truth_assignment_val": 0.9664311037045462, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 3.1776850855260306, "r2_ground_truth_val": 0.9694467004604407, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 104.46778425727943, "r2_baseline_sklearn_val": -0.00445305898471271}