{"time_milp": 440.94773387908936, "time_greedy": 0.4753021001815796, "time_refit_milp_assignment": 443.69889783859253, "mse_refit_ground_truth_assignment": 0.08500976756486096, "r2_refit_ground_truth_assignment": 0.9992351279490798, "weight_mismatch_refit_ground_truth_assignment": 0.49100539681925803, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.3211401017701745, "r2_milp": 0.9971105545243811, "weight_mismatch_milp": 1.1327568756507185, "refit-weight_mismatch_milp": 0.8402437346307917, "rand_score_milp": 0.9311424100156495, "label_mismatch_milp": 0.05555555555555555, "mse_refit_milp_assignment": 0.32110758557394703, "r2_refit_milp_assignment": 0.9971108470875819, "weight_mismatch_refit_milp_assignment": 1.1152635552240258, "refit-weight_mismatch_refit_milp_assignment": 0.8192695162288042, "rand_score_refit_milp_assignment": 0.9311424100156495, "label_mismatch_refit_milp_assignment": 0.05555555555555555, "mse_greedy": 3.340439714468494, "r2_greedy": 0.9699445246285181, "weight_mismatch_greedy": 7.870720606192376, "refit-weight_mismatch_greedy": 7.505430618409571, "rand_score_greedy": 0.8635954616588417, "label_mismatch_greedy": 0.1625, "mse_greedy_sem": 1.4330529167665589, "r2_greedy_sem": 0.01289383743683603, "weight_mismatch_greedy_sem": 2.228989101732747, "refit-weight_mismatch_greedy_sem": 2.247885649565866, "rand_score_greedy_sem": 0.027632187463727843, "label_mismatch_greedy_sem": 0.0384491111152008, "mse_ground_truth": 0.10451290827395981, "r2_ground_truth": 0.9990643520256753, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 106.78975678998275, "r2_baseline_sklearn": 0.03916334989492021, "mse_milp_val": 0.31353900024631814, "r2_milp_val": 0.9972138001784027, "label_mismatch_milp_val": 0.041666666666666664, "mse_refit_milp_assignment_val": 0.3143628536121156, "r2_refit_milp_assignment_val": 0.9972064791749582, "label_mismatch_refit_milp_assignment_val": 0.041666666666666664, "mse_greedy_val": 5.829631505889592, "label_mismatch_greedy_val": 0.17604166666666665, "mse_greedy_val_sem": 3.3843142532313526, "label_mismatch_greedy_val_sem": 0.04148741596532052, "r2_greedy_val": 0.9481961789476676, "r2_greedy_val_sem": 0.030074012359465822, "mse_refit_ground_truth_assignment_val": 0.15253625067031398, "r2_refit_ground_truth_assignment_val": 0.9986445179895616, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.10563745548623926, "r2_ground_truth_val": 0.9990612744845186, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 112.54815583843633, "r2_baseline_sklearn_val": -0.0001360324291477255}