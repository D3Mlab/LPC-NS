{"time_milp": 1323.7345235347748, "time_greedy": 0.5020861625671387, "time_refit_milp_assignment": 1326.4650180339813, "mse_refit_ground_truth_assignment": 4.940619955006483, "r2_refit_ground_truth_assignment": 0.9595318058182695, "weight_mismatch_refit_ground_truth_assignment": 2.219719065680709, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.3426424167663225, "r2_milp": 0.948047960117458, "weight_mismatch_milp": 6.953855044611307, "refit-weight_mismatch_milp": 6.330965819478903, "rand_score_milp": 0.844679186228482, "label_mismatch_milp": 0.1388888888888889, "mse_refit_milp_assignment": 6.342585587130908, "r2_refit_milp_assignment": 0.948048425604126, "weight_mismatch_refit_milp_assignment": 6.982341319488798, "refit-weight_mismatch_refit_milp_assignment": 6.361287674639774, "rand_score_refit_milp_assignment": 0.844679186228482, "label_mismatch_refit_milp_assignment": 0.1388888888888889, "mse_greedy": 10.440566343894147, "r2_greedy": 0.9144822168028114, "weight_mismatch_greedy": 20.817587791445906, "refit-weight_mismatch_greedy": 20.630544597729557, "rand_score_greedy": 0.7312597809076682, "label_mismatch_greedy": 0.3402777777777778, "mse_greedy_sem": 1.9939265638885906, "r2_greedy_sem": 0.016332081420224975, "weight_mismatch_greedy_sem": 2.797622535133843, "refit-weight_mismatch_greedy_sem": 2.9280764076407073, "rand_score_greedy_sem": 0.020168659512702785, "label_mismatch_greedy_sem": 0.031064671375492067, "mse_ground_truth": 5.782123013616688, "r2_ground_truth": 0.9527771516210041, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 114.62718269927898, "r2_baseline_sklearn": 0.06109858069966967, "mse_milp_val": 8.464434269981377, "r2_milp_val": 0.9310202868880426, "label_mismatch_milp_val": 0.1875, "mse_refit_milp_assignment_val": 8.47905776406688, "r2_refit_milp_assignment_val": 0.9309011147857451, "label_mismatch_refit_milp_assignment_val": 0.1875, "mse_greedy_val": 30.912188861168026, "label_mismatch_greedy_val": 0.3489583333333333, "mse_greedy_val_sem": 6.8229850801878, "label_mismatch_greedy_val_sem": 0.027863878803193645, "r2_greedy_val": 0.7480854772695036, "r2_greedy_val_sem": 0.055602954478321635, "mse_refit_ground_truth_assignment_val": 6.990675081627269, "r2_refit_ground_truth_assignment_val": 0.9430304795088663, "label_mismatch_refit_ground_truth_assignment_val": 0.14583333333333334, "mse_ground_truth_val": 6.78138653118054, "r2_ground_truth_val": 0.944736047029029, "label_mismatch_ground_truth_val": 0.14583333333333334, "mse_baseline_sklearn_val": 123.16757990285221, "r2_baseline_sklearn_val": -0.0037368187173048018}