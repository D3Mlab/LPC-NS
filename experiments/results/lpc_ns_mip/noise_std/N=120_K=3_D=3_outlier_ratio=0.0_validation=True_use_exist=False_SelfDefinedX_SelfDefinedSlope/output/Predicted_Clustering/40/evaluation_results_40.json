{"time_milp": 17533.92346572876, "time_greedy": 0.5476686477661132, "time_refit_milp_assignment": 17536.99721288681, "mse_refit_ground_truth_assignment": 7.0201607496715575, "r2_refit_ground_truth_assignment": 0.9419928244455562, "weight_mismatch_refit_ground_truth_assignment": 5.284403411278806, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 8.458404098900136, "r2_milp": 0.930108704206199, "weight_mismatch_milp": 14.736040040137226, "refit-weight_mismatch_milp": 12.556629766335691, "rand_score_milp": 0.7492175273865415, "label_mismatch_milp": 0.2638888888888889, "mse_refit_milp_assignment": 8.458366080268554, "r2_refit_milp_assignment": 0.9301090183519165, "weight_mismatch_refit_milp_assignment": 14.732030885707507, "refit-weight_mismatch_refit_milp_assignment": 12.588074805137234, "rand_score_refit_milp_assignment": 0.7492175273865415, "label_mismatch_refit_milp_assignment": 0.2638888888888889, "mse_greedy": 9.22284223963106, "r2_greedy": 0.9237921967911848, "weight_mismatch_greedy": 16.007701954981613, "refit-weight_mismatch_greedy": 15.467505996493426, "rand_score_greedy": 0.7487089201877934, "label_mismatch_greedy": 0.30416666666666664, "mse_greedy_sem": 1.4274699252292125, "r2_greedy_sem": 0.011795100070227549, "weight_mismatch_greedy_sem": 2.139194724151094, "refit-weight_mismatch_greedy_sem": 2.4509521444479057, "rand_score_greedy_sem": 0.01824958073138382, "label_mismatch_greedy_sem": 0.02751889598307598, "mse_ground_truth": 7.813047799277766, "r2_ground_truth": 0.9337096539235052, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 115.5917570555856, "r2_baseline_sklearn": 0.04487210716881729, "mse_milp_val": 15.814442207389485, "r2_milp_val": 0.8596560985385855, "label_mismatch_milp_val": 0.3125, "mse_refit_milp_assignment_val": 15.816096762646708, "r2_refit_milp_assignment_val": 0.8596414153308607, "label_mismatch_refit_milp_assignment_val": 0.3125, "mse_greedy_val": 23.447636396537355, "label_mismatch_greedy_val": 0.30833333333333335, "mse_greedy_val_sem": 4.561622910004613, "label_mismatch_greedy_val_sem": 0.02378248778295069, "r2_greedy_val": 0.7919159759930653, "r2_greedy_val_sem": 0.04048172852322791, "mse_refit_ground_truth_assignment_val": 9.159290307580784, "r2_refit_ground_truth_assignment_val": 0.9187166692617863, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 8.773575642411021, "r2_ground_truth_val": 0.9221396607433014, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 113.41735298711588, "r2_baseline_sklearn_val": -0.006512503122029001}