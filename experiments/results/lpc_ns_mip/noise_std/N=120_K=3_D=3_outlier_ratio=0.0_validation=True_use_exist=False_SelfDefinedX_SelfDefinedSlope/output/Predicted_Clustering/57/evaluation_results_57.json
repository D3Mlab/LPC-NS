{"time_milp": 1011.0490946769714, "time_greedy": 0.4768008470535278, "time_refit_milp_assignment": 1013.8292927742004, "mse_refit_ground_truth_assignment": 3.789309921008061, "r2_refit_ground_truth_assignment": 0.9692442060443609, "weight_mismatch_refit_ground_truth_assignment": 3.5187970338662096, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 4.6493798737718555, "r2_milp": 0.9622634800530695, "weight_mismatch_milp": 4.60343875282658, "refit-weight_mismatch_milp": 4.582408210431252, "rand_score_milp": 0.8039906103286385, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 4.649336120064285, "r2_refit_milp_assignment": 0.9622638351784203, "weight_mismatch_refit_milp_assignment": 4.6051900819175025, "refit-weight_mismatch_refit_milp_assignment": 4.552015608721538, "rand_score_refit_milp_assignment": 0.8039906103286385, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 8.894017264221358, "r2_greedy": 0.927812037516446, "weight_mismatch_greedy": 17.58964265895105, "refit-weight_mismatch_greedy": 17.8087350306709, "rand_score_greedy": 0.7302034428794992, "label_mismatch_greedy": 0.34930555555555554, "mse_greedy_sem": 1.548207582967388, "r2_greedy_sem": 0.012565969639568481, "weight_mismatch_greedy_sem": 2.24015112333552, "refit-weight_mismatch_greedy_sem": 2.382057287840498, "rand_score_greedy_sem": 0.01813862515776067, "label_mismatch_greedy_sem": 0.02812782005210661, "mse_ground_truth": 3.908589301382351, "r2_ground_truth": 0.9662725514584362, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 114.62984821763717, "r2_baseline_sklearn": 0.0696110726118867, "mse_milp_val": 8.719625760464334, "r2_milp_val": 0.9166460432839817, "label_mismatch_milp_val": 0.041666666666666664, "mse_refit_milp_assignment_val": 8.727337493171783, "r2_refit_milp_assignment_val": 0.9165723241299766, "label_mismatch_refit_milp_assignment_val": 0.041666666666666664, "mse_greedy_val": 22.646701348009977, "label_mismatch_greedy_val": 0.29166666666666663, "mse_greedy_val_sem": 5.218036374933282, "label_mismatch_greedy_val_sem": 0.03369458847348727, "r2_greedy_val": 0.7835122497479646, "r2_greedy_val_sem": 0.0498810373388819, "mse_refit_ground_truth_assignment_val": 4.801655468455674, "r2_refit_ground_truth_assignment_val": 0.9540992935846396, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 4.404327401308927, "r2_ground_truth_val": 0.9578974917436907, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 105.12194092129414, "r2_baseline_sklearn_val": -0.004897452501536836}