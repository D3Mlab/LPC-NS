{"time_milp": 2325.8812391757965, "time_greedy": 0.47458840608596803, "time_refit_milp_assignment": 2328.604287147522, "mse_refit_ground_truth_assignment": 1.1429090972609084, "r2_refit_ground_truth_assignment": 0.9899007390208403, "weight_mismatch_refit_ground_truth_assignment": 1.800353121676372, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.117091414937902, "r2_milp": 0.9724559724209025, "weight_mismatch_milp": 2.9679856508642493, "refit-weight_mismatch_milp": 2.9612472368714347, "rand_score_milp": 0.912754303599374, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 3.117055459793421, "r2_refit_milp_assignment": 0.9724562901367984, "weight_mismatch_refit_milp_assignment": 2.961245668834985, "refit-weight_mismatch_refit_milp_assignment": 2.984690062961352, "rand_score_refit_milp_assignment": 0.912754303599374, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 4.460200599782868, "r2_greedy": 0.9605876530473285, "weight_mismatch_greedy": 11.436973662170493, "refit-weight_mismatch_greedy": 10.488397946617285, "rand_score_greedy": 0.8445226917057903, "label_mismatch_greedy": 0.1923611111111111, "mse_greedy_sem": 1.3768846670065031, "r2_greedy_sem": 0.012166774788675594, "weight_mismatch_greedy_sem": 2.808943858870309, "refit-weight_mismatch_greedy_sem": 2.840771999599593, "rand_score_greedy_sem": 0.02870671397945804, "label_mismatch_greedy_sem": 0.04222668249371422, "mse_ground_truth": 1.4051179890165708, "r2_ground_truth": 0.9876171538743387, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 108.57658085536224, "r2_baseline_sklearn": 0.04056829286676966, "mse_milp_val": 6.2973067395636635, "r2_milp_val": 0.9447224411024231, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 6.300414688159901, "r2_refit_milp_assignment_val": 0.944695159628186, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 7.964616204257392, "label_mismatch_greedy_val": 0.22395833333333331, "mse_greedy_val_sem": 3.6925185351074643, "label_mismatch_greedy_val_sem": 0.0397553683068152, "r2_greedy_val": 0.9300868514850306, "r2_greedy_val_sem": 0.03241281062623606, "mse_refit_ground_truth_assignment_val": 2.040459715962848, "r2_refit_ground_truth_assignment_val": 0.9820889093080633, "label_mismatch_refit_ground_truth_assignment_val": 0.0625, "mse_ground_truth_val": 1.3739095639063692, "r2_ground_truth_val": 0.9879398654091859, "label_mismatch_ground_truth_val": 0.0625, "mse_baseline_sklearn_val": 113.9429922454442, "r2_baseline_sklearn_val": -0.00018797325570685253}