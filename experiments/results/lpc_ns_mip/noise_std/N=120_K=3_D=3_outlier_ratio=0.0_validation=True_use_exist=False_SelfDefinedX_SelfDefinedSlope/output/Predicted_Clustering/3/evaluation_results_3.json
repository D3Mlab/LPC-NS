{"time_milp": 372.6877233982086, "time_greedy": 0.5373803973197937, "time_refit_milp_assignment": 375.77754259109497, "mse_refit_ground_truth_assignment": 0.5919973614726703, "r2_refit_ground_truth_assignment": 0.9948387593746341, "weight_mismatch_refit_ground_truth_assignment": 0.7683642919953325, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.1547220513297674, "r2_milp": 0.9899327281670594, "weight_mismatch_milp": 2.2699515849571945, "refit-weight_mismatch_milp": 2.094948722787016, "rand_score_milp": 0.8877151799687011, "label_mismatch_milp": 0.09722222222222222, "mse_refit_milp_assignment": 1.1546772226290136, "r2_refit_milp_assignment": 0.989933118999395, "weight_mismatch_refit_milp_assignment": 2.280002056239912, "refit-weight_mismatch_refit_milp_assignment": 2.0573297248792466, "rand_score_refit_milp_assignment": 0.8877151799687011, "label_mismatch_refit_milp_assignment": 0.09722222222222222, "mse_greedy": 6.6410919687698335, "r2_greedy": 0.9421006310218354, "weight_mismatch_greedy": 17.273565305835785, "refit-weight_mismatch_greedy": 17.19132110507024, "rand_score_greedy": 0.773356807511737, "label_mismatch_greedy": 0.2826388888888889, "mse_greedy_sem": 1.71067344303776, "r2_greedy_sem": 0.014914251051689226, "weight_mismatch_greedy_sem": 2.9351342688824618, "refit-weight_mismatch_greedy_sem": 3.019292458366436, "rand_score_greedy_sem": 0.0291913579358409, "label_mismatch_greedy_sem": 0.038753877481073604, "mse_ground_truth": 0.6928283492647214, "r2_ground_truth": 0.9939189458807312, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 107.18755843116125, "r2_baseline_sklearn": 0.06550127228188907, "mse_milp_val": 1.679811237402905, "r2_milp_val": 0.9850842979997153, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 1.68067020424818, "r2_refit_milp_assignment_val": 0.9850766708966178, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 15.832614981675892, "label_mismatch_greedy_val": 0.2604166666666667, "mse_greedy_val_sem": 4.306721142878381, "label_mismatch_greedy_val_sem": 0.03703722739960825, "r2_greedy_val": 0.8594160095529368, "r2_greedy_val_sem": 0.038241064076232095, "mse_refit_ground_truth_assignment_val": 1.0808548624154868, "r2_refit_ground_truth_assignment_val": 0.9904026662791747, "label_mismatch_refit_ground_truth_assignment_val": 0.020833333333333332, "mse_ground_truth_val": 1.0857220129642875, "r2_ground_truth_val": 0.9903594489428693, "label_mismatch_ground_truth_val": 0.020833333333333332, "mse_baseline_sklearn_val": 112.89344533553135, "r2_baseline_sklearn_val": -0.00242512427384578}