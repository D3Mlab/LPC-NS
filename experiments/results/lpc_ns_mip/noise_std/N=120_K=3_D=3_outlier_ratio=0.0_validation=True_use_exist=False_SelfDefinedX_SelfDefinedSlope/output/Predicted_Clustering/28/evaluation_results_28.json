{"time_milp": 21181.906883716583, "time_greedy": 0.5412947654724121, "time_refit_milp_assignment": 21185.0113363266, "mse_refit_ground_truth_assignment": 4.339064842602691, "r2_refit_ground_truth_assignment": 0.9637396511423355, "weight_mismatch_refit_ground_truth_assignment": 3.323267814126435, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.007935878523952, "r2_milp": 0.9497933635997278, "weight_mismatch_milp": 13.987690622617803, "refit-weight_mismatch_milp": 15.889334849034254, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 6.0079107815795005, "r2_refit_milp_assignment": 0.9497935733278591, "weight_mismatch_refit_milp_assignment": 13.967852661046223, "refit-weight_mismatch_refit_milp_assignment": 15.871429442254188, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 8.950941288553489, "r2_greedy": 0.9251994921715114, "weight_mismatch_greedy": 18.329103527944245, "refit-weight_mismatch_greedy": 17.63884150093671, "rand_score_greedy": 0.7298904538341158, "label_mismatch_greedy": 0.33194444444444443, "mse_greedy_sem": 1.7929526534642959, "r2_greedy_sem": 0.014983202846282899, "weight_mismatch_greedy_sem": 2.6423472212341963, "refit-weight_mismatch_greedy_sem": 2.802385087291735, "rand_score_greedy_sem": 0.02078309019076382, "label_mismatch_greedy_sem": 0.03179790952299362, "mse_ground_truth": 5.519414190701667, "r2_ground_truth": 0.9545737261399825, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.8583222520023, "r2_baseline_sklearn": 0.06523134946797671, "mse_milp_val": 13.306745832499177, "r2_milp_val": 0.8928877744866982, "label_mismatch_milp_val": 0.3333333333333333, "mse_refit_milp_assignment_val": 13.313633982715118, "r2_refit_milp_assignment_val": 0.8928323285415672, "label_mismatch_refit_milp_assignment_val": 0.3333333333333333, "mse_greedy_val": 28.41003868079365, "label_mismatch_greedy_val": 0.3177083333333333, "mse_greedy_val_sem": 7.186909875597745, "label_mismatch_greedy_val_sem": 0.022765399887055438, "r2_greedy_val": 0.771314301157936, "r2_greedy_val_sem": 0.05785080146783133, "mse_refit_ground_truth_assignment_val": 8.910021004884934, "r2_refit_ground_truth_assignment_val": 0.9282790705393485, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 7.541046571574378, "r2_ground_truth_val": 0.9392985865103066, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 124.2876000190792, "r2_baseline_sklearn_val": -0.0004490661598794965}