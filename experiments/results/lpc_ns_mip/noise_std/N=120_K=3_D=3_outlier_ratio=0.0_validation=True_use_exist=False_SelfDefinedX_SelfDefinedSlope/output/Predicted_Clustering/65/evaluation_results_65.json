{"time_milp": 1258.275491476059, "time_greedy": 0.4828786015510559, "time_refit_milp_assignment": 1260.983228445053, "mse_refit_ground_truth_assignment": 1.9461870348788475, "r2_refit_ground_truth_assignment": 0.9827282739177766, "weight_mismatch_refit_ground_truth_assignment": 1.1444900853276563, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.898350319702316, "r2_milp": 0.9742781593366543, "weight_mismatch_milp": 3.7548440702943724, "refit-weight_mismatch_milp": 2.723947641913927, "rand_score_milp": 0.8689358372456965, "label_mismatch_milp": 0.1111111111111111, "mse_refit_milp_assignment": 2.898310317567033, "r2_refit_milp_assignment": 0.974278514341549, "weight_mismatch_refit_milp_assignment": 3.7567270051650663, "refit-weight_mismatch_refit_milp_assignment": 2.724340108417485, "rand_score_refit_milp_assignment": 0.8689358372456965, "label_mismatch_refit_milp_assignment": 0.1111111111111111, "mse_greedy": 6.513443205213292, "r2_greedy": 0.9421954802511744, "weight_mismatch_greedy": 11.610952111948624, "refit-weight_mismatch_greedy": 11.16645622481832, "rand_score_greedy": 0.7690532081377153, "label_mismatch_greedy": 0.29236111111111107, "mse_greedy_sem": 1.4209826717944312, "r2_greedy_sem": 0.012610721906462145, "weight_mismatch_greedy_sem": 2.0209447856090605, "refit-weight_mismatch_greedy_sem": 2.0737295774203086, "rand_score_greedy_sem": 0.02530703689440237, "label_mismatch_greedy_sem": 0.03675310728444233, "mse_ground_truth": 1.9364933688014145, "r2_ground_truth": 0.9826851915573034, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 107.21793470057716, "r2_baseline_sklearn": 0.048478503832312, "mse_milp_val": 3.059090777102444, "r2_milp_val": 0.9723149715668296, "label_mismatch_milp_val": 0.14583333333333334, "mse_refit_milp_assignment_val": 3.0655960982091517, "r2_refit_milp_assignment_val": 0.9722560978645013, "label_mismatch_refit_milp_assignment_val": 0.14583333333333334, "mse_greedy_val": 12.311788711198886, "label_mismatch_greedy_val": 0.3052083333333333, "mse_greedy_val_sem": 3.6210030146923593, "label_mismatch_greedy_val_sem": 0.034108148164314504, "r2_greedy_val": 0.8885772782278849, "r2_greedy_val_sem": 0.03277038137237238, "mse_refit_ground_truth_assignment_val": 2.431081480637171, "r2_refit_ground_truth_assignment_val": 0.9779985084396401, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 2.410974715915666, "r2_ground_truth_val": 0.9781804763489224, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 110.63926822140813, "r2_baseline_sklearn_val": -0.001294668815342792}