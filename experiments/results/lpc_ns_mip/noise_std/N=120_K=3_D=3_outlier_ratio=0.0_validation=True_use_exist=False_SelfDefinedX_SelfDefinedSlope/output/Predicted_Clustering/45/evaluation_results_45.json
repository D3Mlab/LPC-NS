{"time_milp": 68.76206278800964, "time_greedy": 0.4801450133323669, "time_refit_milp_assignment": 71.4939227104187, "mse_refit_ground_truth_assignment": 1.6021127599723453, "r2_refit_ground_truth_assignment": 0.9857328625154049, "weight_mismatch_refit_ground_truth_assignment": 2.0895575472133094, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.6143996244526524, "r2_milp": 0.9856234455073298, "weight_mismatch_milp": 3.164188682813556, "refit-weight_mismatch_milp": 1.2341593291018413, "rand_score_milp": 0.8748043818466353, "label_mismatch_milp": 0.1111111111111111, "mse_refit_milp_assignment": 1.6143522073046754, "r2_refit_milp_assignment": 0.9856238677666028, "weight_mismatch_refit_milp_assignment": 3.199389538193812, "refit-weight_mismatch_refit_milp_assignment": 1.2315020083750214, "rand_score_refit_milp_assignment": 0.8748043818466353, "label_mismatch_refit_milp_assignment": 0.1111111111111111, "mse_greedy": 5.517498975236871, "r2_greedy": 0.9508655580196642, "weight_mismatch_greedy": 11.339918959088505, "refit-weight_mismatch_greedy": 10.284043073071732, "rand_score_greedy": 0.7910602503912363, "label_mismatch_greedy": 0.24652777777777782, "mse_greedy_sem": 1.7098985904126693, "r2_greedy_sem": 0.015226992059256768, "weight_mismatch_greedy_sem": 2.9910132756402477, "refit-weight_mismatch_greedy_sem": 3.0726121854776602, "rand_score_greedy_sem": 0.02427939839778695, "label_mismatch_greedy_sem": 0.03645354674788621, "mse_ground_truth": 2.2007365372477987, "r2_ground_truth": 0.9809426437393735, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 111.80857251792428, "r2_baseline_sklearn": 0.0043220952206399765, "mse_milp_val": 2.7685962507420476, "r2_milp_val": 0.9769777003248963, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 2.7653277802355967, "r2_refit_milp_assignment_val": 0.9770048793357248, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 13.482859067270173, "label_mismatch_greedy_val": 0.2072916666666667, "mse_greedy_val_sem": 4.564507004386188, "label_mismatch_greedy_val_sem": 0.037980444481492, "r2_greedy_val": 0.8878831025503674, "r2_greedy_val_sem": 0.03795621990599877, "mse_refit_ground_truth_assignment_val": 2.946061497574883, "r2_refit_ground_truth_assignment_val": 0.9755019856577949, "label_mismatch_refit_ground_truth_assignment_val": 0.10416666666666667, "mse_ground_truth_val": 2.9820116932046528, "r2_ground_truth_val": 0.9752030413184225, "label_mismatch_ground_truth_val": 0.10416666666666667, "mse_baseline_sklearn_val": 120.25748700185049, "r2_baseline_sklearn_val": -2.7642851303522065e-06}