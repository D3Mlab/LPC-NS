{"time_milp": 24.26473832130432, "time_greedy": 0.545738422870636, "time_refit_milp_assignment": 27.410586833953857, "mse_refit_ground_truth_assignment": 0.07356640224362813, "r2_refit_ground_truth_assignment": 0.9993292139037283, "weight_mismatch_refit_ground_truth_assignment": 0.44776233157091616, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.41582607639443003, "r2_milp": 0.9962084546476956, "weight_mismatch_milp": 1.5434495844055913, "refit-weight_mismatch_milp": 1.2122242172508486, "rand_score_milp": 0.8877151799687011, "label_mismatch_milp": 0.09722222222222222, "mse_refit_milp_assignment": 0.41578468265078844, "r2_refit_milp_assignment": 0.9962088320801492, "weight_mismatch_refit_milp_assignment": 1.5746389227310669, "refit-weight_mismatch_refit_milp_assignment": 1.2086298430186384, "rand_score_refit_milp_assignment": 0.8877151799687011, "label_mismatch_refit_milp_assignment": 0.09722222222222222, "mse_greedy": 4.542710954654599, "r2_greedy": 0.9585790897090221, "weight_mismatch_greedy": 9.699459537731075, "refit-weight_mismatch_greedy": 9.509653949552106, "rand_score_greedy": 0.8237284820031299, "label_mismatch_greedy": 0.21736111111111106, "mse_greedy_sem": 1.696023992892859, "r2_greedy_sem": 0.015464522916427399, "weight_mismatch_greedy_sem": 2.731089600474443, "refit-weight_mismatch_greedy_sem": 2.761229001211885, "rand_score_greedy_sem": 0.032825813054544385, "label_mismatch_greedy_sem": 0.04377320001223627, "mse_ground_truth": 0.1010542287511744, "r2_ground_truth": 0.9990970559926606, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 109.24701848142199, "r2_baseline_sklearn": 0.0038743390795629162, "mse_milp_val": 0.5168228969194345, "r2_milp_val": 0.9955167511812816, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 0.5157522036416543, "r2_refit_milp_assignment_val": 0.9955260390522359, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 10.139948429083018, "label_mismatch_greedy_val": 0.2052083333333333, "mse_greedy_val_sem": 3.95776144237583, "label_mismatch_greedy_val_sem": 0.04067557580545434, "r2_greedy_val": 0.9120396714473762, "r2_greedy_val_sem": 0.034332126956957934, "mse_refit_ground_truth_assignment_val": 0.5721986899638826, "r2_refit_ground_truth_assignment_val": 0.9950363865143291, "label_mismatch_refit_ground_truth_assignment_val": 0.041666666666666664, "mse_ground_truth_val": 0.5533729352377457, "r2_ground_truth_val": 0.9951996930224976, "label_mismatch_ground_truth_val": 0.041666666666666664, "mse_baseline_sklearn_val": 115.28478384055232, "r2_baseline_sklearn_val": -5.31595060817569e-05}