{"time_milp": 1176.480495929718, "time_greedy": 0.46568697690963745, "time_refit_milp_assignment": 1179.1766982078552, "mse_refit_ground_truth_assignment": 6.385178097094, "r2_refit_ground_truth_assignment": 0.9471693712659243, "weight_mismatch_refit_ground_truth_assignment": 4.255380105783466, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.90672804286299, "r2_milp": 0.9511280419245205, "weight_mismatch_milp": 17.901731890068948, "refit-weight_mismatch_milp": 15.5031860093303, "rand_score_milp": 0.7570422535211268, "label_mismatch_milp": 0.3333333333333333, "mse_refit_milp_assignment": 5.906696169624634, "r2_refit_milp_assignment": 0.9511283056420231, "weight_mismatch_refit_milp_assignment": 17.9129587564483, "refit-weight_mismatch_refit_milp_assignment": 15.530054927372827, "rand_score_refit_milp_assignment": 0.7570422535211268, "label_mismatch_refit_milp_assignment": 0.3333333333333333, "mse_greedy": 9.730755339225325, "r2_greedy": 0.9194882406079316, "weight_mismatch_greedy": 20.58282285919658, "refit-weight_mismatch_greedy": 19.74095974362505, "rand_score_greedy": 0.7298513302034427, "label_mismatch_greedy": 0.3402777777777777, "mse_greedy_sem": 1.2406801315922127, "r2_greedy_sem": 0.010265322347034207, "weight_mismatch_greedy_sem": 2.944349418819593, "refit-weight_mismatch_greedy_sem": 2.9498183109498304, "rand_score_greedy_sem": 0.021660550556346043, "label_mismatch_greedy_sem": 0.03429562502763854, "mse_ground_truth": 7.850080665910758, "r2_ground_truth": 0.9349794813994586, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 115.66272402748642, "r2_baseline_sklearn": 0.0430126867958468, "mse_milp_val": 14.73929119198983, "r2_milp_val": 0.8777043972261089, "label_mismatch_milp_val": 0.2916666666666667, "mse_refit_milp_assignment_val": 14.75321618744689, "r2_refit_milp_assignment_val": 0.8775888580396676, "label_mismatch_refit_milp_assignment_val": 0.2916666666666667, "mse_greedy_val": 22.000901882660198, "label_mismatch_greedy_val": 0.38020833333333337, "mse_greedy_val_sem": 4.919000879134686, "label_mismatch_greedy_val_sem": 0.023651254788492202, "r2_greedy_val": 0.8174529885961276, "r2_greedy_val_sem": 0.04081418636236762, "mse_refit_ground_truth_assignment_val": 8.517256323063917, "r2_refit_ground_truth_assignment_val": 0.9293301840338895, "label_mismatch_refit_ground_truth_assignment_val": 0.22916666666666666, "mse_ground_truth_val": 6.025863223309988, "r2_ground_truth_val": 0.9500018986307693, "label_mismatch_ground_truth_val": 0.22916666666666666, "mse_baseline_sklearn_val": 120.55751399334359, "r2_baseline_sklearn_val": -0.00029598782540496416}