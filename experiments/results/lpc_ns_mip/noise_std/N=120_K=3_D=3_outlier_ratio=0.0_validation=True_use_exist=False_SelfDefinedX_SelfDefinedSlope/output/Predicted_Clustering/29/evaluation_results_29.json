{"time_milp": 2752.7302675247192, "time_greedy": 0.5323268294334411, "time_refit_milp_assignment": 2755.8227252960205, "mse_refit_ground_truth_assignment": 5.544816320603819, "r2_refit_ground_truth_assignment": 0.9543608100172366, "weight_mismatch_refit_ground_truth_assignment": 3.756737529010844, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.507623465038446, "r2_milp": 0.946435977950513, "weight_mismatch_milp": 14.060581938283832, "refit-weight_mismatch_milp": 16.14858880314812, "rand_score_milp": 0.7187010954616588, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 6.507598187151725, "r2_refit_milp_assignment": 0.946436186011918, "weight_mismatch_refit_milp_assignment": 14.04114887508146, "refit-weight_mismatch_refit_milp_assignment": 16.130741961871884, "rand_score_refit_milp_assignment": 0.7187010954616588, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 9.769337153900542, "r2_greedy": 0.9195889261983735, "weight_mismatch_greedy": 19.981254081305632, "refit-weight_mismatch_greedy": 19.29973879706931, "rand_score_greedy": 0.7271517996870109, "label_mismatch_greedy": 0.33263888888888893, "mse_greedy_sem": 1.8962320684920662, "r2_greedy_sem": 0.015607820101044112, "weight_mismatch_greedy_sem": 2.9846998079205225, "refit-weight_mismatch_greedy_sem": 3.1852252551730755, "rand_score_greedy_sem": 0.021521336159191884, "label_mismatch_greedy_sem": 0.03282808793852918, "mse_ground_truth": 7.053164447853171, "r2_ground_truth": 0.9429487800844719, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.90271146397494, "r2_baseline_sklearn": 0.062470749709138906, "mse_milp_val": 25.696836932708013, "r2_milp_val": 0.7973425815008968, "label_mismatch_milp_val": 0.3125, "mse_refit_milp_assignment_val": 25.713171910122625, "r2_refit_milp_assignment_val": 0.7972137561375747, "label_mismatch_refit_milp_assignment_val": 0.3125, "mse_greedy_val": 34.908119825217206, "label_mismatch_greedy_val": 0.29375000000000007, "mse_greedy_val_sem": 9.112950756666875, "label_mismatch_greedy_val_sem": 0.024599310894641502, "r2_greedy_val": 0.7246980448620388, "r2_greedy_val_sem": 0.0718690428744895, "mse_refit_ground_truth_assignment_val": 10.676367410047703, "r2_refit_ground_truth_assignment_val": 0.915801113423643, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 8.536993408563069, "r2_ground_truth_val": 0.9326732293762924, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 126.86336344220979, "r2_baseline_sklearn_val": -0.0005045292009158153}