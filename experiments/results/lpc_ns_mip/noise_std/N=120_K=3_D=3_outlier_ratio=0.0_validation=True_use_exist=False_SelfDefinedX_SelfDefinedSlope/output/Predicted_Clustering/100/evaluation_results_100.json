{"time_milp": 9370.279732227325, "time_greedy": 0.47236818075180054, "time_refit_milp_assignment": 9373.02272439003, "mse_refit_ground_truth_assignment": 7.129801460320849, "r2_refit_ground_truth_assignment": 0.9392262481288337, "weight_mismatch_refit_ground_truth_assignment": 3.7449797510518583, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 8.356582798575205, "r2_milp": 0.9287692802783022, "weight_mismatch_milp": 9.023852940991878, "refit-weight_mismatch_milp": 9.679064546979546, "rand_score_milp": 0.7664319248826291, "label_mismatch_milp": 0.2777777777777778, "mse_refit_milp_assignment": 8.35651636650599, "r2_refit_milp_assignment": 0.9287698465389637, "weight_mismatch_refit_milp_assignment": 9.061182170741912, "refit-weight_mismatch_refit_milp_assignment": 9.682937458438538, "rand_score_refit_milp_assignment": 0.7664319248826291, "label_mismatch_refit_milp_assignment": 0.2777777777777778, "mse_greedy": 11.292827719784784, "r2_greedy": 0.9037410068729818, "weight_mismatch_greedy": 17.733956112496138, "refit-weight_mismatch_greedy": 17.80249006343405, "rand_score_greedy": 0.7522104851330204, "label_mismatch_greedy": 0.292361111111111, "mse_greedy_sem": 1.4893325084869455, "r2_greedy_sem": 0.012694929140477653, "weight_mismatch_greedy_sem": 3.5210799915147635, "refit-weight_mismatch_greedy_sem": 3.6241184852566173, "rand_score_greedy_sem": 0.022089060936277306, "label_mismatch_greedy_sem": 0.03612621984873043, "mse_ground_truth": 8.884301978480348, "r2_ground_truth": 0.9239392642502842, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 114.23344169242003, "r2_baseline_sklearn": 0.026284970284143006, "mse_milp_val": 14.075077142627142, "r2_milp_val": 0.8780200570701195, "label_mismatch_milp_val": 0.2916666666666667, "mse_refit_milp_assignment_val": 14.095602432980863, "r2_refit_milp_assignment_val": 0.8778421771394737, "label_mismatch_refit_milp_assignment_val": 0.2916666666666667, "mse_greedy_val": 23.84618807819189, "label_mismatch_greedy_val": 0.30312500000000003, "mse_greedy_val_sem": 5.4457836911261035, "label_mismatch_greedy_val_sem": 0.029827836588098636, "r2_greedy_val": 0.7933399134230167, "r2_greedy_val_sem": 0.04719522153383009, "mse_refit_ground_truth_assignment_val": 8.417743262830449, "r2_refit_ground_truth_assignment_val": 0.9270486525655525, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 9.344465541057517, "r2_ground_truth_val": 0.9190173267358961, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 116.47298046961475, "r2_baseline_sklearn_val": -0.009398908907497283}