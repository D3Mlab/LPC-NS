{"time_milp": 186.47731566429138, "time_greedy": 0.47274428606033325, "time_refit_milp_assignment": 189.24290776252747, "mse_refit_ground_truth_assignment": 4.324069642986585, "r2_refit_ground_truth_assignment": 0.962769868102642, "weight_mismatch_refit_ground_truth_assignment": 3.4328445418298092, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.30313820798901, "r2_milp": 0.9715600623227485, "weight_mismatch_milp": 5.4077385426739415, "refit-weight_mismatch_milp": 2.8247233961793503, "rand_score_milp": 0.8137715179968701, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 3.3030811810833174, "r2_refit_milp_assignment": 0.9715605533229857, "weight_mismatch_refit_milp_assignment": 5.445424830393867, "refit-weight_mismatch_refit_milp_assignment": 2.8195124567682455, "rand_score_refit_milp_assignment": 0.8137715179968701, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 7.964107478954096, "r2_greedy": 0.931429233021926, "weight_mismatch_greedy": 15.377438335862902, "refit-weight_mismatch_greedy": 14.503348014545177, "rand_score_greedy": 0.7480829420970265, "label_mismatch_greedy": 0.3111111111111111, "mse_greedy_sem": 1.565409276972822, "r2_greedy_sem": 0.013478134874532793, "weight_mismatch_greedy_sem": 2.8206369493070613, "refit-weight_mismatch_greedy_sem": 3.072130647815936, "rand_score_greedy_sem": 0.01942622268180521, "label_mismatch_greedy_sem": 0.030783968174298213, "mse_ground_truth": 5.939743001041252, "r2_ground_truth": 0.9506680700658865, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 115.50055022527688, "r2_baseline_sklearn": 0.0055431401113017476, "mse_milp_val": 7.938241199799236, "r2_milp_val": 0.9373855240389857, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 7.934412490934943, "r2_refit_milp_assignment_val": 0.9374157237511274, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 26.619246146102675, "label_mismatch_greedy_val": 0.24479166666666666, "mse_greedy_val_sem": 5.616224734628744, "label_mismatch_greedy_val_sem": 0.033177920322555246, "r2_greedy_val": 0.7900353357923133, "r2_greedy_val_sem": 0.04429910351514129, "mse_refit_ground_truth_assignment_val": 8.736831688637595, "r2_refit_ground_truth_assignment_val": 0.9310864807487252, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 8.621575563337947, "r2_ground_truth_val": 0.9319955866457742, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 126.799357297644, "r2_baseline_sklearn_val": -0.00015546385592224432}