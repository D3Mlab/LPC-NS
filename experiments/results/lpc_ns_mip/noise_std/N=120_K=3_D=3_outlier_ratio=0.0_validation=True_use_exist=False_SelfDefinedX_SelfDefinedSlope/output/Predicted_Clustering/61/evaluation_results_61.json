{"time_milp": 433.23371505737305, "time_greedy": 0.47546054124832154, "time_refit_milp_assignment": 435.98894023895264, "mse_refit_ground_truth_assignment": 0.08936573119341644, "r2_refit_ground_truth_assignment": 0.9991830590801226, "weight_mismatch_refit_ground_truth_assignment": 0.24524787543320217, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 1.7260934140032174, "r2_milp": 0.984220838093093, "weight_mismatch_milp": 3.2117577674685664, "refit-weight_mismatch_milp": 3.0631846955195896, "rand_score_milp": 0.912754303599374, "label_mismatch_milp": 0.06944444444444445, "mse_refit_milp_assignment": 1.7260549504993146, "r2_refit_milp_assignment": 0.9842211897089734, "weight_mismatch_refit_milp_assignment": 3.215801243573327, "refit-weight_mismatch_refit_milp_assignment": 3.0369968914515164, "rand_score_refit_milp_assignment": 0.912754303599374, "label_mismatch_refit_milp_assignment": 0.06944444444444445, "mse_greedy": 4.538988257379726, "r2_greedy": 0.9585066312021681, "weight_mismatch_greedy": 10.203972752881784, "refit-weight_mismatch_greedy": 10.065166506773748, "rand_score_greedy": 0.8458920187793428, "label_mismatch_greedy": 0.19027777777777777, "mse_greedy_sem": 1.5373221200814413, "r2_greedy_sem": 0.014053500487888075, "weight_mismatch_greedy_sem": 3.2457644601096467, "refit-weight_mismatch_greedy_sem": 3.2642602759112496, "rand_score_greedy_sem": 0.03705156549376199, "label_mismatch_greedy_sem": 0.04809247136994662, "mse_ground_truth": 0.08892061387353431, "r2_ground_truth": 0.9992002092061585, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 104.4404594362749, "r2_baseline_sklearn": 0.04525276227392849, "mse_milp_val": 0.9705338044834564, "r2_milp_val": 0.9914732313432296, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 0.9715125363732197, "r2_refit_milp_assignment_val": 0.9914646325490789, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 10.776153703258483, "label_mismatch_greedy_val": 0.190625, "mse_greedy_val_sem": 4.343603423592423, "label_mismatch_greedy_val_sem": 0.046517889212784214, "r2_greedy_val": 0.9053245036772433, "r2_greedy_val_sem": 0.03816137197759988, "mse_refit_ground_truth_assignment_val": 0.08723723735747606, "r2_refit_ground_truth_assignment_val": 0.9992335643150535, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.08323152377742439, "r2_ground_truth_val": 0.9992687571057061, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 113.89563141913696, "r2_baseline_sklearn_val": -0.0006469590666613456}