{"time_milp": 2842.7723989486694, "time_greedy": 0.4760017037391663, "time_refit_milp_assignment": 2845.515622138977, "mse_refit_ground_truth_assignment": 4.996685226867936, "r2_refit_ground_truth_assignment": 0.9579813721423707, "weight_mismatch_refit_ground_truth_assignment": 3.7643747089620447, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.238884479922299, "r2_milp": 0.9559446458289411, "weight_mismatch_milp": 8.440530324987433, "refit-weight_mismatch_milp": 6.660754879320345, "rand_score_milp": 0.7562597809076682, "label_mismatch_milp": 0.3472222222222222, "mse_refit_milp_assignment": 5.238852326285025, "r2_refit_milp_assignment": 0.9559449162185408, "weight_mismatch_refit_milp_assignment": 8.43473913308911, "refit-weight_mismatch_refit_milp_assignment": 6.674352994019307, "rand_score_refit_milp_assignment": 0.7562597809076682, "label_mismatch_refit_milp_assignment": 0.3472222222222222, "mse_greedy": 8.955985924928758, "r2_greedy": 0.9246864225798681, "weight_mismatch_greedy": 18.93057471411269, "refit-weight_mismatch_greedy": 18.23173951373675, "rand_score_greedy": 0.7462245696400627, "label_mismatch_greedy": 0.3090277777777778, "mse_greedy_sem": 1.3257642314841724, "r2_greedy_sem": 0.011148749889255667, "weight_mismatch_greedy_sem": 3.4229310452823123, "refit-weight_mismatch_greedy_sem": 3.4255229841325967, "rand_score_greedy_sem": 0.023549991429001976, "label_mismatch_greedy_sem": 0.03655089544853407, "mse_ground_truth": 6.14303649743608, "r2_ground_truth": 0.9483212311247168, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 113.85566777050114, "r2_baseline_sklearn": 0.04255346968707319, "mse_milp_val": 13.171271985933615, "r2_milp_val": 0.889116495262477, "label_mismatch_milp_val": 0.3541666666666667, "mse_refit_milp_assignment_val": 13.180576768626949, "r2_refit_milp_assignment_val": 0.8890381621358846, "label_mismatch_refit_milp_assignment_val": 0.3541666666666667, "mse_greedy_val": 19.31111039970458, "label_mismatch_greedy_val": 0.3489583333333333, "mse_greedy_val_sem": 4.928925097705498, "label_mismatch_greedy_val_sem": 0.029380287566914996, "r2_greedy_val": 0.8374277287888919, "r2_greedy_val_sem": 0.04149458685584825, "mse_refit_ground_truth_assignment_val": 7.895299844256791, "r2_refit_ground_truth_assignment_val": 0.9335327279992574, "label_mismatch_refit_ground_truth_assignment_val": 0.1875, "mse_ground_truth_val": 5.295060758235091, "r2_ground_truth_val": 0.9554230680758647, "label_mismatch_ground_truth_val": 0.1875, "mse_baseline_sklearn_val": 118.81730145404968, "r2_baseline_sklearn_val": -0.0002738401234174681}