{"time_milp": 97.5609302520752, "time_greedy": 0.4768964767456055, "time_refit_milp_assignment": 100.25061440467834, "mse_refit_ground_truth_assignment": 0.24928362207524662, "r2_refit_ground_truth_assignment": 0.9978862642816758, "weight_mismatch_refit_ground_truth_assignment": 0.6624854998463205, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 2.6009100504324727, "r2_milp": 0.9779462588517428, "weight_mismatch_milp": 7.0896194355215485, "refit-weight_mismatch_milp": 6.746667166802666, "rand_score_milp": 0.8039906103286385, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 2.6008619228104735, "r2_refit_milp_assignment": 0.9779466669374117, "weight_mismatch_refit_milp_assignment": 7.06483400849155, "refit-weight_mismatch_refit_milp_assignment": 6.741091906959496, "rand_score_refit_milp_assignment": 0.8039906103286385, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 5.833785351417107, "r2_greedy": 0.9505339325236355, "weight_mismatch_greedy": 13.75031008379158, "refit-weight_mismatch_greedy": 13.459613315255677, "rand_score_greedy": 0.8023474178403756, "label_mismatch_greedy": 0.2277777777777778, "mse_greedy_sem": 1.8161507870385816, "r2_greedy_sem": 0.015399578826992683, "weight_mismatch_greedy_sem": 3.3814056016393366, "refit-weight_mismatch_greedy_sem": 3.4278837722578412, "rand_score_greedy_sem": 0.030898121738270456, "label_mismatch_greedy_sem": 0.039456488565615226, "mse_ground_truth": 0.35857255035350094, "r2_ground_truth": 0.996829673968944, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 116.94789888097047, "r2_baseline_sklearn": 0.008370670364158506, "mse_milp_val": 6.080910188417931, "r2_milp_val": 0.9423927719646643, "label_mismatch_milp_val": 0.1875, "mse_refit_milp_assignment_val": 6.082490802320163, "r2_refit_milp_assignment_val": 0.9423777980902475, "label_mismatch_refit_milp_assignment_val": 0.1875, "mse_greedy_val": 15.509192367954459, "label_mismatch_greedy_val": 0.23437500000000006, "mse_greedy_val_sem": 5.161766324507261, "label_mismatch_greedy_val_sem": 0.036614639873555704, "r2_greedy_val": 0.8530743665502012, "r2_greedy_val_sem": 0.04889976015224938, "mse_refit_ground_truth_assignment_val": 0.4936805232108293, "r2_refit_ground_truth_assignment_val": 0.9953231398596583, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.46882545217397187, "r2_ground_truth_val": 0.9955586032525862, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 106.0550012301657, "r2_baseline_sklearn_val": -0.004707264348444706}