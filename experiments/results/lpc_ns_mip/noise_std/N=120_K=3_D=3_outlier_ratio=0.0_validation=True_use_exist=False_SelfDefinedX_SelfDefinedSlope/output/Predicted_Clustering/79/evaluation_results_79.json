{"time_milp": 1625.138039112091, "time_greedy": 0.4215267300605774, "time_refit_milp_assignment": 1627.573561668396, "mse_refit_ground_truth_assignment": 4.680992458968521, "r2_refit_ground_truth_assignment": 0.9631071611539339, "weight_mismatch_refit_ground_truth_assignment": 2.8707704993349257, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 6.0899519459509595, "r2_milp": 0.9520025683246318, "weight_mismatch_milp": 9.50926390215894, "refit-weight_mismatch_milp": 7.900138949016181, "rand_score_milp": 0.8039906103286385, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 6.089906575397336, "r2_refit_milp_assignment": 0.952002925908742, "weight_mismatch_refit_milp_assignment": 9.486839094967747, "refit-weight_mismatch_refit_milp_assignment": 7.898983504033765, "rand_score_refit_milp_assignment": 0.8039906103286385, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 7.569579155448922, "r2_greedy": 0.9403410139276203, "weight_mismatch_greedy": 13.414210518105467, "refit-weight_mismatch_greedy": 12.854320263642956, "rand_score_greedy": 0.7798513302034429, "label_mismatch_greedy": 0.2479166666666667, "mse_greedy_sem": 1.4917608464197618, "r2_greedy_sem": 0.01175718461122295, "weight_mismatch_greedy_sem": 2.229562225329843, "refit-weight_mismatch_greedy_sem": 2.3100395950473964, "rand_score_greedy_sem": 0.019503270849021325, "label_mismatch_greedy_sem": 0.028325646101995918, "mse_ground_truth": 6.733195667749073, "r2_ground_truth": 0.9456600485060339, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 125.03087224310713, "r2_baseline_sklearn": 0.014579950537996655, "mse_milp_val": 18.11228233899601, "r2_milp_val": 0.8475636574150657, "label_mismatch_milp_val": 0.125, "mse_refit_milp_assignment_val": 18.10824792518484, "r2_refit_milp_assignment_val": 0.8475976117933344, "label_mismatch_refit_milp_assignment_val": 0.125, "mse_greedy_val": 22.697899971564297, "label_mismatch_greedy_val": 0.24583333333333335, "mse_greedy_val_sem": 5.951015519230509, "label_mismatch_greedy_val_sem": 0.028219262116256062, "r2_greedy_val": 0.8089702450930465, "r2_greedy_val_sem": 0.050084855317464504, "mse_refit_ground_truth_assignment_val": 9.017490502006375, "r2_refit_ground_truth_assignment_val": 0.9241071199259788, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 8.60372489193483, "r2_ground_truth_val": 0.9275894483871985, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 119.8778240998217, "r2_baseline_sklearn_val": -0.00891410153613248}