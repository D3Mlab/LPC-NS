{"time_milp": 767.7526819705963, "time_greedy": 0.47832937240600587, "time_refit_milp_assignment": 770.442752122879, "mse_refit_ground_truth_assignment": 6.403933766503624, "r2_refit_ground_truth_assignment": 0.949515644760212, "weight_mismatch_refit_ground_truth_assignment": 4.574436144026592, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.9022332719145005, "r2_milp": 0.9534707178319066, "weight_mismatch_milp": 7.0074426657292745, "refit-weight_mismatch_milp": 4.347355074853337, "rand_score_milp": 0.832942097026604, "label_mismatch_milp": 0.1527777777777778, "mse_refit_milp_assignment": 5.902183138523242, "r2_refit_milp_assignment": 0.9534711130502249, "weight_mismatch_refit_milp_assignment": 7.010943084617422, "refit-weight_mismatch_refit_milp_assignment": 4.330006294388323, "rand_score_refit_milp_assignment": 0.832942097026604, "label_mismatch_refit_milp_assignment": 0.1527777777777778, "mse_greedy": 11.703868261486111, "r2_greedy": 0.9077344856245849, "weight_mismatch_greedy": 21.873157957618197, "refit-weight_mismatch_greedy": 22.526691217486714, "rand_score_greedy": 0.6978482003129891, "label_mismatch_greedy": 0.3909722222222222, "mse_greedy_sem": 1.810992524351426, "r2_greedy_sem": 0.014276660763447338, "weight_mismatch_greedy_sem": 2.900877992234463, "refit-weight_mismatch_greedy_sem": 3.0767482614218276, "rand_score_greedy_sem": 0.017418680383917307, "label_mismatch_greedy_sem": 0.026299768718239296, "mse_ground_truth": 6.605515919336174, "r2_ground_truth": 0.9443719771597339, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 117.74284261273591, "r2_baseline_sklearn": 0.07179372708453713, "mse_milp_val": 13.680952682635033, "r2_milp_val": 0.8712059328239099, "label_mismatch_milp_val": 0.14583333333333334, "mse_refit_milp_assignment_val": 13.6906315196251, "r2_refit_milp_assignment_val": 0.8711148151356609, "label_mismatch_refit_milp_assignment_val": 0.14583333333333334, "mse_greedy_val": 31.496033192132423, "label_mismatch_greedy_val": 0.353125, "mse_greedy_val_sem": 5.078933517388973, "label_mismatch_greedy_val_sem": 0.0320431153141371, "r2_greedy_val": 0.7034927092557884, "r2_greedy_val_sem": 0.04781366618216388, "mse_refit_ground_truth_assignment_val": 9.237793890186198, "r2_refit_ground_truth_assignment_val": 0.9130343423845277, "label_mismatch_refit_ground_truth_assignment_val": 0.20833333333333334, "mse_ground_truth_val": 9.698841224253563, "r2_ground_truth_val": 0.9086939895821531, "label_mismatch_ground_truth_val": 0.20833333333333334, "mse_baseline_sklearn_val": 106.84169814606882, "r2_baseline_sklearn_val": -0.005820074628162475}