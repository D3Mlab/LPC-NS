{"time_milp": 23874.58238387108, "time_greedy": 0.48303660154342654, "time_refit_milp_assignment": 23877.33873319626, "mse_refit_ground_truth_assignment": 0.07512657163738884, "r2_refit_ground_truth_assignment": 0.9993169880623304, "weight_mismatch_refit_ground_truth_assignment": 0.5466624218428057, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 3.8964364791972264, "r2_milp": 0.9645756145707238, "weight_mismatch_milp": 8.118547754621844, "refit-weight_mismatch_milp": 8.370880785302449, "rand_score_milp": 0.8243348982785602, "label_mismatch_milp": 0.1527777777777778, "mse_refit_milp_assignment": 3.896385231976197, "r2_refit_milp_assignment": 0.9645760804839549, "weight_mismatch_refit_milp_assignment": 8.104624017551021, "refit-weight_mismatch_refit_milp_assignment": 8.398992627410466, "rand_score_refit_milp_assignment": 0.8243348982785602, "label_mismatch_refit_milp_assignment": 0.1527777777777778, "mse_greedy": 2.752262233067767, "r2_greedy": 0.9749778551075673, "weight_mismatch_greedy": 8.766889962684969, "refit-weight_mismatch_greedy": 8.545353777248613, "rand_score_greedy": 0.8556924882629108, "label_mismatch_greedy": 0.16041666666666662, "mse_greedy_sem": 0.9882453816235989, "r2_greedy_sem": 0.008984615939266935, "weight_mismatch_greedy_sem": 2.0216236470064803, "refit-weight_mismatch_greedy_sem": 2.074941604062077, "rand_score_greedy_sem": 0.02646295057851175, "label_mismatch_greedy_sem": 0.03163104272502954, "mse_ground_truth": 0.08361168869619488, "r2_ground_truth": 0.9992491674604773, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 101.92020415584021, "r2_baseline_sklearn": 0.07339421178223393, "mse_milp_val": 5.470625518029087, "r2_milp_val": 0.9517027077036441, "label_mismatch_milp_val": 0.10416666666666667, "mse_refit_milp_assignment_val": 5.475232518405625, "r2_refit_milp_assignment_val": 0.951662034906162, "label_mismatch_refit_milp_assignment_val": 0.10416666666666667, "mse_greedy_val": 5.825928549710705, "label_mismatch_greedy_val": 0.16041666666666668, "mse_greedy_val_sem": 2.144883720948367, "label_mismatch_greedy_val_sem": 0.031417678796112104, "r2_greedy_val": 0.9485659230126882, "r2_greedy_val_sem": 0.01893605688617124, "mse_refit_ground_truth_assignment_val": 0.09047472656847545, "r2_refit_ground_truth_assignment_val": 0.9992012459452562, "label_mismatch_refit_ground_truth_assignment_val": 0.0, "mse_ground_truth_val": 0.07464887981784495, "r2_ground_truth_val": 0.9993409640714255, "label_mismatch_ground_truth_val": 0.0, "mse_baseline_sklearn_val": 113.50775932846085, "r2_baseline_sklearn_val": -0.0021006577993931685}