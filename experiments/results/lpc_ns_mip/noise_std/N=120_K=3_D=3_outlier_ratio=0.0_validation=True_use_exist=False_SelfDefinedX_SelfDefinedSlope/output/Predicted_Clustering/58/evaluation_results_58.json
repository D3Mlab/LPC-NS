{"time_milp": 750.7888436317444, "time_greedy": 0.4867595434188843, "time_refit_milp_assignment": 753.4834394454956, "mse_refit_ground_truth_assignment": 5.011362370533162, "r2_refit_ground_truth_assignment": 0.9598859519023044, "weight_mismatch_refit_ground_truth_assignment": 4.046616588946403, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 5.194814140600149, "r2_milp": 0.9584174903176172, "weight_mismatch_milp": 4.974592055912435, "refit-weight_mismatch_milp": 4.847674844887171, "rand_score_milp": 0.8039906103286385, "label_mismatch_milp": 0.19444444444444445, "mse_refit_milp_assignment": 5.19476942571556, "r2_refit_milp_assignment": 0.9584178482432467, "weight_mismatch_refit_milp_assignment": 4.978224222797131, "refit-weight_mismatch_refit_milp_assignment": 4.817522461521885, "rand_score_refit_milp_assignment": 0.8039906103286385, "label_mismatch_refit_milp_assignment": 0.19444444444444445, "mse_greedy": 10.114683634490575, "r2_greedy": 0.9190358078687966, "weight_mismatch_greedy": 18.018711222518984, "refit-weight_mismatch_greedy": 18.14311177863655, "rand_score_greedy": 0.7197378716744913, "label_mismatch_greedy": 0.36180555555555555, "mse_greedy_sem": 1.676204371185892, "r2_greedy_sem": 0.01341737790958527, "weight_mismatch_greedy_sem": 2.23879826628577, "refit-weight_mismatch_greedy_sem": 2.4293109565046542, "rand_score_greedy_sem": 0.019247898714745866, "label_mismatch_greedy_sem": 0.03071917582159219, "mse_ground_truth": 5.16910935107816, "r2_ground_truth": 0.9559057160796678, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 116.09575969333264, "r2_baseline_sklearn": 0.07069763789973371, "mse_milp_val": 10.69431260393244, "r2_milp_val": 0.898487034289061, "label_mismatch_milp_val": 0.0625, "mse_refit_milp_assignment_val": 10.70207332381914, "r2_refit_milp_assignment_val": 0.8984133676850512, "label_mismatch_refit_milp_assignment_val": 0.0625, "mse_greedy_val": 26.95569203514939, "label_mismatch_greedy_val": 0.3125, "mse_greedy_val_sem": 5.093939445549377, "label_mismatch_greedy_val_sem": 0.035638495186824125, "r2_greedy_val": 0.744130142570121, "r2_greedy_val_sem": 0.04835288806496162, "mse_refit_ground_truth_assignment_val": 6.00380680732597, "r2_refit_ground_truth_assignment_val": 0.9430104339438259, "label_mismatch_refit_ground_truth_assignment_val": 0.125, "mse_ground_truth_val": 5.83078894391807, "r2_ground_truth_val": 0.9446527607661265, "label_mismatch_ground_truth_val": 0.125, "mse_baseline_sklearn_val": 105.91324555089061, "r2_baseline_sklearn_val": -0.005353785898153607}