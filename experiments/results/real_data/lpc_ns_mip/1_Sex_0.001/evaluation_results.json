{"time_milp": 3601.5651907920837, "time_refit_milp_assignment": 3602.4824817180634, "mse_refit_ground_truth_assignment": 0.3780451217972287, "r2_refit_ground_truth_assignment": 0.6341839439828694, "weight_mismatch_refit_ground_truth_assignment": 2.7807807489266354, "refit-weight_mismatch_refit_ground_truth_assignment": 0.0, "rand_score_refit_ground_truth_assignment": 1.0, "label_mismatch_refit_ground_truth_assignment": 0.0, "mse_milp": 0.16122714698010124, "r2_milp": 0.8439882552887706, "weight_mismatch_milp": 3.401092999751908, "refit-weight_mismatch_milp": 2.6967609644626633, "rand_score_milp": 0.49829145728643215, "label_mismatch_milp": 0.48, "mse_refit_milp_assignment": 0.1612281267711407, "r2_refit_milp_assignment": 0.8439873071921729, "weight_mismatch_refit_milp_assignment": 3.4075496754510013, "refit-weight_mismatch_refit_milp_assignment": 2.69642654121421, "rand_score_refit_milp_assignment": 0.49829145728643215, "label_mismatch_refit_milp_assignment": 0.48, "mse_greedy": NaN, "r2_greedy": NaN, "mse_ground_truth": NaN, "r2_ground_truth": NaN, "weight_mismatch_ground_truth": 0, "rand_score_ground_truth": 1, "label_mismatch_ground_truth": 0, "mse_baseline_sklearn": 0.4017170911991063, "r2_baseline_sklearn": 0.6108827877601319}